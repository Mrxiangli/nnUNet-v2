
The following have been reloaded with a version change:
  1) cuda/11.2.0 => cuda/11.7.0

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################


This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 256, 224], 'median_image_size_in_voxels': [50.0, 379.5, 300.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [3, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset301_HMstroke', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [50, 380, 300], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 111.81842803955078, 'mean': 35.17890167236328, 'median': 36.134971618652344, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 66.58898174285878, 'std': 10.811899185180664}}} 

2024-02-08 06:50:51.629938: unpacking dataset...
2024-02-08 06:50:55.437295: unpacking done...
2024-02-08 06:50:55.439674: do_dummy_2d_data_aug: True
2024-02-08 06:50:55.441736: Using splits from existing split file: /scratch/gilbreth/li2068/nnUNet_v2/nnUNet_preprocessed/Dataset301_HMstroke/splits_final.json
2024-02-08 06:50:55.442733: The split file contains 5 splits.
2024-02-08 06:50:55.443017: Desired fold for training: 4
2024-02-08 06:50:55.443271: This split has 64 training and 16 validation cases.
===============================================================================================
Layer (type:depth-idx)                                                 Param #
===============================================================================================
PlainConvUNet                                                          --
├─PlainConvEncoder: 1-1                                                --
│    └─Sequential: 2-1                                                 --
│    │    └─Sequential: 3-1                                            28,704
│    │    └─Sequential: 3-2                                            166,272
│    │    └─Sequential: 3-3                                            664,320
│    │    └─Sequential: 3-4                                            2,655,744
│    │    └─Sequential: 3-5                                            4,978,560
│    │    └─Sequential: 3-6                                            5,531,520
├─UNetDecoder: 1-2                                                     14,025,120
│    └─PlainConvEncoder: 2-2                                           (recursive)
│    │    └─Sequential: 3-7                                            (recursive)
│    └─ModuleList: 2-3                                                 --
│    │    └─StackedConvBlocks: 3-8                                     8,296,320
│    │    └─StackedConvBlocks: 3-9                                     5,309,952
│    │    └─StackedConvBlocks: 3-10                                    1,327,872
│    │    └─StackedConvBlocks: 3-11                                    332,160
│    │    └─StackedConvBlocks: 3-12                                    83,136
│    └─ModuleList: 2-4                                                 --
│    │    └─ConvTranspose3d: 3-13                                      409,920
│    │    └─ConvTranspose3d: 3-14                                      327,936
│    │    └─ConvTranspose3d: 3-15                                      262,272
│    │    └─ConvTranspose3d: 3-16                                      65,600
│    │    └─ConvTranspose3d: 3-17                                      16,416
│    └─ModuleList: 2-5                                                 --
│    │    └─Conv3d: 3-18                                               1,926
│    │    └─Conv3d: 3-19                                               1,542
│    │    └─Conv3d: 3-20                                               774
│    │    └─Conv3d: 3-21                                               390
│    │    └─Conv3d: 3-22                                               198
===============================================================================================
Total params: 73,861,214
Trainable params: 73,861,214
Non-trainable params: 0
===============================================================================================
finish writing the model summary file
2024-02-08 06:50:59.120770: 
2024-02-08 06:50:59.121335: Epoch 0
2024-02-08 06:50:59.121727: Current learning rate: 0.01
/home/li2068/.conda/envs/centos7/conda-4.9.2/nnunetv1/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py:1457: UserWarning: ONNX export mode is set to TrainingMode.EVAL, but operator 'instance_norm' is set to train=True. Exporting with train=True.
  warnings.warn(
using pin_memory on device 0
using pin_memory on device 0
2024-02-08 06:51:52.962954: train_loss 0.5363
2024-02-08 06:51:52.964220: val_loss 0.309
2024-02-08 06:51:52.964556: Pseudo dice [0.688, 0.692, 0.5272, 0.0, 0.003]
2024-02-08 06:51:52.964880: Epoch time: 53.84 s
2024-02-08 06:51:52.965182: Yayy! New best EMA pseudo Dice: 0.382
2024-02-08 06:51:54.093819: 
2024-02-08 06:51:54.095341: Epoch 1
2024-02-08 06:51:54.095743: Current learning rate: 0.00998
2024-02-08 06:52:36.052078: train_loss 0.157
2024-02-08 06:52:36.053512: val_loss 0.0565
2024-02-08 06:52:36.053903: Pseudo dice [0.6934, 0.7215, 0.6041, 0.6255, 0.6228]
2024-02-08 06:52:36.054241: Epoch time: 41.96 s
2024-02-08 06:52:36.054562: Yayy! New best EMA pseudo Dice: 0.4092
2024-02-08 06:52:37.472146: 
2024-02-08 06:52:37.473619: Epoch 2
2024-02-08 06:52:37.474019: Current learning rate: 0.00997
2024-02-08 06:53:19.655232: train_loss 0.0013
2024-02-08 06:53:19.656714: val_loss -0.0881
2024-02-08 06:53:19.657083: Pseudo dice [0.7456, 0.7588, 0.63, 0.6972, 0.6947]
2024-02-08 06:53:19.657408: Epoch time: 42.18 s
2024-02-08 06:53:19.657916: Yayy! New best EMA pseudo Dice: 0.4388
2024-02-08 06:53:20.989750: 
2024-02-08 06:53:20.990628: Epoch 3
2024-02-08 06:53:20.991721: Current learning rate: 0.00995
2024-02-08 06:54:03.174054: train_loss -0.0959
2024-02-08 06:54:03.175429: val_loss -0.1212
2024-02-08 06:54:03.175870: Pseudo dice [0.7454, 0.7569, 0.6574, 0.7136, 0.7544]
2024-02-08 06:54:03.176297: Epoch time: 42.19 s
2024-02-08 06:54:03.176704: Yayy! New best EMA pseudo Dice: 0.4675
2024-02-08 06:54:04.479067: 
2024-02-08 06:54:04.480338: Epoch 4
2024-02-08 06:54:04.480874: Current learning rate: 0.00993
2024-02-08 06:54:46.737192: train_loss -0.1564
2024-02-08 06:54:46.738616: val_loss -0.1523
2024-02-08 06:54:46.739173: Pseudo dice [0.744, 0.764, 0.6759, 0.7167, 0.7722]
2024-02-08 06:54:46.739599: Epoch time: 42.26 s
2024-02-08 06:54:46.739987: Yayy! New best EMA pseudo Dice: 0.4942
2024-02-08 06:54:48.091873: 
2024-02-08 06:54:48.092829: Epoch 5
2024-02-08 06:54:48.093682: Current learning rate: 0.00992
2024-02-08 06:55:30.421473: train_loss -0.1749
2024-02-08 06:55:30.422782: val_loss -0.1982
2024-02-08 06:55:30.423241: Pseudo dice [0.7726, 0.776, 0.6702, 0.751, 0.7766]
2024-02-08 06:55:30.423654: Epoch time: 42.33 s
2024-02-08 06:55:30.424079: Yayy! New best EMA pseudo Dice: 0.5197
2024-02-08 06:55:31.841494: 
2024-02-08 06:55:31.843063: Epoch 6
2024-02-08 06:55:31.843649: Current learning rate: 0.0099
2024-02-08 06:56:14.252488: train_loss -0.1997
2024-02-08 06:56:14.254017: val_loss -0.2404
2024-02-08 06:56:14.254498: Pseudo dice [0.785, 0.7853, 0.6793, 0.7502, 0.8096]
2024-02-08 06:56:14.254936: Epoch time: 42.41 s
2024-02-08 06:56:14.255363: Yayy! New best EMA pseudo Dice: 0.5439
2024-02-08 06:56:15.594421: 
2024-02-08 06:56:15.595621: Epoch 7
2024-02-08 06:56:15.596591: Current learning rate: 0.00989
2024-02-08 06:56:58.335003: train_loss -0.2199
2024-02-08 06:56:58.336292: val_loss -0.224
2024-02-08 06:56:58.336761: Pseudo dice [0.771, 0.7732, 0.6873, 0.7452, 0.7788]
2024-02-08 06:56:58.337167: Epoch time: 42.74 s
2024-02-08 06:56:58.337564: Yayy! New best EMA pseudo Dice: 0.5646
2024-02-08 06:56:59.683141: 
2024-02-08 06:56:59.684711: Epoch 8
2024-02-08 06:56:59.685370: Current learning rate: 0.00987
2024-02-08 06:57:42.446491: train_loss -0.2557
2024-02-08 06:57:42.447972: val_loss -0.2464
2024-02-08 06:57:42.448442: Pseudo dice [0.7848, 0.7871, 0.6782, 0.756, 0.7923]
2024-02-08 06:57:42.448871: Epoch time: 42.77 s
2024-02-08 06:57:42.449255: Yayy! New best EMA pseudo Dice: 0.5841
2024-02-08 06:57:43.815181: 
2024-02-08 06:57:43.816734: Epoch 9
2024-02-08 06:57:43.817331: Current learning rate: 0.00985
2024-02-08 06:58:26.572595: train_loss -0.2627
2024-02-08 06:58:26.574198: val_loss -0.2399
2024-02-08 06:58:26.574674: Pseudo dice [0.7677, 0.7741, 0.6962, 0.7661, 0.7925]
2024-02-08 06:58:26.575123: Epoch time: 42.76 s
2024-02-08 06:58:26.575540: Yayy! New best EMA pseudo Dice: 0.6016
2024-02-08 06:58:27.905666: 
2024-02-08 06:58:27.906708: Epoch 10
2024-02-08 06:58:27.907685: Current learning rate: 0.00984
2024-02-08 06:59:10.531137: train_loss -0.2793
2024-02-08 06:59:10.532562: val_loss -0.2627
2024-02-08 06:59:10.533056: Pseudo dice [0.7925, 0.7862, 0.6869, 0.7697, 0.807]
2024-02-08 06:59:10.533520: Epoch time: 42.63 s
2024-02-08 06:59:10.533921: Yayy! New best EMA pseudo Dice: 0.6183
2024-02-08 06:59:12.209410: 
2024-02-08 06:59:12.210392: Epoch 11
2024-02-08 06:59:12.211046: Current learning rate: 0.00982
2024-02-08 06:59:54.727155: train_loss -0.2758
2024-02-08 06:59:54.728734: val_loss -0.2605
2024-02-08 06:59:54.729244: Pseudo dice [0.7919, 0.7875, 0.69, 0.7712, 0.808]
2024-02-08 06:59:54.729666: Epoch time: 42.52 s
2024-02-08 06:59:54.730097: Yayy! New best EMA pseudo Dice: 0.6335
2024-02-08 06:59:56.079128: 
2024-02-08 06:59:56.080939: Epoch 12
2024-02-08 06:59:56.081585: Current learning rate: 0.0098
2024-02-08 07:00:38.887697: train_loss -0.281
2024-02-08 07:00:38.889116: val_loss -0.266
2024-02-08 07:00:38.889586: Pseudo dice [0.7821, 0.7876, 0.6981, 0.7592, 0.8161]
2024-02-08 07:00:38.890030: Epoch time: 42.81 s
2024-02-08 07:00:38.890478: Yayy! New best EMA pseudo Dice: 0.647
2024-02-08 07:00:40.250367: 
2024-02-08 07:00:40.251735: Epoch 13
2024-02-08 07:00:40.252349: Current learning rate: 0.00979
2024-02-08 07:01:23.351711: train_loss -0.2929
2024-02-08 07:01:23.353236: val_loss -0.2579
2024-02-08 07:01:23.353705: Pseudo dice [0.7763, 0.793, 0.695, 0.7697, 0.8116]
2024-02-08 07:01:23.354178: Epoch time: 43.1 s
2024-02-08 07:01:23.354663: Yayy! New best EMA pseudo Dice: 0.6592
2024-02-08 07:01:24.682571: 
2024-02-08 07:01:24.684372: Epoch 14
2024-02-08 07:01:24.685117: Current learning rate: 0.00977
2024-02-08 07:02:07.690174: train_loss -0.3075
2024-02-08 07:02:07.691676: val_loss -0.2914
2024-02-08 07:02:07.692126: Pseudo dice [0.7999, 0.7881, 0.6982, 0.7865, 0.8054]
2024-02-08 07:02:07.692561: Epoch time: 43.01 s
2024-02-08 07:02:07.692971: Yayy! New best EMA pseudo Dice: 0.6708
2024-02-08 07:02:09.060756: 
2024-02-08 07:02:09.062222: Epoch 15
2024-02-08 07:02:09.062851: Current learning rate: 0.00975
2024-02-08 07:02:51.780625: train_loss -0.322
2024-02-08 07:02:51.783237: val_loss -0.2881
2024-02-08 07:02:51.783780: Pseudo dice [0.7941, 0.7869, 0.7011, 0.7711, 0.8]
2024-02-08 07:02:51.784243: Epoch time: 42.72 s
2024-02-08 07:02:51.784657: Yayy! New best EMA pseudo Dice: 0.6808
2024-02-08 07:02:53.242165: 
2024-02-08 07:02:53.243190: Epoch 16
2024-02-08 07:02:53.244210: Current learning rate: 0.00974
2024-02-08 07:03:35.931364: train_loss -0.3117
2024-02-08 07:03:35.932763: val_loss -0.2807
2024-02-08 07:03:35.933308: Pseudo dice [0.8027, 0.7849, 0.7014, 0.7601, 0.8059]
2024-02-08 07:03:35.933745: Epoch time: 42.69 s
2024-02-08 07:03:35.934142: Yayy! New best EMA pseudo Dice: 0.6898
2024-02-08 07:03:37.282737: 
2024-02-08 07:03:37.283808: Epoch 17
2024-02-08 07:03:37.284733: Current learning rate: 0.00972
2024-02-08 07:04:19.866740: train_loss -0.3277
2024-02-08 07:04:19.868207: val_loss -0.2804
2024-02-08 07:04:19.868715: Pseudo dice [0.7908, 0.7876, 0.7011, 0.7726, 0.7938]
2024-02-08 07:04:19.869155: Epoch time: 42.58 s
2024-02-08 07:04:19.869590: Yayy! New best EMA pseudo Dice: 0.6978
2024-02-08 07:04:21.192255: 
2024-02-08 07:04:21.193387: Epoch 18
2024-02-08 07:04:21.193895: Current learning rate: 0.0097
2024-02-08 07:05:03.600467: train_loss -0.3189
2024-02-08 07:05:03.601813: val_loss -0.3017
2024-02-08 07:05:03.602239: Pseudo dice [0.8039, 0.7964, 0.7019, 0.7817, 0.8127]
2024-02-08 07:05:03.602635: Epoch time: 42.41 s
2024-02-08 07:05:03.603035: Yayy! New best EMA pseudo Dice: 0.7059
2024-02-08 07:05:04.948078: 
2024-02-08 07:05:04.949678: Epoch 19
2024-02-08 07:05:04.950224: Current learning rate: 0.00969
2024-02-08 07:05:48.040867: train_loss -0.3257
2024-02-08 07:05:48.042130: val_loss -0.3043
2024-02-08 07:05:48.042580: Pseudo dice [0.8026, 0.7984, 0.7023, 0.7808, 0.8177]
2024-02-08 07:05:48.042989: Epoch time: 43.09 s
2024-02-08 07:05:48.043390: Yayy! New best EMA pseudo Dice: 0.7134
2024-02-08 07:05:49.785017: 
2024-02-08 07:05:49.786244: Epoch 20
2024-02-08 07:05:49.787056: Current learning rate: 0.00967
2024-02-08 07:06:32.713863: train_loss -0.3415
2024-02-08 07:06:32.715350: val_loss -0.2997
2024-02-08 07:06:32.715827: Pseudo dice [0.7969, 0.7942, 0.7014, 0.7886, 0.8073]
2024-02-08 07:06:32.716298: Epoch time: 42.93 s
2024-02-08 07:06:32.716722: Yayy! New best EMA pseudo Dice: 0.7198
2024-02-08 07:06:34.118015: 
2024-02-08 07:06:34.119269: Epoch 21
2024-02-08 07:06:34.120195: Current learning rate: 0.00966
2024-02-08 07:07:17.193672: train_loss -0.3409
2024-02-08 07:07:17.195464: val_loss -0.2863
2024-02-08 07:07:17.195992: Pseudo dice [0.8005, 0.7876, 0.7012, 0.7763, 0.8153]
2024-02-08 07:07:17.196471: Epoch time: 43.08 s
2024-02-08 07:07:17.196905: Yayy! New best EMA pseudo Dice: 0.7254
2024-02-08 07:07:18.524449: 
2024-02-08 07:07:18.525561: Epoch 22
2024-02-08 07:07:18.526565: Current learning rate: 0.00964
2024-02-08 07:08:01.578551: train_loss -0.3442
2024-02-08 07:08:01.579991: val_loss -0.306
2024-02-08 07:08:01.580491: Pseudo dice [0.7994, 0.7957, 0.7054, 0.7792, 0.8184]
2024-02-08 07:08:01.581083: Epoch time: 43.06 s
2024-02-08 07:08:01.581555: Yayy! New best EMA pseudo Dice: 0.7309
2024-02-08 07:08:02.895033: 
2024-02-08 07:08:02.896344: Epoch 23
2024-02-08 07:08:02.896932: Current learning rate: 0.00962
2024-02-08 07:08:45.837461: train_loss -0.3503
2024-02-08 07:08:45.838909: val_loss -0.3089
2024-02-08 07:08:45.839374: Pseudo dice [0.804, 0.7989, 0.7122, 0.7883, 0.8225]
2024-02-08 07:08:45.839802: Epoch time: 42.94 s
2024-02-08 07:08:45.840444: Yayy! New best EMA pseudo Dice: 0.7363
2024-02-08 07:08:47.122533: 
2024-02-08 07:08:47.124084: Epoch 24
2024-02-08 07:08:47.124638: Current learning rate: 0.00961
2024-02-08 07:09:30.021939: train_loss -0.3633
2024-02-08 07:09:30.023832: val_loss -0.3147
2024-02-08 07:09:30.024389: Pseudo dice [0.8042, 0.7981, 0.7042, 0.7983, 0.8208]
2024-02-08 07:09:30.024875: Epoch time: 42.9 s
2024-02-08 07:09:30.025357: Yayy! New best EMA pseudo Dice: 0.7412
2024-02-08 07:09:31.655828: 
2024-02-08 07:09:31.656878: Epoch 25
2024-02-08 07:09:31.657506: Current learning rate: 0.00959
2024-02-08 07:10:14.308088: train_loss -0.3558
2024-02-08 07:10:14.309575: val_loss -0.2922
2024-02-08 07:10:14.310034: Pseudo dice [0.8052, 0.7874, 0.6968, 0.7863, 0.8218]
2024-02-08 07:10:14.310480: Epoch time: 42.65 s
2024-02-08 07:10:14.310914: Yayy! New best EMA pseudo Dice: 0.745
2024-02-08 07:10:15.608683: 
2024-02-08 07:10:15.609962: Epoch 26
2024-02-08 07:10:15.610508: Current learning rate: 0.00957
2024-02-08 07:10:58.147965: train_loss -0.3628
2024-02-08 07:10:58.149557: val_loss -0.3077
2024-02-08 07:10:58.150039: Pseudo dice [0.7989, 0.7965, 0.6895, 0.787, 0.8119]
2024-02-08 07:10:58.150498: Epoch time: 42.54 s
2024-02-08 07:10:58.150936: Yayy! New best EMA pseudo Dice: 0.7482
2024-02-08 07:10:59.439487: 
2024-02-08 07:10:59.440638: Epoch 27
2024-02-08 07:10:59.441673: Current learning rate: 0.00956
2024-02-08 07:11:42.070557: train_loss -0.3594
2024-02-08 07:11:42.072216: val_loss -0.3288
2024-02-08 07:11:42.072902: Pseudo dice [0.8156, 0.8023, 0.7015, 0.8094, 0.8176]
2024-02-08 07:11:42.073389: Epoch time: 42.63 s
2024-02-08 07:11:42.073852: Yayy! New best EMA pseudo Dice: 0.7523
2024-02-08 07:11:43.397971: 
2024-02-08 07:11:43.399744: Epoch 28
2024-02-08 07:11:43.400401: Current learning rate: 0.00954
2024-02-08 07:12:26.192275: train_loss -0.364
2024-02-08 07:12:26.194055: val_loss -0.3335
2024-02-08 07:12:26.194565: Pseudo dice [0.8055, 0.8071, 0.7088, 0.8012, 0.8261]
2024-02-08 07:12:26.195009: Epoch time: 42.8 s
2024-02-08 07:12:26.195505: Yayy! New best EMA pseudo Dice: 0.756
2024-02-08 07:12:27.544363: 
2024-02-08 07:12:27.545384: Epoch 29
2024-02-08 07:12:27.546463: Current learning rate: 0.00952
2024-02-08 07:13:10.582005: train_loss -0.3686
2024-02-08 07:13:10.583355: val_loss -0.3212
2024-02-08 07:13:10.583801: Pseudo dice [0.8166, 0.8019, 0.7002, 0.788, 0.821]
2024-02-08 07:13:10.584218: Epoch time: 43.04 s
2024-02-08 07:13:10.584646: Yayy! New best EMA pseudo Dice: 0.759
2024-02-08 07:13:12.210034: 
2024-02-08 07:13:12.211012: Epoch 30
2024-02-08 07:13:12.211620: Current learning rate: 0.00951
2024-02-08 07:13:55.290427: train_loss -0.3817
2024-02-08 07:13:55.292104: val_loss -0.3085
2024-02-08 07:13:55.292647: Pseudo dice [0.7985, 0.7945, 0.704, 0.792, 0.8145]
2024-02-08 07:13:55.293130: Epoch time: 43.08 s
2024-02-08 07:13:55.293622: Yayy! New best EMA pseudo Dice: 0.7612
2024-02-08 07:13:56.649865: 
2024-02-08 07:13:56.651271: Epoch 31
2024-02-08 07:13:56.651812: Current learning rate: 0.00949
2024-02-08 07:14:40.004472: train_loss -0.3795
2024-02-08 07:14:40.005944: val_loss -0.3027
2024-02-08 07:14:40.006436: Pseudo dice [0.8009, 0.7943, 0.7056, 0.8026, 0.813]
2024-02-08 07:14:40.006897: Epoch time: 43.36 s
2024-02-08 07:14:40.007333: Yayy! New best EMA pseudo Dice: 0.7634
2024-02-08 07:14:41.371050: 
2024-02-08 07:14:41.372584: Epoch 32
2024-02-08 07:14:41.373274: Current learning rate: 0.00947
2024-02-08 07:15:24.396036: train_loss -0.3811
2024-02-08 07:15:24.397388: val_loss -0.3361
2024-02-08 07:15:24.397848: Pseudo dice [0.8177, 0.8018, 0.7149, 0.8134, 0.8057]
2024-02-08 07:15:24.398286: Epoch time: 43.03 s
2024-02-08 07:15:24.398730: Yayy! New best EMA pseudo Dice: 0.7661
2024-02-08 07:15:25.792835: 
2024-02-08 07:15:25.793934: Epoch 33
2024-02-08 07:15:25.794909: Current learning rate: 0.00946
2024-02-08 07:16:08.898062: train_loss -0.3836
2024-02-08 07:16:08.899930: val_loss -0.3365
2024-02-08 07:16:08.900470: Pseudo dice [0.8186, 0.8022, 0.7111, 0.8129, 0.8188]
2024-02-08 07:16:08.901137: Epoch time: 43.11 s
2024-02-08 07:16:08.901642: Yayy! New best EMA pseudo Dice: 0.7688
2024-02-08 07:16:10.220600: 
2024-02-08 07:16:10.221656: Epoch 34
2024-02-08 07:16:10.222629: Current learning rate: 0.00944
2024-02-08 07:16:53.483434: train_loss -0.3819
2024-02-08 07:16:53.484860: val_loss -0.3274
2024-02-08 07:16:53.485344: Pseudo dice [0.8175, 0.8, 0.7123, 0.811, 0.817]
2024-02-08 07:16:53.485798: Epoch time: 43.26 s
2024-02-08 07:16:53.486216: Yayy! New best EMA pseudo Dice: 0.771
2024-02-08 07:16:55.107061: 
2024-02-08 07:16:55.108721: Epoch 35
2024-02-08 07:16:55.109295: Current learning rate: 0.00943
2024-02-08 07:17:38.341725: train_loss -0.3818
2024-02-08 07:17:38.343295: val_loss -0.3345
2024-02-08 07:17:38.343822: Pseudo dice [0.8047, 0.8054, 0.7039, 0.799, 0.8147]
2024-02-08 07:17:38.344260: Epoch time: 43.24 s
2024-02-08 07:17:38.344685: Yayy! New best EMA pseudo Dice: 0.7725
2024-02-08 07:17:39.723243: 
2024-02-08 07:17:39.725267: Epoch 36
2024-02-08 07:17:39.725947: Current learning rate: 0.00941
2024-02-08 07:18:22.405441: train_loss -0.3911
2024-02-08 07:18:22.406930: val_loss -0.3498
2024-02-08 07:18:22.407387: Pseudo dice [0.817, 0.8046, 0.7143, 0.8162, 0.8309]
2024-02-08 07:18:22.407817: Epoch time: 42.68 s
2024-02-08 07:18:22.408246: Yayy! New best EMA pseudo Dice: 0.7749
2024-02-08 07:18:23.758127: 
2024-02-08 07:18:23.759382: Epoch 37
2024-02-08 07:18:23.759882: Current learning rate: 0.00939
2024-02-08 07:19:06.561167: train_loss -0.3922
2024-02-08 07:19:06.562463: val_loss -0.3129
2024-02-08 07:19:06.562963: Pseudo dice [0.8059, 0.7928, 0.707, 0.7895, 0.8192]
2024-02-08 07:19:06.563379: Epoch time: 42.8 s
2024-02-08 07:19:06.563794: Yayy! New best EMA pseudo Dice: 0.7757
2024-02-08 07:19:07.889383: 
2024-02-08 07:19:07.890335: Epoch 38
2024-02-08 07:19:07.891172: Current learning rate: 0.00938
2024-02-08 07:19:50.497706: train_loss -0.3937
2024-02-08 07:19:50.500135: val_loss -0.3553
2024-02-08 07:19:50.500809: Pseudo dice [0.818, 0.8106, 0.7224, 0.8201, 0.8178]
2024-02-08 07:19:50.501484: Epoch time: 42.61 s
2024-02-08 07:19:50.502059: Yayy! New best EMA pseudo Dice: 0.7779
2024-02-08 07:19:51.815689: 
2024-02-08 07:19:51.816964: Epoch 39
2024-02-08 07:19:51.817462: Current learning rate: 0.00936
2024-02-08 07:20:34.465688: train_loss -0.3952
2024-02-08 07:20:34.467044: val_loss -0.3089
2024-02-08 07:20:34.467499: Pseudo dice [0.8102, 0.7955, 0.7103, 0.799, 0.7971]
2024-02-08 07:20:34.467922: Epoch time: 42.65 s
2024-02-08 07:20:34.468325: Yayy! New best EMA pseudo Dice: 0.7784
2024-02-08 07:20:35.994482: 
2024-02-08 07:20:35.995903: Epoch 40
2024-02-08 07:20:35.996591: Current learning rate: 0.00934
2024-02-08 07:21:18.791726: train_loss -0.3894
2024-02-08 07:21:18.793642: val_loss -0.3344
2024-02-08 07:21:18.794239: Pseudo dice [0.8158, 0.8051, 0.7081, 0.7986, 0.8188]
2024-02-08 07:21:18.794735: Epoch time: 42.8 s
2024-02-08 07:21:18.795270: Yayy! New best EMA pseudo Dice: 0.7795
2024-02-08 07:21:20.157043: 
2024-02-08 07:21:20.158710: Epoch 41
2024-02-08 07:21:20.159720: Current learning rate: 0.00933
2024-02-08 07:22:02.841706: train_loss -0.3989
2024-02-08 07:22:02.843056: val_loss -0.3404
2024-02-08 07:22:02.843565: Pseudo dice [0.8135, 0.8076, 0.7231, 0.8129, 0.811]
2024-02-08 07:22:02.844027: Epoch time: 42.69 s
2024-02-08 07:22:02.844478: Yayy! New best EMA pseudo Dice: 0.7809
2024-02-08 07:22:04.102729: 
2024-02-08 07:22:04.104180: Epoch 42
2024-02-08 07:22:04.104696: Current learning rate: 0.00931
2024-02-08 07:22:46.850098: train_loss -0.4088
2024-02-08 07:22:46.851726: val_loss -0.3418
2024-02-08 07:22:46.852271: Pseudo dice [0.8134, 0.8057, 0.7143, 0.8108, 0.817]
2024-02-08 07:22:46.852756: Epoch time: 42.75 s
2024-02-08 07:22:46.853208: Yayy! New best EMA pseudo Dice: 0.782
2024-02-08 07:22:48.122955: 
2024-02-08 07:22:48.124216: Epoch 43
2024-02-08 07:22:48.124740: Current learning rate: 0.00929
2024-02-08 07:23:30.868593: train_loss -0.4018
2024-02-08 07:23:30.870765: val_loss -0.3414
2024-02-08 07:23:30.871320: Pseudo dice [0.8204, 0.8031, 0.7125, 0.8111, 0.8271]
2024-02-08 07:23:30.871803: Epoch time: 42.75 s
2024-02-08 07:23:30.872247: Yayy! New best EMA pseudo Dice: 0.7833
2024-02-08 07:23:32.161578: 
2024-02-08 07:23:32.163032: Epoch 44
2024-02-08 07:23:32.163979: Current learning rate: 0.00928
2024-02-08 07:24:15.096109: train_loss -0.4078
2024-02-08 07:24:15.097896: val_loss -0.3161
2024-02-08 07:24:15.098426: Pseudo dice [0.8067, 0.7926, 0.7065, 0.8083, 0.8181]
2024-02-08 07:24:15.098962: Epoch time: 42.94 s
2024-02-08 07:24:15.099445: Yayy! New best EMA pseudo Dice: 0.7836
2024-02-08 07:24:16.734388: 
2024-02-08 07:24:16.735594: Epoch 45
2024-02-08 07:24:16.736207: Current learning rate: 0.00926
2024-02-08 07:24:59.883705: train_loss -0.4031
2024-02-08 07:24:59.885380: val_loss -0.3607
2024-02-08 07:24:59.885934: Pseudo dice [0.822, 0.8075, 0.7224, 0.8226, 0.8196]
2024-02-08 07:24:59.886489: Epoch time: 43.15 s
2024-02-08 07:24:59.887329: Yayy! New best EMA pseudo Dice: 0.7851
2024-02-08 07:25:01.195724: 
2024-02-08 07:25:01.197693: Epoch 46
2024-02-08 07:25:01.198249: Current learning rate: 0.00924
2024-02-08 07:25:44.417038: train_loss -0.4112
2024-02-08 07:25:44.419738: val_loss -0.3201
2024-02-08 07:25:44.420244: Pseudo dice [0.8118, 0.8005, 0.708, 0.7969, 0.801]
2024-02-08 07:25:44.420836: Epoch time: 43.22 s
2024-02-08 07:25:45.428236: 
2024-02-08 07:25:45.429421: Epoch 47
2024-02-08 07:25:45.430472: Current learning rate: 0.00923
2024-02-08 07:26:28.511858: train_loss -0.4094
2024-02-08 07:26:28.514576: val_loss -0.3334
2024-02-08 07:26:28.515106: Pseudo dice [0.8168, 0.8028, 0.7176, 0.8029, 0.8001]
2024-02-08 07:26:28.516107: Epoch time: 43.08 s
2024-02-08 07:26:28.516526: Yayy! New best EMA pseudo Dice: 0.7853
2024-02-08 07:26:29.819906: 
2024-02-08 07:26:29.821097: Epoch 48
2024-02-08 07:26:29.822004: Current learning rate: 0.00921
2024-02-08 07:27:12.648626: train_loss -0.4126
2024-02-08 07:27:12.650146: val_loss -0.3384
2024-02-08 07:27:12.650646: Pseudo dice [0.8154, 0.8046, 0.7089, 0.7891, 0.8217]
2024-02-08 07:27:12.651099: Epoch time: 42.83 s
2024-02-08 07:27:12.651525: Yayy! New best EMA pseudo Dice: 0.7856
2024-02-08 07:27:13.980119: 
2024-02-08 07:27:13.981158: Epoch 49
2024-02-08 07:27:13.982059: Current learning rate: 0.00919
2024-02-08 07:27:56.660235: train_loss -0.4102
2024-02-08 07:27:56.661767: val_loss -0.3104
2024-02-08 07:27:56.662241: Pseudo dice [0.8071, 0.7969, 0.7097, 0.8014, 0.8222]
2024-02-08 07:27:56.662689: Epoch time: 42.68 s
2024-02-08 07:27:56.897238: Yayy! New best EMA pseudo Dice: 0.7857
2024-02-08 07:27:58.318815: 
2024-02-08 07:27:58.319697: Epoch 50
2024-02-08 07:27:58.320127: Current learning rate: 0.00918
2024-02-08 07:28:41.063823: train_loss -0.4075
2024-02-08 07:28:41.065406: val_loss -0.3595
2024-02-08 07:28:41.065807: Pseudo dice [0.8221, 0.8109, 0.7155, 0.8278, 0.8224]
2024-02-08 07:28:41.066136: Epoch time: 42.75 s
2024-02-08 07:28:41.066469: Yayy! New best EMA pseudo Dice: 0.7871
2024-02-08 07:28:42.416277: 
2024-02-08 07:28:42.417717: Epoch 51
2024-02-08 07:28:42.418180: Current learning rate: 0.00916
2024-02-08 07:29:25.142850: train_loss -0.4195
2024-02-08 07:29:25.144839: val_loss -0.3265
2024-02-08 07:29:25.145250: Pseudo dice [0.8168, 0.8039, 0.7082, 0.8048, 0.813]
2024-02-08 07:29:25.145617: Epoch time: 42.73 s
2024-02-08 07:29:25.145943: Yayy! New best EMA pseudo Dice: 0.7874
2024-02-08 07:29:26.477625: 
2024-02-08 07:29:26.478872: Epoch 52
2024-02-08 07:29:26.479366: Current learning rate: 0.00914
2024-02-08 07:30:09.077394: train_loss -0.4223
2024-02-08 07:30:09.078836: val_loss -0.3649
2024-02-08 07:30:09.079304: Pseudo dice [0.8257, 0.8108, 0.7152, 0.823, 0.8276]
2024-02-08 07:30:09.079734: Epoch time: 42.6 s
2024-02-08 07:30:09.080121: Yayy! New best EMA pseudo Dice: 0.7887
2024-02-08 07:30:10.357382: 
2024-02-08 07:30:10.358338: Epoch 53
2024-02-08 07:30:10.359244: Current learning rate: 0.00913
2024-02-08 07:30:53.222005: train_loss -0.4184
2024-02-08 07:30:53.223807: val_loss -0.371
2024-02-08 07:30:53.224314: Pseudo dice [0.8299, 0.8122, 0.7192, 0.8341, 0.8275]
2024-02-08 07:30:53.224754: Epoch time: 42.87 s
2024-02-08 07:30:53.225161: Yayy! New best EMA pseudo Dice: 0.7903
2024-02-08 07:30:54.521938: 
2024-02-08 07:30:54.523451: Epoch 54
2024-02-08 07:30:54.524171: Current learning rate: 0.00911
2024-02-08 07:31:37.318650: train_loss -0.4277
2024-02-08 07:31:37.319971: val_loss -0.3415
2024-02-08 07:31:37.320387: Pseudo dice [0.8137, 0.8117, 0.711, 0.8154, 0.8108]
2024-02-08 07:31:37.320854: Epoch time: 42.8 s
2024-02-08 07:31:37.321276: Yayy! New best EMA pseudo Dice: 0.7905
2024-02-08 07:31:38.714446: 
2024-02-08 07:31:38.716224: Epoch 55
2024-02-08 07:31:38.716806: Current learning rate: 0.0091
2024-02-08 07:32:21.769224: train_loss -0.4286
2024-02-08 07:32:21.770689: val_loss -0.36
2024-02-08 07:32:21.771151: Pseudo dice [0.8247, 0.8049, 0.7235, 0.827, 0.8315]
2024-02-08 07:32:21.771558: Epoch time: 43.06 s
2024-02-08 07:32:21.771946: Yayy! New best EMA pseudo Dice: 0.7917
2024-02-08 07:32:23.070462: 
2024-02-08 07:32:23.071970: Epoch 56
2024-02-08 07:32:23.072570: Current learning rate: 0.00908
2024-02-08 07:33:06.311585: train_loss -0.4307
2024-02-08 07:33:06.313041: val_loss -0.3264
2024-02-08 07:33:06.313532: Pseudo dice [0.8101, 0.801, 0.7237, 0.7961, 0.8105]
2024-02-08 07:33:06.313958: Epoch time: 43.24 s
2024-02-08 07:33:07.364082: 
2024-02-08 07:33:07.365348: Epoch 57
2024-02-08 07:33:07.366529: Current learning rate: 0.00906
2024-02-08 07:33:50.114496: train_loss -0.4341
2024-02-08 07:33:50.115866: val_loss -0.3452
2024-02-08 07:33:50.116304: Pseudo dice [0.812, 0.8057, 0.7183, 0.8041, 0.8338]
2024-02-08 07:33:50.116735: Epoch time: 42.75 s
2024-02-08 07:33:50.117120: Yayy! New best EMA pseudo Dice: 0.7917
2024-02-08 07:33:51.395714: 
2024-02-08 07:33:51.396988: Epoch 58
2024-02-08 07:33:51.398067: Current learning rate: 0.00905
2024-02-08 07:34:34.576615: train_loss -0.4287
2024-02-08 07:34:34.578465: val_loss -0.3415
2024-02-08 07:34:34.578947: Pseudo dice [0.8155, 0.8057, 0.7127, 0.8197, 0.8164]
2024-02-08 07:34:34.579468: Epoch time: 43.18 s
2024-02-08 07:34:34.579936: Yayy! New best EMA pseudo Dice: 0.7919
2024-02-08 07:34:35.932347: 
2024-02-08 07:34:35.933631: Epoch 59
2024-02-08 07:34:35.934665: Current learning rate: 0.00903
2024-02-08 07:35:19.070167: train_loss -0.4302
2024-02-08 07:35:19.072043: val_loss -0.343
2024-02-08 07:35:19.072542: Pseudo dice [0.8217, 0.8083, 0.7015, 0.8157, 0.8234]
2024-02-08 07:35:19.072991: Epoch time: 43.14 s
2024-02-08 07:35:19.073440: Yayy! New best EMA pseudo Dice: 0.7921
2024-02-08 07:35:20.414645: 
2024-02-08 07:35:20.415851: Epoch 60
2024-02-08 07:35:20.416791: Current learning rate: 0.00901
2024-02-08 07:36:03.585999: train_loss -0.4414
2024-02-08 07:36:03.587871: val_loss -0.3406
2024-02-08 07:36:03.588396: Pseudo dice [0.813, 0.8007, 0.7239, 0.808, 0.818]
2024-02-08 07:36:03.588936: Epoch time: 43.17 s
2024-02-08 07:36:03.589751: Yayy! New best EMA pseudo Dice: 0.7922
2024-02-08 07:36:05.133399: 
2024-02-08 07:36:05.134477: Epoch 61
2024-02-08 07:36:05.135059: Current learning rate: 0.009
2024-02-08 07:36:48.146694: train_loss -0.4325
2024-02-08 07:36:48.148071: val_loss -0.3524
2024-02-08 07:36:48.148563: Pseudo dice [0.8229, 0.806, 0.7163, 0.822, 0.8]
2024-02-08 07:36:48.148972: Epoch time: 43.01 s
2024-02-08 07:36:48.149393: Yayy! New best EMA pseudo Dice: 0.7923
2024-02-08 07:36:49.468524: 
2024-02-08 07:36:49.469605: Epoch 62
2024-02-08 07:36:49.470643: Current learning rate: 0.00898
2024-02-08 07:37:31.902965: train_loss -0.4356
2024-02-08 07:37:31.904742: val_loss -0.3536
2024-02-08 07:37:31.905257: Pseudo dice [0.8165, 0.8133, 0.7141, 0.8089, 0.8208]
2024-02-08 07:37:31.905741: Epoch time: 42.44 s
2024-02-08 07:37:31.906152: Yayy! New best EMA pseudo Dice: 0.7926
2024-02-08 07:37:33.212358: 
2024-02-08 07:37:33.213626: Epoch 63
2024-02-08 07:37:33.214102: Current learning rate: 0.00896
2024-02-08 07:38:16.181514: train_loss -0.4365
2024-02-08 07:38:16.183375: val_loss -0.3488
2024-02-08 07:38:16.184165: Pseudo dice [0.8253, 0.8083, 0.7175, 0.8216, 0.8157]
2024-02-08 07:38:16.184676: Epoch time: 42.97 s
2024-02-08 07:38:16.185134: Yayy! New best EMA pseudo Dice: 0.7931
2024-02-08 07:38:17.524457: 
2024-02-08 07:38:17.525923: Epoch 64
2024-02-08 07:38:17.527365: Current learning rate: 0.00895
2024-02-08 07:39:00.474436: train_loss -0.4466
2024-02-08 07:39:00.475868: val_loss -0.348
2024-02-08 07:39:00.476401: Pseudo dice [0.8229, 0.812, 0.709, 0.8054, 0.8291]
2024-02-08 07:39:00.476911: Epoch time: 42.95 s
2024-02-08 07:39:00.477338: Yayy! New best EMA pseudo Dice: 0.7933
2024-02-08 07:39:01.797664: 
2024-02-08 07:39:01.798829: Epoch 65
2024-02-08 07:39:01.799675: Current learning rate: 0.00893
2024-02-08 07:39:44.571723: train_loss -0.4441
2024-02-08 07:39:44.573913: val_loss -0.3578
2024-02-08 07:39:44.574593: Pseudo dice [0.8174, 0.8131, 0.7142, 0.8144, 0.8298]
2024-02-08 07:39:44.575112: Epoch time: 42.77 s
2024-02-08 07:39:44.575583: Yayy! New best EMA pseudo Dice: 0.7938
2024-02-08 07:39:46.191887: 
2024-02-08 07:39:46.193020: Epoch 66
2024-02-08 07:39:46.193620: Current learning rate: 0.00891
2024-02-08 07:40:29.213848: train_loss -0.4429
2024-02-08 07:40:29.215263: val_loss -0.348
2024-02-08 07:40:29.215746: Pseudo dice [0.8174, 0.8167, 0.7194, 0.81, 0.8217]
2024-02-08 07:40:29.216160: Epoch time: 43.02 s
2024-02-08 07:40:29.216607: Yayy! New best EMA pseudo Dice: 0.7941
2024-02-08 07:40:30.607105: 
2024-02-08 07:40:30.608196: Epoch 67
2024-02-08 07:40:30.609189: Current learning rate: 0.0089
2024-02-08 07:41:13.675677: train_loss -0.4415
2024-02-08 07:41:13.677253: val_loss -0.364
2024-02-08 07:41:13.677748: Pseudo dice [0.8304, 0.8062, 0.7249, 0.8106, 0.8231]
2024-02-08 07:41:13.678221: Epoch time: 43.07 s
2024-02-08 07:41:13.678633: Yayy! New best EMA pseudo Dice: 0.7946
2024-02-08 07:41:15.015056: 
2024-02-08 07:41:15.016651: Epoch 68
2024-02-08 07:41:15.017750: Current learning rate: 0.00888
2024-02-08 07:41:58.123143: train_loss -0.4424
2024-02-08 07:41:58.124562: val_loss -0.341
2024-02-08 07:41:58.125036: Pseudo dice [0.818, 0.8046, 0.7112, 0.8041, 0.8243]
2024-02-08 07:41:58.125487: Epoch time: 43.11 s
2024-02-08 07:41:59.172657: 
2024-02-08 07:41:59.174714: Epoch 69
2024-02-08 07:41:59.175343: Current learning rate: 0.00886
2024-02-08 07:42:42.107591: train_loss -0.4481
2024-02-08 07:42:42.109601: val_loss -0.3494
2024-02-08 07:42:42.110405: Pseudo dice [0.8223, 0.7986, 0.7178, 0.8143, 0.8158]
2024-02-08 07:42:42.110935: Epoch time: 42.94 s
2024-02-08 07:42:43.140705: 
2024-02-08 07:42:43.141856: Epoch 70
2024-02-08 07:42:43.142837: Current learning rate: 0.00885
2024-02-08 07:43:25.758920: train_loss -0.4452
2024-02-08 07:43:25.760364: val_loss -0.347
2024-02-08 07:43:25.760818: Pseudo dice [0.8131, 0.8101, 0.7211, 0.8015, 0.8194]
2024-02-08 07:43:25.761229: Epoch time: 42.62 s
2024-02-08 07:43:26.959306: 
2024-02-08 07:43:26.960846: Epoch 71
2024-02-08 07:43:26.961380: Current learning rate: 0.00883
2024-02-08 07:44:09.676222: train_loss -0.4545
2024-02-08 07:44:09.677922: val_loss -0.3437
2024-02-08 07:44:09.678463: Pseudo dice [0.8248, 0.8051, 0.7129, 0.8137, 0.8218]
2024-02-08 07:44:09.678949: Epoch time: 42.72 s
2024-02-08 07:44:10.730682: 
2024-02-08 07:44:10.732348: Epoch 72
2024-02-08 07:44:10.734110: Current learning rate: 0.00881
2024-02-08 07:44:53.844223: train_loss -0.4534
2024-02-08 07:44:53.845707: val_loss -0.3591
2024-02-08 07:44:53.846218: Pseudo dice [0.8199, 0.8169, 0.7193, 0.8152, 0.8168]
2024-02-08 07:44:53.846673: Epoch time: 43.12 s
2024-02-08 07:44:53.847092: Yayy! New best EMA pseudo Dice: 0.7947
2024-02-08 07:44:55.203124: 
2024-02-08 07:44:55.204984: Epoch 73
2024-02-08 07:44:55.205696: Current learning rate: 0.0088
2024-02-08 07:45:38.081657: train_loss -0.4457
2024-02-08 07:45:38.083179: val_loss -0.3483
2024-02-08 07:45:38.083670: Pseudo dice [0.8234, 0.8127, 0.7148, 0.8163, 0.8258]
2024-02-08 07:45:38.084128: Epoch time: 42.88 s
2024-02-08 07:45:38.084553: Yayy! New best EMA pseudo Dice: 0.7951
2024-02-08 07:45:39.420342: 
2024-02-08 07:45:39.421553: Epoch 74
2024-02-08 07:45:39.422112: Current learning rate: 0.00878
2024-02-08 07:46:22.103409: train_loss -0.4457
2024-02-08 07:46:22.104894: val_loss -0.3455
2024-02-08 07:46:22.105390: Pseudo dice [0.8239, 0.8106, 0.7189, 0.8151, 0.8231]
2024-02-08 07:46:22.105927: Epoch time: 42.68 s
2024-02-08 07:46:22.106360: Yayy! New best EMA pseudo Dice: 0.7954
2024-02-08 07:46:23.431082: 
2024-02-08 07:46:23.432252: Epoch 75
2024-02-08 07:46:23.433157: Current learning rate: 0.00876
2024-02-08 07:47:06.216561: train_loss -0.443
2024-02-08 07:47:06.218028: val_loss -0.3441
2024-02-08 07:47:06.218510: Pseudo dice [0.8234, 0.803, 0.7158, 0.8158, 0.819]
2024-02-08 07:47:06.218936: Epoch time: 42.79 s
2024-02-08 07:47:06.219343: Yayy! New best EMA pseudo Dice: 0.7954
2024-02-08 07:47:07.963486: 
2024-02-08 07:47:07.964702: Epoch 76
2024-02-08 07:47:07.965309: Current learning rate: 0.00875
2024-02-08 07:47:50.914961: train_loss -0.4501
2024-02-08 07:47:50.916373: val_loss -0.3641
2024-02-08 07:47:50.916835: Pseudo dice [0.8184, 0.8169, 0.7261, 0.8142, 0.8281]
2024-02-08 07:47:50.917249: Epoch time: 42.95 s
2024-02-08 07:47:50.917636: Yayy! New best EMA pseudo Dice: 0.7959
2024-02-08 07:47:52.241224: 
2024-02-08 07:47:52.242225: Epoch 77
2024-02-08 07:47:52.243104: Current learning rate: 0.00873
2024-02-08 07:48:35.064495: train_loss -0.4596
2024-02-08 07:48:35.066086: val_loss -0.3685
2024-02-08 07:48:35.067142: Pseudo dice [0.8259, 0.8171, 0.731, 0.8278, 0.8118]
2024-02-08 07:48:35.068459: Epoch time: 42.82 s
2024-02-08 07:48:35.068870: Yayy! New best EMA pseudo Dice: 0.7966
2024-02-08 07:48:36.415757: 
2024-02-08 07:48:36.416819: Epoch 78
2024-02-08 07:48:36.418030: Current learning rate: 0.00871
2024-02-08 07:49:18.896900: train_loss -0.4663
2024-02-08 07:49:18.898353: val_loss -0.3719
2024-02-08 07:49:18.898796: Pseudo dice [0.8299, 0.8106, 0.7302, 0.8345, 0.8254]
2024-02-08 07:49:18.899233: Epoch time: 42.48 s
2024-02-08 07:49:18.899678: Yayy! New best EMA pseudo Dice: 0.7976
2024-02-08 07:49:20.260573: 
2024-02-08 07:49:20.261495: Epoch 79
2024-02-08 07:49:20.262333: Current learning rate: 0.0087
2024-02-08 07:50:02.702149: train_loss -0.4678
2024-02-08 07:50:02.703683: val_loss -0.374
2024-02-08 07:50:02.704159: Pseudo dice [0.8268, 0.8189, 0.7255, 0.8154, 0.8257]
2024-02-08 07:50:02.704610: Epoch time: 42.44 s
2024-02-08 07:50:02.705045: Yayy! New best EMA pseudo Dice: 0.798
2024-02-08 07:50:04.066627: 
2024-02-08 07:50:04.068245: Epoch 80
2024-02-08 07:50:04.068871: Current learning rate: 0.00868
2024-02-08 07:50:46.537745: train_loss -0.4642
2024-02-08 07:50:46.539168: val_loss -0.3531
2024-02-08 07:50:46.539621: Pseudo dice [0.8226, 0.8116, 0.7163, 0.8164, 0.8242]
2024-02-08 07:50:46.540036: Epoch time: 42.47 s
2024-02-08 07:50:46.540451: Yayy! New best EMA pseudo Dice: 0.7981
2024-02-08 07:50:47.995875: 
2024-02-08 07:50:47.996865: Epoch 81
2024-02-08 07:50:47.997745: Current learning rate: 0.00866
2024-02-08 07:51:30.542988: train_loss -0.4683
2024-02-08 07:51:30.544667: val_loss -0.3596
2024-02-08 07:51:30.545209: Pseudo dice [0.826, 0.8155, 0.7191, 0.8141, 0.8248]
2024-02-08 07:51:30.545709: Epoch time: 42.55 s
2024-02-08 07:51:30.546181: Yayy! New best EMA pseudo Dice: 0.7982
2024-02-08 07:51:31.875014: 
2024-02-08 07:51:31.876426: Epoch 82
2024-02-08 07:51:31.876959: Current learning rate: 0.00865
2024-02-08 07:52:14.747901: train_loss -0.4679
2024-02-08 07:52:14.749329: val_loss -0.3857
2024-02-08 07:52:14.749862: Pseudo dice [0.8339, 0.8123, 0.735, 0.8391, 0.8263]
2024-02-08 07:52:14.750381: Epoch time: 42.87 s
2024-02-08 07:52:14.750837: Yayy! New best EMA pseudo Dice: 0.7993
2024-02-08 07:52:16.041758: 
2024-02-08 07:52:16.043165: Epoch 83
2024-02-08 07:52:16.043824: Current learning rate: 0.00863
2024-02-08 07:52:59.336837: train_loss -0.4729
2024-02-08 07:52:59.338397: val_loss -0.3681
2024-02-08 07:52:59.338886: Pseudo dice [0.8293, 0.8163, 0.7256, 0.814, 0.8147]
2024-02-08 07:52:59.339298: Epoch time: 43.3 s
2024-02-08 07:52:59.339658: Yayy! New best EMA pseudo Dice: 0.7994
2024-02-08 07:53:00.634361: 
2024-02-08 07:53:00.635741: Epoch 84
2024-02-08 07:53:00.636722: Current learning rate: 0.00861
2024-02-08 07:53:43.344122: train_loss -0.4754
2024-02-08 07:53:43.345523: val_loss -0.3748
2024-02-08 07:53:43.346042: Pseudo dice [0.8302, 0.8191, 0.7247, 0.8244, 0.8269]
2024-02-08 07:53:43.346473: Epoch time: 42.71 s
2024-02-08 07:53:43.346887: Yayy! New best EMA pseudo Dice: 0.8
2024-02-08 07:53:44.602389: 
2024-02-08 07:53:44.603977: Epoch 85
2024-02-08 07:53:44.604516: Current learning rate: 0.0086
2024-02-08 07:54:27.437629: train_loss -0.468
2024-02-08 07:54:27.439471: val_loss -0.3494
2024-02-08 07:54:27.440397: Pseudo dice [0.822, 0.8092, 0.7262, 0.8135, 0.8071]
2024-02-08 07:54:27.440880: Epoch time: 42.84 s
2024-02-08 07:54:28.600188: 
2024-02-08 07:54:28.601158: Epoch 86
2024-02-08 07:54:28.601991: Current learning rate: 0.00858
2024-02-08 07:55:11.456163: train_loss -0.4643
2024-02-08 07:55:11.457942: val_loss -0.3705
2024-02-08 07:55:11.458470: Pseudo dice [0.8302, 0.8144, 0.7328, 0.8219, 0.8268]
2024-02-08 07:55:11.458970: Epoch time: 42.86 s
2024-02-08 07:55:11.459455: Yayy! New best EMA pseudo Dice: 0.8001
2024-02-08 07:55:12.723539: 
2024-02-08 07:55:12.726848: Epoch 87
2024-02-08 07:55:12.727582: Current learning rate: 0.00856
2024-02-08 07:55:55.912312: train_loss -0.4794
2024-02-08 07:55:55.914852: val_loss -0.3789
2024-02-08 07:55:55.915409: Pseudo dice [0.8306, 0.8248, 0.7294, 0.8263, 0.8249]
2024-02-08 07:55:55.915910: Epoch time: 43.19 s
2024-02-08 07:55:55.916355: Yayy! New best EMA pseudo Dice: 0.8008
2024-02-08 07:55:57.265257: 
2024-02-08 07:55:57.267081: Epoch 88
2024-02-08 07:55:57.267774: Current learning rate: 0.00855
2024-02-08 07:56:40.240611: train_loss -0.4755
2024-02-08 07:56:40.242268: val_loss -0.3717
2024-02-08 07:56:40.242790: Pseudo dice [0.8276, 0.8167, 0.7255, 0.8347, 0.8176]
2024-02-08 07:56:40.243256: Epoch time: 42.98 s
2024-02-08 07:56:40.243679: Yayy! New best EMA pseudo Dice: 0.8012
2024-02-08 07:56:41.571040: 
2024-02-08 07:56:41.572780: Epoch 89
2024-02-08 07:56:41.573412: Current learning rate: 0.00853
2024-02-08 07:57:24.531252: train_loss -0.4775
2024-02-08 07:57:24.532612: val_loss -0.3541
2024-02-08 07:57:24.533028: Pseudo dice [0.822, 0.8131, 0.7254, 0.8171, 0.8249]
2024-02-08 07:57:24.533437: Epoch time: 42.96 s
2024-02-08 07:57:25.513815: 
2024-02-08 07:57:25.514635: Epoch 90
2024-02-08 07:57:25.515193: Current learning rate: 0.00851
2024-02-08 07:58:08.544006: train_loss -0.4797
2024-02-08 07:58:08.545420: val_loss -0.3734
2024-02-08 07:58:08.545909: Pseudo dice [0.8233, 0.8176, 0.7241, 0.8235, 0.8186]
2024-02-08 07:58:08.546374: Epoch time: 43.03 s
2024-02-08 07:58:09.658265: 
2024-02-08 07:58:09.660023: Epoch 91
2024-02-08 07:58:09.660813: Current learning rate: 0.0085
2024-02-08 07:58:52.333110: train_loss -0.477
2024-02-08 07:58:52.334549: val_loss -0.3541
2024-02-08 07:58:52.335024: Pseudo dice [0.8258, 0.8184, 0.7186, 0.8127, 0.8131]
2024-02-08 07:58:52.335470: Epoch time: 42.68 s
2024-02-08 07:58:53.308361: 
2024-02-08 07:58:53.309309: Epoch 92
2024-02-08 07:58:53.309818: Current learning rate: 0.00848
2024-02-08 07:59:35.806443: train_loss -0.4856
2024-02-08 07:59:35.807793: val_loss -0.376
2024-02-08 07:59:35.808238: Pseudo dice [0.8291, 0.817, 0.7362, 0.8223, 0.8114]
2024-02-08 07:59:35.808675: Epoch time: 42.5 s
2024-02-08 07:59:36.790288: 
2024-02-08 07:59:36.791076: Epoch 93
2024-02-08 07:59:36.791616: Current learning rate: 0.00846
2024-02-08 08:00:19.455595: train_loss -0.4788
2024-02-08 08:00:19.456828: val_loss -0.3623
2024-02-08 08:00:19.457265: Pseudo dice [0.8223, 0.8224, 0.7277, 0.8221, 0.8153]
2024-02-08 08:00:19.457680: Epoch time: 42.67 s
2024-02-08 08:00:20.450306: 
2024-02-08 08:00:20.451075: Epoch 94
2024-02-08 08:00:20.452054: Current learning rate: 0.00845
2024-02-08 08:01:03.052998: train_loss -0.4801
2024-02-08 08:01:03.054372: val_loss -0.3829
2024-02-08 08:01:03.054826: Pseudo dice [0.8329, 0.8209, 0.7343, 0.8293, 0.8236]
2024-02-08 08:01:03.055243: Epoch time: 42.6 s
2024-02-08 08:01:03.055645: Yayy! New best EMA pseudo Dice: 0.8018
2024-02-08 08:01:04.333415: 
2024-02-08 08:01:04.335024: Epoch 95
2024-02-08 08:01:04.335517: Current learning rate: 0.00843
2024-02-08 08:01:47.101866: train_loss -0.4786
2024-02-08 08:01:47.103367: val_loss -0.3737
2024-02-08 08:01:47.103844: Pseudo dice [0.8328, 0.8224, 0.7236, 0.836, 0.8111]
2024-02-08 08:01:47.104264: Epoch time: 42.77 s
2024-02-08 08:01:47.104656: Yayy! New best EMA pseudo Dice: 0.8022
2024-02-08 08:01:48.519228: 
2024-02-08 08:01:48.520717: Epoch 96
2024-02-08 08:01:48.521243: Current learning rate: 0.00841
2024-02-08 08:02:31.210563: train_loss -0.4922
2024-02-08 08:02:31.211840: val_loss -0.3808
2024-02-08 08:02:31.212293: Pseudo dice [0.8346, 0.8196, 0.7386, 0.8372, 0.8146]
2024-02-08 08:02:31.212699: Epoch time: 42.69 s
2024-02-08 08:02:31.213259: Yayy! New best EMA pseudo Dice: 0.8028
2024-02-08 08:02:32.521472: 
2024-02-08 08:02:32.522694: Epoch 97
2024-02-08 08:02:32.523184: Current learning rate: 0.0084
2024-02-08 08:03:15.145649: train_loss -0.4894
2024-02-08 08:03:15.146962: val_loss -0.4048
2024-02-08 08:03:15.147442: Pseudo dice [0.834, 0.8316, 0.7379, 0.8349, 0.8207]
2024-02-08 08:03:15.147876: Epoch time: 42.63 s
2024-02-08 08:03:15.148349: Yayy! New best EMA pseudo Dice: 0.8037
2024-02-08 08:03:16.486848: 
2024-02-08 08:03:16.488293: Epoch 98
2024-02-08 08:03:16.488813: Current learning rate: 0.00838
2024-02-08 08:03:59.397154: train_loss -0.4875
2024-02-08 08:03:59.398538: val_loss -0.3756
2024-02-08 08:03:59.399020: Pseudo dice [0.829, 0.8238, 0.7279, 0.8243, 0.8118]
2024-02-08 08:03:59.399471: Epoch time: 42.91 s
2024-02-08 08:04:00.393447: 
2024-02-08 08:04:00.394141: Epoch 99
2024-02-08 08:04:00.394921: Current learning rate: 0.00836
2024-02-08 08:04:43.415746: train_loss -0.4986
2024-02-08 08:04:43.417040: val_loss -0.3593
2024-02-08 08:04:43.417687: Pseudo dice [0.8277, 0.8082, 0.7275, 0.8324, 0.822]
2024-02-08 08:04:43.418101: Epoch time: 43.02 s
2024-02-08 08:04:44.627750: 
2024-02-08 08:04:44.628952: Epoch 100
2024-02-08 08:04:44.629686: Current learning rate: 0.00835
2024-02-08 08:05:27.434528: train_loss -0.4939
2024-02-08 08:05:27.435776: val_loss -0.3712
2024-02-08 08:05:27.436227: Pseudo dice [0.8243, 0.8218, 0.7407, 0.8132, 0.8168]
2024-02-08 08:05:27.436669: Epoch time: 42.81 s
2024-02-08 08:05:28.438864: 
2024-02-08 08:05:28.440040: Epoch 101
2024-02-08 08:05:28.441366: Current learning rate: 0.00833
2024-02-08 08:06:11.379204: train_loss -0.4906
2024-02-08 08:06:11.380495: val_loss -0.3632
2024-02-08 08:06:11.380947: Pseudo dice [0.8288, 0.8247, 0.7214, 0.8119, 0.8018]
2024-02-08 08:06:11.381344: Epoch time: 42.94 s
2024-02-08 08:06:12.499256: 
2024-02-08 08:06:12.500957: Epoch 102
2024-02-08 08:06:12.501456: Current learning rate: 0.00831
2024-02-08 08:06:55.440149: train_loss -0.4926
2024-02-08 08:06:55.441386: val_loss -0.3655
2024-02-08 08:06:55.442014: Pseudo dice [0.8302, 0.82, 0.7196, 0.8315, 0.8175]
2024-02-08 08:06:55.442440: Epoch time: 42.94 s
2024-02-08 08:06:56.434540: 
2024-02-08 08:06:56.435270: Epoch 103
2024-02-08 08:06:56.435853: Current learning rate: 0.0083
2024-02-08 08:07:39.363140: train_loss -0.4943
2024-02-08 08:07:39.364410: val_loss -0.3582
2024-02-08 08:07:39.364850: Pseudo dice [0.8252, 0.8139, 0.7292, 0.8106, 0.8199]
2024-02-08 08:07:39.365267: Epoch time: 42.93 s
2024-02-08 08:07:40.352573: 
2024-02-08 08:07:40.353386: Epoch 104
2024-02-08 08:07:40.354046: Current learning rate: 0.00828
2024-02-08 08:08:23.137392: train_loss -0.4911
2024-02-08 08:08:23.139015: val_loss -0.3467
2024-02-08 08:08:23.139506: Pseudo dice [0.8221, 0.8118, 0.7237, 0.825, 0.8159]
2024-02-08 08:08:23.140594: Epoch time: 42.79 s
2024-02-08 08:08:24.140671: 
2024-02-08 08:08:24.142228: Epoch 105
2024-02-08 08:08:24.142711: Current learning rate: 0.00826
2024-02-08 08:09:06.902642: train_loss -0.4968
2024-02-08 08:09:06.904171: val_loss -0.3605
2024-02-08 08:09:06.904698: Pseudo dice [0.8252, 0.8223, 0.7318, 0.8212, 0.826]
2024-02-08 08:09:06.905175: Epoch time: 42.76 s
2024-02-08 08:09:07.906212: 
2024-02-08 08:09:07.907733: Epoch 106
2024-02-08 08:09:07.908473: Current learning rate: 0.00825
2024-02-08 08:09:50.609574: train_loss -0.4913
2024-02-08 08:09:50.611260: val_loss -0.3791
2024-02-08 08:09:50.611759: Pseudo dice [0.8257, 0.8226, 0.7312, 0.8259, 0.8285]
2024-02-08 08:09:50.612205: Epoch time: 42.7 s
2024-02-08 08:09:51.901688: 
2024-02-08 08:09:51.903146: Epoch 107
2024-02-08 08:09:51.903791: Current learning rate: 0.00823
2024-02-08 08:10:34.726553: train_loss -0.4989
2024-02-08 08:10:34.729121: val_loss -0.377
2024-02-08 08:10:34.729704: Pseudo dice [0.8321, 0.8207, 0.7365, 0.8233, 0.8115]
2024-02-08 08:10:34.730247: Epoch time: 42.83 s
2024-02-08 08:10:35.735207: 
2024-02-08 08:10:35.736785: Epoch 108
2024-02-08 08:10:35.737325: Current learning rate: 0.00821
2024-02-08 08:11:18.778638: train_loss -0.4985
2024-02-08 08:11:18.780456: val_loss -0.362
2024-02-08 08:11:18.781172: Pseudo dice [0.8313, 0.8184, 0.7291, 0.8307, 0.8206]
2024-02-08 08:11:18.781658: Epoch time: 43.04 s
2024-02-08 08:11:19.781078: 
2024-02-08 08:11:19.782645: Epoch 109
2024-02-08 08:11:19.783914: Current learning rate: 0.0082
2024-02-08 08:12:02.298734: train_loss -0.5006
2024-02-08 08:12:02.300180: val_loss -0.3505
2024-02-08 08:12:02.300617: Pseudo dice [0.8288, 0.8129, 0.7178, 0.8061, 0.8165]
2024-02-08 08:12:02.301055: Epoch time: 42.52 s
2024-02-08 08:12:03.367938: 
2024-02-08 08:12:03.369597: Epoch 110
2024-02-08 08:12:03.370327: Current learning rate: 0.00818
2024-02-08 08:12:46.152907: train_loss -0.5005
2024-02-08 08:12:46.154247: val_loss -0.3607
2024-02-08 08:12:46.154679: Pseudo dice [0.8293, 0.8181, 0.7289, 0.8154, 0.8159]
2024-02-08 08:12:46.155095: Epoch time: 42.79 s
2024-02-08 08:12:47.196874: 
2024-02-08 08:12:47.198156: Epoch 111
2024-02-08 08:12:47.199416: Current learning rate: 0.00816
2024-02-08 08:13:30.017685: train_loss -0.5052
2024-02-08 08:13:30.019269: val_loss -0.3705
2024-02-08 08:13:30.019823: Pseudo dice [0.8291, 0.8171, 0.7282, 0.8232, 0.8255]
2024-02-08 08:13:30.020267: Epoch time: 42.82 s
2024-02-08 08:13:31.055738: 
2024-02-08 08:13:31.056944: Epoch 112
2024-02-08 08:13:31.058965: Current learning rate: 0.00815
2024-02-08 08:14:14.140028: train_loss -0.506
2024-02-08 08:14:14.141299: val_loss -0.3963
2024-02-08 08:14:14.141757: Pseudo dice [0.8387, 0.8235, 0.734, 0.833, 0.8271]
2024-02-08 08:14:14.142541: Epoch time: 43.09 s
2024-02-08 08:14:14.143061: Yayy! New best EMA pseudo Dice: 0.8038
2024-02-08 08:14:15.599990: 
2024-02-08 08:14:15.601673: Epoch 113
2024-02-08 08:14:15.602178: Current learning rate: 0.00813
2024-02-08 08:14:58.460619: train_loss -0.5077
2024-02-08 08:14:58.462093: val_loss -0.3935
2024-02-08 08:14:58.462566: Pseudo dice [0.8322, 0.8226, 0.7401, 0.8309, 0.8224]
2024-02-08 08:14:58.462988: Epoch time: 42.86 s
2024-02-08 08:14:58.463391: Yayy! New best EMA pseudo Dice: 0.8044
2024-02-08 08:14:59.760962: 
2024-02-08 08:14:59.762308: Epoch 114
2024-02-08 08:14:59.763505: Current learning rate: 0.00811
2024-02-08 08:15:42.546246: train_loss -0.5137
2024-02-08 08:15:42.547716: val_loss -0.3499
2024-02-08 08:15:42.548169: Pseudo dice [0.8253, 0.8181, 0.7258, 0.8247, 0.8113]
2024-02-08 08:15:42.548609: Epoch time: 42.79 s
2024-02-08 08:15:43.560129: 
2024-02-08 08:15:43.561064: Epoch 115
2024-02-08 08:15:43.561836: Current learning rate: 0.0081
2024-02-08 08:16:26.623500: train_loss -0.5093
2024-02-08 08:16:26.625049: val_loss -0.3713
2024-02-08 08:16:26.625567: Pseudo dice [0.8307, 0.8172, 0.7283, 0.8085, 0.8263]
2024-02-08 08:16:26.626017: Epoch time: 43.06 s
2024-02-08 08:16:27.678684: 
2024-02-08 08:16:27.680092: Epoch 116
2024-02-08 08:16:27.681725: Current learning rate: 0.00808
2024-02-08 08:17:10.704322: train_loss -0.5087
2024-02-08 08:17:10.705719: val_loss -0.3604
2024-02-08 08:17:10.706192: Pseudo dice [0.8284, 0.8143, 0.7316, 0.8232, 0.818]
2024-02-08 08:17:10.706633: Epoch time: 43.03 s
2024-02-08 08:17:11.737350: 
2024-02-08 08:17:11.738907: Epoch 117
2024-02-08 08:17:11.739434: Current learning rate: 0.00806
2024-02-08 08:17:54.893611: train_loss -0.5154
2024-02-08 08:17:54.895006: val_loss -0.3775
2024-02-08 08:17:54.895472: Pseudo dice [0.8258, 0.8165, 0.7351, 0.824, 0.8345]
2024-02-08 08:17:54.895900: Epoch time: 43.16 s
2024-02-08 08:17:56.181232: 
2024-02-08 08:17:56.182854: Epoch 118
2024-02-08 08:17:56.183615: Current learning rate: 0.00805
2024-02-08 08:18:39.380755: train_loss -0.5065
2024-02-08 08:18:39.382904: val_loss -0.3448
2024-02-08 08:18:39.383762: Pseudo dice [0.8251, 0.8177, 0.7307, 0.8012, 0.8037]
2024-02-08 08:18:39.384343: Epoch time: 43.2 s
2024-02-08 08:18:40.431088: 
2024-02-08 08:18:40.432156: Epoch 119
2024-02-08 08:18:40.433037: Current learning rate: 0.00803
2024-02-08 08:19:23.692180: train_loss -0.5054
2024-02-08 08:19:23.693887: val_loss -0.3826
2024-02-08 08:19:23.694412: Pseudo dice [0.8288, 0.8161, 0.7373, 0.8287, 0.8198]
2024-02-08 08:19:23.694867: Epoch time: 43.26 s
2024-02-08 08:19:24.752133: 
2024-02-08 08:19:24.754058: Epoch 120
2024-02-08 08:19:24.755039: Current learning rate: 0.00801
2024-02-08 08:20:08.202140: train_loss -0.5031
2024-02-08 08:20:08.203748: val_loss -0.3749
2024-02-08 08:20:08.204272: Pseudo dice [0.828, 0.8225, 0.7418, 0.8332, 0.8237]
2024-02-08 08:20:08.204753: Epoch time: 43.45 s
2024-02-08 08:20:09.230649: 
2024-02-08 08:20:09.232218: Epoch 121
2024-02-08 08:20:09.232880: Current learning rate: 0.008
2024-02-08 08:20:52.400284: train_loss -0.5092
2024-02-08 08:20:52.401640: val_loss -0.3832
2024-02-08 08:20:52.402099: Pseudo dice [0.8292, 0.8265, 0.7381, 0.8353, 0.8123]
2024-02-08 08:20:52.402748: Epoch time: 43.17 s
2024-02-08 08:20:52.403192: Yayy! New best EMA pseudo Dice: 0.8046
2024-02-08 08:20:53.772496: 
2024-02-08 08:20:53.774428: Epoch 122
2024-02-08 08:20:53.775099: Current learning rate: 0.00798
2024-02-08 08:21:36.772346: train_loss -0.5041
2024-02-08 08:21:36.773858: val_loss -0.3992
2024-02-08 08:21:36.774349: Pseudo dice [0.8358, 0.8203, 0.7441, 0.8362, 0.8318]
2024-02-08 08:21:36.774818: Epoch time: 43.0 s
2024-02-08 08:21:36.775798: Yayy! New best EMA pseudo Dice: 0.8055
2024-02-08 08:21:38.297659: 
2024-02-08 08:21:38.299201: Epoch 123
2024-02-08 08:21:38.299723: Current learning rate: 0.00796
2024-02-08 08:22:21.169569: train_loss -0.5106
2024-02-08 08:22:21.171656: val_loss -0.3783
2024-02-08 08:22:21.172139: Pseudo dice [0.8415, 0.8208, 0.7331, 0.8269, 0.827]
2024-02-08 08:22:21.172573: Epoch time: 42.87 s
2024-02-08 08:22:21.172979: Yayy! New best EMA pseudo Dice: 0.8059
2024-02-08 08:22:22.562573: 
2024-02-08 08:22:22.564764: Epoch 124
2024-02-08 08:22:22.565607: Current learning rate: 0.00795
2024-02-08 08:23:05.894595: train_loss -0.5077
2024-02-08 08:23:05.896273: val_loss -0.3718
2024-02-08 08:23:05.896833: Pseudo dice [0.8265, 0.8177, 0.7319, 0.8301, 0.8175]
2024-02-08 08:23:05.897316: Epoch time: 43.34 s
2024-02-08 08:23:06.935347: 
2024-02-08 08:23:06.936539: Epoch 125
2024-02-08 08:23:06.937434: Current learning rate: 0.00793
2024-02-08 08:23:50.002095: train_loss -0.5062
2024-02-08 08:23:50.003468: val_loss -0.347
2024-02-08 08:23:50.003966: Pseudo dice [0.8234, 0.8132, 0.7249, 0.817, 0.8057]
2024-02-08 08:23:50.004470: Epoch time: 43.07 s
2024-02-08 08:23:51.044523: 
2024-02-08 08:23:51.046231: Epoch 126
2024-02-08 08:23:51.046830: Current learning rate: 0.00791
2024-02-08 08:24:34.019016: train_loss -0.4948
2024-02-08 08:24:34.020426: val_loss -0.3554
2024-02-08 08:24:34.021014: Pseudo dice [0.8283, 0.8133, 0.7311, 0.8229, 0.8243]
2024-02-08 08:24:34.021597: Epoch time: 42.98 s
2024-02-08 08:24:35.033664: 
2024-02-08 08:24:35.034878: Epoch 127
2024-02-08 08:24:35.035824: Current learning rate: 0.0079
2024-02-08 08:25:17.857083: train_loss -0.5098
2024-02-08 08:25:17.858516: val_loss -0.3872
2024-02-08 08:25:17.858993: Pseudo dice [0.8374, 0.8205, 0.7355, 0.8327, 0.8282]
2024-02-08 08:25:17.859521: Epoch time: 42.82 s
2024-02-08 08:25:18.883233: 
2024-02-08 08:25:18.884760: Epoch 128
2024-02-08 08:25:18.886136: Current learning rate: 0.00788
2024-02-08 08:26:01.560428: train_loss -0.5175
2024-02-08 08:26:01.562398: val_loss -0.3726
2024-02-08 08:26:01.562965: Pseudo dice [0.8327, 0.8205, 0.7343, 0.8166, 0.825]
2024-02-08 08:26:01.563521: Epoch time: 42.68 s
2024-02-08 08:26:02.856194: 
2024-02-08 08:26:02.857913: Epoch 129
2024-02-08 08:26:02.858524: Current learning rate: 0.00786
2024-02-08 08:26:45.757250: train_loss -0.5144
2024-02-08 08:26:45.758667: val_loss -0.4069
2024-02-08 08:26:45.759178: Pseudo dice [0.8376, 0.8338, 0.7363, 0.8367, 0.8195]
2024-02-08 08:26:45.759638: Epoch time: 42.9 s
2024-02-08 08:26:45.760097: Yayy! New best EMA pseudo Dice: 0.8062
2024-02-08 08:26:47.081133: 
2024-02-08 08:26:47.082987: Epoch 130
2024-02-08 08:26:47.083542: Current learning rate: 0.00785
2024-02-08 08:27:30.074179: train_loss -0.5199
2024-02-08 08:27:30.075966: val_loss -0.3652
2024-02-08 08:27:30.076495: Pseudo dice [0.8234, 0.8229, 0.7371, 0.8005, 0.8333]
2024-02-08 08:27:30.076935: Epoch time: 42.99 s
2024-02-08 08:27:31.101198: 
2024-02-08 08:27:31.102201: Epoch 131
2024-02-08 08:27:31.103304: Current learning rate: 0.00783
2024-02-08 08:28:14.265823: train_loss -0.5215
2024-02-08 08:28:14.268466: val_loss -0.3705
2024-02-08 08:28:14.269167: Pseudo dice [0.8338, 0.8137, 0.7275, 0.8184, 0.8244]
2024-02-08 08:28:14.269735: Epoch time: 43.17 s
2024-02-08 08:28:15.311798: 
2024-02-08 08:28:15.314431: Epoch 132
2024-02-08 08:28:15.315387: Current learning rate: 0.00781
2024-02-08 08:28:58.225195: train_loss -0.5174
2024-02-08 08:28:58.226832: val_loss -0.3658
2024-02-08 08:28:58.227417: Pseudo dice [0.8265, 0.8221, 0.7325, 0.8256, 0.8226]
2024-02-08 08:28:58.227884: Epoch time: 42.92 s
2024-02-08 08:28:59.265113: 
2024-02-08 08:28:59.267267: Epoch 133
2024-02-08 08:28:59.268707: Current learning rate: 0.00779
2024-02-08 08:29:42.142903: train_loss -0.5148
2024-02-08 08:29:42.144486: val_loss -0.3716
2024-02-08 08:29:42.145004: Pseudo dice [0.8344, 0.8196, 0.7281, 0.8227, 0.8202]
2024-02-08 08:29:42.145458: Epoch time: 42.88 s
2024-02-08 08:29:43.349174: 
2024-02-08 08:29:43.350824: Epoch 134
2024-02-08 08:29:43.351435: Current learning rate: 0.00778
2024-02-08 08:30:26.168984: train_loss -0.5181
2024-02-08 08:30:26.170410: val_loss -0.3683
2024-02-08 08:30:26.170884: Pseudo dice [0.8338, 0.8226, 0.729, 0.8283, 0.8181]
2024-02-08 08:30:26.171359: Epoch time: 42.82 s
2024-02-08 08:30:27.190990: 
2024-02-08 08:30:27.192700: Epoch 135
2024-02-08 08:30:27.193214: Current learning rate: 0.00776
2024-02-08 08:31:09.838864: train_loss -0.5159
2024-02-08 08:31:09.840159: val_loss -0.3669
2024-02-08 08:31:09.840624: Pseudo dice [0.8305, 0.8216, 0.7305, 0.8316, 0.8036]
2024-02-08 08:31:09.841048: Epoch time: 42.65 s
2024-02-08 08:31:10.881292: 
2024-02-08 08:31:10.882502: Epoch 136
2024-02-08 08:31:10.883758: Current learning rate: 0.00774
2024-02-08 08:31:53.686673: train_loss -0.5219
2024-02-08 08:31:53.688383: val_loss -0.3693
2024-02-08 08:31:53.688889: Pseudo dice [0.8295, 0.8256, 0.7394, 0.8061, 0.8129]
2024-02-08 08:31:53.689337: Epoch time: 42.81 s
2024-02-08 08:31:54.714636: 
2024-02-08 08:31:54.715723: Epoch 137
2024-02-08 08:31:54.716909: Current learning rate: 0.00773
2024-02-08 08:32:37.542501: train_loss -0.5278
2024-02-08 08:32:37.543982: val_loss -0.3927
2024-02-08 08:32:37.545031: Pseudo dice [0.8346, 0.8289, 0.7365, 0.8333, 0.8222]
2024-02-08 08:32:37.545532: Epoch time: 42.83 s
2024-02-08 08:32:38.574152: 
2024-02-08 08:32:38.575185: Epoch 138
2024-02-08 08:32:38.576092: Current learning rate: 0.00771
2024-02-08 08:33:21.561458: train_loss -0.5244
2024-02-08 08:33:21.562855: val_loss -0.3601
2024-02-08 08:33:21.563361: Pseudo dice [0.8263, 0.8175, 0.7294, 0.8376, 0.8151]
2024-02-08 08:33:21.563793: Epoch time: 42.99 s
2024-02-08 08:33:22.603200: 
2024-02-08 08:33:22.604517: Epoch 139
2024-02-08 08:33:22.605598: Current learning rate: 0.00769
2024-02-08 08:34:05.728875: train_loss -0.5185
2024-02-08 08:34:05.730532: val_loss -0.3643
2024-02-08 08:34:05.731178: Pseudo dice [0.8342, 0.8217, 0.7299, 0.821, 0.8079]
2024-02-08 08:34:05.731765: Epoch time: 43.13 s
2024-02-08 08:34:06.973682: 
2024-02-08 08:34:06.975295: Epoch 140
2024-02-08 08:34:06.976210: Current learning rate: 0.00768
2024-02-08 08:34:49.528969: train_loss -0.518
2024-02-08 08:34:49.530440: val_loss -0.3614
2024-02-08 08:34:49.530910: Pseudo dice [0.8324, 0.8144, 0.7269, 0.8177, 0.8199]
2024-02-08 08:34:49.531421: Epoch time: 42.56 s
2024-02-08 08:34:50.547463: 
2024-02-08 08:34:50.548440: Epoch 141
2024-02-08 08:34:50.549375: Current learning rate: 0.00766
2024-02-08 08:35:33.162983: train_loss -0.5247
2024-02-08 08:35:33.164437: val_loss -0.366
2024-02-08 08:35:33.164922: Pseudo dice [0.8324, 0.818, 0.728, 0.8205, 0.8258]
2024-02-08 08:35:33.165356: Epoch time: 42.62 s
2024-02-08 08:35:34.209752: 
2024-02-08 08:35:34.210763: Epoch 142
2024-02-08 08:35:34.211708: Current learning rate: 0.00764
2024-02-08 08:36:17.153568: train_loss -0.5228
2024-02-08 08:36:17.154971: val_loss -0.3668
2024-02-08 08:36:17.155463: Pseudo dice [0.8315, 0.8147, 0.7272, 0.8048, 0.8234]
2024-02-08 08:36:17.155919: Epoch time: 42.94 s
2024-02-08 08:36:18.197689: 
2024-02-08 08:36:18.199359: Epoch 143
2024-02-08 08:36:18.200170: Current learning rate: 0.00763
2024-02-08 08:37:01.285365: train_loss -0.528
2024-02-08 08:37:01.286711: val_loss -0.3931
2024-02-08 08:37:01.287169: Pseudo dice [0.837, 0.8239, 0.7443, 0.8318, 0.8297]
2024-02-08 08:37:01.287591: Epoch time: 43.09 s
2024-02-08 08:37:02.328485: 
2024-02-08 08:37:02.329549: Epoch 144
2024-02-08 08:37:02.330491: Current learning rate: 0.00761
2024-02-08 08:37:45.462460: train_loss -0.527
2024-02-08 08:37:45.463817: val_loss -0.3671
2024-02-08 08:37:45.464293: Pseudo dice [0.833, 0.8205, 0.7303, 0.8234, 0.8173]
2024-02-08 08:37:45.464710: Epoch time: 43.14 s
2024-02-08 08:37:46.621406: 
2024-02-08 08:37:46.623047: Epoch 145
2024-02-08 08:37:46.623626: Current learning rate: 0.00759
2024-02-08 08:38:29.721675: train_loss -0.522
2024-02-08 08:38:29.723142: val_loss -0.3673
2024-02-08 08:38:29.723628: Pseudo dice [0.8311, 0.8241, 0.7328, 0.8187, 0.8144]
2024-02-08 08:38:29.724088: Epoch time: 43.1 s
2024-02-08 08:38:30.742462: 
2024-02-08 08:38:30.743950: Epoch 146
2024-02-08 08:38:30.744516: Current learning rate: 0.00758
2024-02-08 08:39:13.633169: train_loss -0.5216
2024-02-08 08:39:13.634554: val_loss -0.3562
2024-02-08 08:39:13.635003: Pseudo dice [0.8258, 0.8201, 0.7223, 0.8185, 0.8248]
2024-02-08 08:39:13.635462: Epoch time: 42.89 s
2024-02-08 08:39:14.659476: 
2024-02-08 08:39:14.661074: Epoch 147
2024-02-08 08:39:14.661616: Current learning rate: 0.00756
2024-02-08 08:39:57.774926: train_loss -0.524
2024-02-08 08:39:57.776578: val_loss -0.3769
2024-02-08 08:39:57.777171: Pseudo dice [0.8301, 0.8253, 0.7349, 0.8206, 0.8238]
2024-02-08 08:39:57.777604: Epoch time: 43.12 s
2024-02-08 08:39:58.856934: 
2024-02-08 08:39:58.858642: Epoch 148
2024-02-08 08:39:58.860527: Current learning rate: 0.00754
2024-02-08 08:40:41.908891: train_loss -0.5263
2024-02-08 08:40:41.911348: val_loss -0.3988
2024-02-08 08:40:41.911829: Pseudo dice [0.8393, 0.824, 0.7378, 0.8368, 0.8323]
2024-02-08 08:40:41.912610: Epoch time: 43.05 s
2024-02-08 08:40:42.957631: 
2024-02-08 08:40:42.958562: Epoch 149
2024-02-08 08:40:42.959554: Current learning rate: 0.00752
2024-02-08 08:41:25.919296: train_loss -0.5298
2024-02-08 08:41:25.921408: val_loss -0.4086
2024-02-08 08:41:25.921932: Pseudo dice [0.8423, 0.8256, 0.7452, 0.8375, 0.8301]
2024-02-08 08:41:25.922404: Epoch time: 42.96 s
2024-02-08 08:41:26.187788: Yayy! New best EMA pseudo Dice: 0.8071
2024-02-08 08:41:27.662335: 
2024-02-08 08:41:27.663387: Epoch 150
2024-02-08 08:41:27.663939: Current learning rate: 0.00751
2024-02-08 08:42:10.748983: train_loss -0.533
2024-02-08 08:42:10.750550: val_loss -0.3654
2024-02-08 08:42:10.751022: Pseudo dice [0.8325, 0.8203, 0.7301, 0.8254, 0.8184]
2024-02-08 08:42:10.751507: Epoch time: 43.09 s
2024-02-08 08:42:11.796961: 
2024-02-08 08:42:11.798410: Epoch 151
2024-02-08 08:42:11.798921: Current learning rate: 0.00749
2024-02-08 08:42:54.712113: train_loss -0.5388
2024-02-08 08:42:54.713463: val_loss -0.3481
2024-02-08 08:42:54.713968: Pseudo dice [0.8245, 0.8141, 0.7284, 0.8075, 0.8241]
2024-02-08 08:42:54.714433: Epoch time: 42.92 s
2024-02-08 08:42:55.764637: 
2024-02-08 08:42:55.765715: Epoch 152
2024-02-08 08:42:55.766629: Current learning rate: 0.00747
2024-02-08 08:43:38.822804: train_loss -0.5375
2024-02-08 08:43:38.824197: val_loss -0.3902
2024-02-08 08:43:38.824711: Pseudo dice [0.8382, 0.8176, 0.7383, 0.8362, 0.8257]
2024-02-08 08:43:38.825126: Epoch time: 43.06 s
2024-02-08 08:43:39.876352: 
2024-02-08 08:43:39.878089: Epoch 153
2024-02-08 08:43:39.878656: Current learning rate: 0.00746
2024-02-08 08:44:22.995196: train_loss -0.5298
2024-02-08 08:44:22.996557: val_loss -0.3577
2024-02-08 08:44:22.997024: Pseudo dice [0.8266, 0.8206, 0.723, 0.8169, 0.814]
2024-02-08 08:44:22.997442: Epoch time: 43.12 s
2024-02-08 08:44:24.105193: 
2024-02-08 08:44:24.106961: Epoch 154
2024-02-08 08:44:24.107608: Current learning rate: 0.00744
2024-02-08 08:45:07.031952: train_loss -0.5409
2024-02-08 08:45:07.033326: val_loss -0.3638
2024-02-08 08:45:07.033775: Pseudo dice [0.8307, 0.8192, 0.7316, 0.8271, 0.8165]
2024-02-08 08:45:07.034194: Epoch time: 42.93 s
2024-02-08 08:45:08.076424: 
2024-02-08 08:45:08.077852: Epoch 155
2024-02-08 08:45:08.078333: Current learning rate: 0.00742
2024-02-08 08:45:51.375338: train_loss -0.5406
2024-02-08 08:45:51.376854: val_loss -0.385
2024-02-08 08:45:51.377322: Pseudo dice [0.8335, 0.8246, 0.7375, 0.8431, 0.8103]
2024-02-08 08:45:51.377784: Epoch time: 43.3 s
2024-02-08 08:45:52.593376: 
2024-02-08 08:45:52.595068: Epoch 156
2024-02-08 08:45:52.595625: Current learning rate: 0.00741
2024-02-08 08:46:35.952253: train_loss -0.5414
2024-02-08 08:46:35.955312: val_loss -0.3797
2024-02-08 08:46:35.955796: Pseudo dice [0.8342, 0.8199, 0.7293, 0.8215, 0.8239]
2024-02-08 08:46:35.956217: Epoch time: 43.36 s
2024-02-08 08:46:37.011817: 
2024-02-08 08:46:37.012714: Epoch 157
2024-02-08 08:46:37.013527: Current learning rate: 0.00739
2024-02-08 08:47:19.745694: train_loss -0.5313
2024-02-08 08:47:19.747543: val_loss -0.3685
2024-02-08 08:47:19.748050: Pseudo dice [0.8335, 0.8213, 0.7325, 0.8159, 0.8243]
2024-02-08 08:47:19.748481: Epoch time: 42.73 s
2024-02-08 08:47:20.807408: 
2024-02-08 08:47:20.808466: Epoch 158
2024-02-08 08:47:20.809319: Current learning rate: 0.00737
2024-02-08 08:48:03.734404: train_loss -0.5369
2024-02-08 08:48:03.736403: val_loss -0.3745
2024-02-08 08:48:03.736936: Pseudo dice [0.8363, 0.8165, 0.7367, 0.8145, 0.8322]
2024-02-08 08:48:03.737460: Epoch time: 42.93 s
2024-02-08 08:48:04.863596: 
2024-02-08 08:48:04.865889: Epoch 159
2024-02-08 08:48:04.866548: Current learning rate: 0.00736
2024-02-08 08:48:47.939535: train_loss -0.5366
2024-02-08 08:48:47.941018: val_loss -0.3812
2024-02-08 08:48:47.941514: Pseudo dice [0.8365, 0.8211, 0.7301, 0.8245, 0.8216]
2024-02-08 08:48:47.941979: Epoch time: 43.08 s
2024-02-08 08:48:49.044989: 
2024-02-08 08:48:49.046184: Epoch 160
2024-02-08 08:48:49.047452: Current learning rate: 0.00734
2024-02-08 08:49:31.806739: train_loss -0.5406
2024-02-08 08:49:31.808306: val_loss -0.3774
2024-02-08 08:49:31.808838: Pseudo dice [0.8357, 0.8234, 0.733, 0.8338, 0.8284]
2024-02-08 08:49:31.809272: Epoch time: 42.76 s
2024-02-08 08:49:33.020629: 
2024-02-08 08:49:33.022248: Epoch 161
2024-02-08 08:49:33.022746: Current learning rate: 0.00732
2024-02-08 08:50:15.930097: train_loss -0.5446
2024-02-08 08:50:15.931523: val_loss -0.3646
2024-02-08 08:50:15.932001: Pseudo dice [0.8277, 0.8206, 0.7315, 0.8259, 0.8054]
2024-02-08 08:50:15.932438: Epoch time: 42.91 s
2024-02-08 08:50:16.986421: 
2024-02-08 08:50:16.987317: Epoch 162
2024-02-08 08:50:16.988114: Current learning rate: 0.00731
2024-02-08 08:50:59.697685: train_loss -0.5336
2024-02-08 08:50:59.699554: val_loss -0.3712
2024-02-08 08:50:59.700076: Pseudo dice [0.8328, 0.8165, 0.7311, 0.8248, 0.8271]
2024-02-08 08:50:59.700556: Epoch time: 42.71 s
2024-02-08 08:51:00.753605: 
2024-02-08 08:51:00.754622: Epoch 163
2024-02-08 08:51:00.755677: Current learning rate: 0.00729
2024-02-08 08:51:43.456287: train_loss -0.5401
2024-02-08 08:51:43.457663: val_loss -0.3689
2024-02-08 08:51:43.458117: Pseudo dice [0.836, 0.8172, 0.7444, 0.8394, 0.8091]
2024-02-08 08:51:43.458535: Epoch time: 42.7 s
2024-02-08 08:51:44.500392: 
2024-02-08 08:51:44.502469: Epoch 164
2024-02-08 08:51:44.503034: Current learning rate: 0.00727
2024-02-08 08:52:27.472138: train_loss -0.5377
2024-02-08 08:52:27.473528: val_loss -0.3807
2024-02-08 08:52:27.474013: Pseudo dice [0.8348, 0.8247, 0.7311, 0.8327, 0.8258]
2024-02-08 08:52:27.474472: Epoch time: 42.97 s
2024-02-08 08:52:28.501468: 
2024-02-08 08:52:28.502702: Epoch 165
2024-02-08 08:52:28.503866: Current learning rate: 0.00725
2024-02-08 08:53:11.230484: train_loss -0.54
2024-02-08 08:53:11.231725: val_loss -0.3567
2024-02-08 08:53:11.232161: Pseudo dice [0.8264, 0.8174, 0.7265, 0.8259, 0.817]
2024-02-08 08:53:11.232601: Epoch time: 42.73 s
2024-02-08 08:53:12.243541: 
2024-02-08 08:53:12.244408: Epoch 166
2024-02-08 08:53:12.245417: Current learning rate: 0.00724
2024-02-08 08:53:54.777393: train_loss -0.5387
2024-02-08 08:53:54.778795: val_loss -0.3487
2024-02-08 08:53:54.779293: Pseudo dice [0.8313, 0.82, 0.7269, 0.8191, 0.8173]
2024-02-08 08:53:54.779749: Epoch time: 42.53 s
2024-02-08 08:53:55.929261: 
2024-02-08 08:53:55.930530: Epoch 167
2024-02-08 08:53:55.931377: Current learning rate: 0.00722
2024-02-08 08:54:38.551558: train_loss -0.5374
2024-02-08 08:54:38.552959: val_loss -0.3704
2024-02-08 08:54:38.553428: Pseudo dice [0.8322, 0.8144, 0.7337, 0.8303, 0.8342]
2024-02-08 08:54:38.553857: Epoch time: 42.62 s
2024-02-08 08:54:39.622833: 
2024-02-08 08:54:39.624959: Epoch 168
2024-02-08 08:54:39.626435: Current learning rate: 0.0072
2024-02-08 08:55:22.903491: train_loss -0.5415
2024-02-08 08:55:22.904942: val_loss -0.3587
2024-02-08 08:55:22.905472: Pseudo dice [0.8349, 0.8143, 0.7267, 0.8253, 0.8287]
2024-02-08 08:55:22.905910: Epoch time: 43.28 s
2024-02-08 08:55:23.937901: 
2024-02-08 08:55:23.939482: Epoch 169
2024-02-08 08:55:23.940019: Current learning rate: 0.00719
2024-02-08 08:56:06.869549: train_loss -0.5446
2024-02-08 08:56:06.870978: val_loss -0.3285
2024-02-08 08:56:06.871464: Pseudo dice [0.8262, 0.8113, 0.7291, 0.805, 0.8135]
2024-02-08 08:56:06.871900: Epoch time: 42.93 s
2024-02-08 08:56:07.926351: 
2024-02-08 08:56:07.927881: Epoch 170
2024-02-08 08:56:07.928427: Current learning rate: 0.00717
2024-02-08 08:56:50.990785: train_loss -0.5379
2024-02-08 08:56:50.992505: val_loss -0.3845
2024-02-08 08:56:50.993013: Pseudo dice [0.8332, 0.8251, 0.7377, 0.81, 0.8344]
2024-02-08 08:56:50.993492: Epoch time: 43.07 s
2024-02-08 08:56:52.078146: 
2024-02-08 08:56:52.079800: Epoch 171
2024-02-08 08:56:52.080323: Current learning rate: 0.00715
2024-02-08 08:57:34.776046: train_loss -0.5462
2024-02-08 08:57:34.777534: val_loss -0.3671
2024-02-08 08:57:34.778028: Pseudo dice [0.8328, 0.8183, 0.7305, 0.8356, 0.8143]
2024-02-08 08:57:34.778484: Epoch time: 42.7 s
2024-02-08 08:57:36.108675: 
2024-02-08 08:57:36.110394: Epoch 172
2024-02-08 08:57:36.111073: Current learning rate: 0.00714
2024-02-08 08:58:19.178686: train_loss -0.5428
2024-02-08 08:58:19.180099: val_loss -0.3706
2024-02-08 08:58:19.180590: Pseudo dice [0.8311, 0.8215, 0.7351, 0.8301, 0.8226]
2024-02-08 08:58:19.181016: Epoch time: 43.07 s
2024-02-08 08:58:20.237790: 
2024-02-08 08:58:20.239143: Epoch 173
2024-02-08 08:58:20.240412: Current learning rate: 0.00712
2024-02-08 08:59:03.060419: train_loss -0.5473
2024-02-08 08:59:03.061731: val_loss -0.3552
2024-02-08 08:59:03.062358: Pseudo dice [0.8311, 0.8198, 0.7305, 0.8217, 0.8223]
2024-02-08 08:59:03.062766: Epoch time: 42.82 s
2024-02-08 08:59:04.149025: 
2024-02-08 08:59:04.150903: Epoch 174
2024-02-08 08:59:04.151604: Current learning rate: 0.0071
2024-02-08 08:59:47.032202: train_loss -0.5481
2024-02-08 08:59:47.033945: val_loss -0.3821
2024-02-08 08:59:47.034477: Pseudo dice [0.8327, 0.8318, 0.7333, 0.8168, 0.8266]
2024-02-08 08:59:47.034956: Epoch time: 42.88 s
2024-02-08 08:59:48.120444: 
2024-02-08 08:59:48.122075: Epoch 175
2024-02-08 08:59:48.122694: Current learning rate: 0.00708
2024-02-08 09:00:31.368312: train_loss -0.5429
2024-02-08 09:00:31.370287: val_loss -0.3213
2024-02-08 09:00:31.370810: Pseudo dice [0.8239, 0.8177, 0.715, 0.8203, 0.8033]
2024-02-08 09:00:31.371243: Epoch time: 43.25 s
2024-02-08 09:00:32.472566: 
2024-02-08 09:00:32.473599: Epoch 176
2024-02-08 09:00:32.474460: Current learning rate: 0.00707
2024-02-08 09:01:15.560966: train_loss -0.5447
2024-02-08 09:01:15.562410: val_loss -0.3597
2024-02-08 09:01:15.562853: Pseudo dice [0.829, 0.8248, 0.7315, 0.8138, 0.8242]
2024-02-08 09:01:15.563318: Epoch time: 43.09 s
2024-02-08 09:01:16.935893: 
2024-02-08 09:01:16.936857: Epoch 177
2024-02-08 09:01:16.937999: Current learning rate: 0.00705
2024-02-08 09:01:59.762240: train_loss -0.5408
2024-02-08 09:01:59.763638: val_loss -0.3907
2024-02-08 09:01:59.764096: Pseudo dice [0.8386, 0.8271, 0.7355, 0.8366, 0.8265]
2024-02-08 09:01:59.764533: Epoch time: 42.83 s
2024-02-08 09:02:00.825468: 
2024-02-08 09:02:00.826568: Epoch 178
2024-02-08 09:02:00.827658: Current learning rate: 0.00703
2024-02-08 09:02:43.688385: train_loss -0.5487
2024-02-08 09:02:43.689827: val_loss -0.3648
2024-02-08 09:02:43.690301: Pseudo dice [0.8247, 0.8172, 0.7381, 0.8249, 0.8298]
2024-02-08 09:02:43.690731: Epoch time: 42.86 s
2024-02-08 09:02:44.733148: 
2024-02-08 09:02:44.734171: Epoch 179
2024-02-08 09:02:44.735192: Current learning rate: 0.00702
2024-02-08 09:03:27.605074: train_loss -0.5488
2024-02-08 09:03:27.606744: val_loss -0.3614
2024-02-08 09:03:27.607234: Pseudo dice [0.8308, 0.82, 0.7329, 0.8268, 0.8201]
2024-02-08 09:03:27.607655: Epoch time: 42.87 s
2024-02-08 09:03:28.672570: 
2024-02-08 09:03:28.674001: Epoch 180
2024-02-08 09:03:28.674597: Current learning rate: 0.007
2024-02-08 09:04:11.755657: train_loss -0.5517
2024-02-08 09:04:11.757098: val_loss -0.3802
2024-02-08 09:04:11.757566: Pseudo dice [0.8351, 0.8274, 0.7303, 0.8299, 0.8211]
2024-02-08 09:04:11.757976: Epoch time: 43.08 s
2024-02-08 09:04:12.810730: 
2024-02-08 09:04:12.811939: Epoch 181
2024-02-08 09:04:12.813082: Current learning rate: 0.00698
2024-02-08 09:04:55.798797: train_loss -0.5529
2024-02-08 09:04:55.800277: val_loss -0.3813
2024-02-08 09:04:55.800725: Pseudo dice [0.8336, 0.8286, 0.7335, 0.8248, 0.822]
2024-02-08 09:04:55.801137: Epoch time: 42.99 s
2024-02-08 09:04:56.877469: 
2024-02-08 09:04:56.879408: Epoch 182
2024-02-08 09:04:56.880122: Current learning rate: 0.00697
2024-02-08 09:05:40.028896: train_loss -0.5532
2024-02-08 09:05:40.030363: val_loss -0.3838
2024-02-08 09:05:40.030868: Pseudo dice [0.8384, 0.8258, 0.7402, 0.8367, 0.8192]
2024-02-08 09:05:40.031320: Epoch time: 43.15 s
2024-02-08 09:05:41.287858: 
2024-02-08 09:05:41.289384: Epoch 183
2024-02-08 09:05:41.289887: Current learning rate: 0.00695
2024-02-08 09:06:24.228219: train_loss -0.5603
2024-02-08 09:06:24.229651: val_loss -0.3705
2024-02-08 09:06:24.230143: Pseudo dice [0.8331, 0.8225, 0.7375, 0.8305, 0.8261]
2024-02-08 09:06:24.230597: Epoch time: 42.94 s
2024-02-08 09:06:24.231016: Yayy! New best EMA pseudo Dice: 0.8073
2024-02-08 09:06:25.528892: 
2024-02-08 09:06:25.530008: Epoch 184
2024-02-08 09:06:25.531122: Current learning rate: 0.00693
2024-02-08 09:07:08.686759: train_loss -0.5519
2024-02-08 09:07:08.688219: val_loss -0.3549
2024-02-08 09:07:08.688707: Pseudo dice [0.83, 0.8207, 0.726, 0.8282, 0.8114]
2024-02-08 09:07:08.689192: Epoch time: 43.16 s
2024-02-08 09:07:09.747010: 
2024-02-08 09:07:09.748052: Epoch 185
2024-02-08 09:07:09.749045: Current learning rate: 0.00691
2024-02-08 09:07:52.844371: train_loss -0.5543
2024-02-08 09:07:52.845860: val_loss -0.3548
2024-02-08 09:07:52.846338: Pseudo dice [0.8342, 0.824, 0.7242, 0.8229, 0.8154]
2024-02-08 09:07:52.846792: Epoch time: 43.1 s
2024-02-08 09:07:53.916982: 
2024-02-08 09:07:53.918717: Epoch 186
2024-02-08 09:07:53.919405: Current learning rate: 0.0069
2024-02-08 09:08:37.027074: train_loss -0.5539
2024-02-08 09:08:37.028670: val_loss -0.3711
2024-02-08 09:08:37.029165: Pseudo dice [0.8309, 0.8189, 0.7413, 0.8229, 0.8259]
2024-02-08 09:08:37.029641: Epoch time: 43.11 s
2024-02-08 09:08:38.155475: 
2024-02-08 09:08:38.156633: Epoch 187
2024-02-08 09:08:38.157779: Current learning rate: 0.00688
2024-02-08 09:09:21.148164: train_loss -0.5541
2024-02-08 09:09:21.149534: val_loss -0.3751
2024-02-08 09:09:21.149999: Pseudo dice [0.8362, 0.8161, 0.7379, 0.8386, 0.817]
2024-02-08 09:09:21.150386: Epoch time: 42.99 s
2024-02-08 09:09:22.421880: 
2024-02-08 09:09:22.423113: Epoch 188
2024-02-08 09:09:22.424329: Current learning rate: 0.00686
2024-02-08 09:10:05.400899: train_loss -0.5569
2024-02-08 09:10:05.402313: val_loss -0.3594
2024-02-08 09:10:05.402770: Pseudo dice [0.8378, 0.822, 0.7296, 0.82, 0.8301]
2024-02-08 09:10:05.403190: Epoch time: 42.98 s
2024-02-08 09:10:06.434472: 
2024-02-08 09:10:06.435487: Epoch 189
2024-02-08 09:10:06.436627: Current learning rate: 0.00685
2024-02-08 09:10:49.255823: train_loss -0.5496
2024-02-08 09:10:49.258455: val_loss -0.3644
2024-02-08 09:10:49.258911: Pseudo dice [0.8351, 0.8262, 0.7397, 0.8214, 0.8284]
2024-02-08 09:10:49.259321: Epoch time: 42.82 s
2024-02-08 09:10:49.259730: Yayy! New best EMA pseudo Dice: 0.8074
2024-02-08 09:10:50.592136: 
2024-02-08 09:10:50.593391: Epoch 190
2024-02-08 09:10:50.594743: Current learning rate: 0.00683
2024-02-08 09:11:33.439908: train_loss -0.5574
2024-02-08 09:11:33.441344: val_loss -0.3696
2024-02-08 09:11:33.441830: Pseudo dice [0.8342, 0.8251, 0.7351, 0.8416, 0.8281]
2024-02-08 09:11:33.442441: Epoch time: 42.85 s
2024-02-08 09:11:33.442817: Yayy! New best EMA pseudo Dice: 0.808
2024-02-08 09:11:34.788793: 
2024-02-08 09:11:34.790117: Epoch 191
2024-02-08 09:11:34.790891: Current learning rate: 0.00681
2024-02-08 09:12:17.496795: train_loss -0.5532
2024-02-08 09:12:17.498304: val_loss -0.3636
2024-02-08 09:12:17.498851: Pseudo dice [0.83, 0.8244, 0.7322, 0.8292, 0.8182]
2024-02-08 09:12:17.499299: Epoch time: 42.71 s
2024-02-08 09:12:18.556783: 
2024-02-08 09:12:18.557822: Epoch 192
2024-02-08 09:12:18.558785: Current learning rate: 0.00679
2024-02-08 09:13:01.272934: train_loss -0.5598
2024-02-08 09:13:01.274225: val_loss -0.3751
2024-02-08 09:13:01.274673: Pseudo dice [0.8298, 0.8231, 0.7317, 0.832, 0.8306]
2024-02-08 09:13:01.275149: Epoch time: 42.72 s
2024-02-08 09:13:01.275543: Yayy! New best EMA pseudo Dice: 0.808
2024-02-08 09:13:02.761207: 
2024-02-08 09:13:02.762186: Epoch 193
2024-02-08 09:13:02.763033: Current learning rate: 0.00678
2024-02-08 09:13:45.744801: train_loss -0.554
2024-02-08 09:13:45.746197: val_loss -0.3135
2024-02-08 09:13:45.746641: Pseudo dice [0.8244, 0.8094, 0.7118, 0.8067, 0.8143]
2024-02-08 09:13:45.747105: Epoch time: 42.98 s
2024-02-08 09:13:46.796643: 
2024-02-08 09:13:46.797573: Epoch 194
2024-02-08 09:13:46.798475: Current learning rate: 0.00676
2024-02-08 09:14:29.596225: train_loss -0.5569
2024-02-08 09:14:29.597967: val_loss -0.3644
2024-02-08 09:14:29.598495: Pseudo dice [0.8339, 0.8176, 0.7309, 0.8246, 0.8263]
2024-02-08 09:14:29.598979: Epoch time: 42.8 s
2024-02-08 09:14:30.662685: 
2024-02-08 09:14:30.663622: Epoch 195
2024-02-08 09:14:30.664761: Current learning rate: 0.00674
2024-02-08 09:15:13.314169: train_loss -0.5508
2024-02-08 09:15:13.315583: val_loss -0.3664
2024-02-08 09:15:13.316071: Pseudo dice [0.8357, 0.8203, 0.7297, 0.8205, 0.8199]
2024-02-08 09:15:13.316506: Epoch time: 42.65 s
2024-02-08 09:15:14.373798: 
2024-02-08 09:15:14.374818: Epoch 196
2024-02-08 09:15:14.375701: Current learning rate: 0.00673
2024-02-08 09:15:57.224494: train_loss -0.5613
2024-02-08 09:15:57.226151: val_loss -0.3461
2024-02-08 09:15:57.226665: Pseudo dice [0.8288, 0.8118, 0.7328, 0.8193, 0.8259]
2024-02-08 09:15:57.227084: Epoch time: 42.85 s
2024-02-08 09:15:58.287246: 
2024-02-08 09:15:58.288460: Epoch 197
2024-02-08 09:15:58.289687: Current learning rate: 0.00671
2024-02-08 09:16:41.015673: train_loss -0.5639
2024-02-08 09:16:41.017680: val_loss -0.3758
2024-02-08 09:16:41.018179: Pseudo dice [0.8356, 0.8216, 0.7365, 0.8213, 0.8288]
2024-02-08 09:16:41.018631: Epoch time: 42.73 s
2024-02-08 09:16:42.072732: 
2024-02-08 09:16:42.074082: Epoch 198
2024-02-08 09:16:42.074565: Current learning rate: 0.00669
2024-02-08 09:17:25.292178: train_loss -0.5568
2024-02-08 09:17:25.294079: val_loss -0.3375
2024-02-08 09:17:25.294596: Pseudo dice [0.825, 0.8128, 0.7256, 0.807, 0.8155]
2024-02-08 09:17:25.295045: Epoch time: 43.22 s
2024-02-08 09:17:26.371099: 
2024-02-08 09:17:26.372798: Epoch 199
2024-02-08 09:17:26.373334: Current learning rate: 0.00667
2024-02-08 09:18:09.224372: train_loss -0.5545
2024-02-08 09:18:09.225662: val_loss -0.387
2024-02-08 09:18:09.226107: Pseudo dice [0.837, 0.8251, 0.7392, 0.8414, 0.8177]
2024-02-08 09:18:09.226544: Epoch time: 42.86 s
2024-02-08 09:18:10.525413: 
2024-02-08 09:18:10.526641: Epoch 200
2024-02-08 09:18:10.527373: Current learning rate: 0.00666
2024-02-08 09:18:53.483674: train_loss -0.562
2024-02-08 09:18:53.485138: val_loss -0.3634
2024-02-08 09:18:53.485612: Pseudo dice [0.8331, 0.8181, 0.7353, 0.8276, 0.8134]
2024-02-08 09:18:53.486049: Epoch time: 42.96 s
2024-02-08 09:18:54.555927: 
2024-02-08 09:18:54.557398: Epoch 201
2024-02-08 09:18:54.557938: Current learning rate: 0.00664
2024-02-08 09:19:37.508195: train_loss -0.5635
2024-02-08 09:19:37.509552: val_loss -0.371
2024-02-08 09:19:37.510069: Pseudo dice [0.8324, 0.8263, 0.7368, 0.8291, 0.8151]
2024-02-08 09:19:37.510515: Epoch time: 42.95 s
2024-02-08 09:19:38.565108: 
2024-02-08 09:19:38.566107: Epoch 202
2024-02-08 09:19:38.566941: Current learning rate: 0.00662
2024-02-08 09:20:21.708772: train_loss -0.5634
2024-02-08 09:20:21.710111: val_loss -0.3243
2024-02-08 09:20:21.710570: Pseudo dice [0.8211, 0.8127, 0.7301, 0.8136, 0.818]
2024-02-08 09:20:21.711038: Epoch time: 43.14 s
2024-02-08 09:20:22.922555: 
2024-02-08 09:20:22.923487: Epoch 203
2024-02-08 09:20:22.924542: Current learning rate: 0.00661
2024-02-08 09:21:05.868091: train_loss -0.5564
2024-02-08 09:21:05.869436: val_loss -0.3934
2024-02-08 09:21:05.869896: Pseudo dice [0.8398, 0.8238, 0.7437, 0.8374, 0.8244]
2024-02-08 09:21:05.870337: Epoch time: 42.95 s
2024-02-08 09:21:06.926004: 
2024-02-08 09:21:06.927049: Epoch 204
2024-02-08 09:21:06.927909: Current learning rate: 0.00659
2024-02-08 09:21:49.824712: train_loss -0.5564
2024-02-08 09:21:49.826028: val_loss -0.3554
2024-02-08 09:21:49.826511: Pseudo dice [0.8328, 0.8241, 0.7383, 0.8333, 0.8139]
2024-02-08 09:21:49.826943: Epoch time: 42.9 s
2024-02-08 09:21:50.891544: 
2024-02-08 09:21:50.892570: Epoch 205
2024-02-08 09:21:50.893708: Current learning rate: 0.00657
2024-02-08 09:22:33.697590: train_loss -0.5577
2024-02-08 09:22:33.699514: val_loss -0.3741
2024-02-08 09:22:33.700015: Pseudo dice [0.832, 0.8218, 0.7304, 0.8273, 0.8269]
2024-02-08 09:22:33.700481: Epoch time: 42.81 s
2024-02-08 09:22:34.679745: 
2024-02-08 09:22:34.680538: Epoch 206
2024-02-08 09:22:34.681251: Current learning rate: 0.00656
2024-02-08 09:23:17.316686: train_loss -0.5508
2024-02-08 09:23:17.318004: val_loss -0.3737
2024-02-08 09:23:17.318476: Pseudo dice [0.8336, 0.823, 0.7369, 0.8344, 0.8187]
2024-02-08 09:23:17.318967: Epoch time: 42.64 s
2024-02-08 09:23:18.312904: 
2024-02-08 09:23:18.313866: Epoch 207
2024-02-08 09:23:18.314379: Current learning rate: 0.00654
2024-02-08 09:24:01.286235: train_loss -0.5515
2024-02-08 09:24:01.287711: val_loss -0.3698
2024-02-08 09:24:01.288202: Pseudo dice [0.8353, 0.8222, 0.7369, 0.83, 0.8221]
2024-02-08 09:24:01.288637: Epoch time: 42.97 s
2024-02-08 09:24:02.293856: 
2024-02-08 09:24:02.295496: Epoch 208
2024-02-08 09:24:02.296126: Current learning rate: 0.00652
2024-02-08 09:24:45.172816: train_loss -0.5627
2024-02-08 09:24:45.174378: val_loss -0.3675
2024-02-08 09:24:45.174850: Pseudo dice [0.8295, 0.8232, 0.732, 0.8316, 0.8211]
2024-02-08 09:24:45.175299: Epoch time: 42.88 s
2024-02-08 09:24:46.284720: 
2024-02-08 09:24:46.285697: Epoch 209
2024-02-08 09:24:46.286588: Current learning rate: 0.0065
2024-02-08 09:25:29.032947: train_loss -0.5671
2024-02-08 09:25:29.034411: val_loss -0.3553
2024-02-08 09:25:29.034910: Pseudo dice [0.83, 0.8232, 0.7324, 0.8156, 0.8231]
2024-02-08 09:25:29.035335: Epoch time: 42.75 s
2024-02-08 09:25:30.072191: 
2024-02-08 09:25:30.074655: Epoch 210
2024-02-08 09:25:30.076200: Current learning rate: 0.00649
2024-02-08 09:26:13.192789: train_loss -0.5605
2024-02-08 09:26:13.194290: val_loss -0.3687
2024-02-08 09:26:13.194770: Pseudo dice [0.8322, 0.8237, 0.7327, 0.8356, 0.8317]
2024-02-08 09:26:13.195183: Epoch time: 43.12 s
2024-02-08 09:26:14.202901: 
2024-02-08 09:26:14.204460: Epoch 211
2024-02-08 09:26:14.204954: Current learning rate: 0.00647
2024-02-08 09:26:57.378369: train_loss -0.5659
2024-02-08 09:26:57.379760: val_loss -0.346
2024-02-08 09:26:57.380242: Pseudo dice [0.8292, 0.8193, 0.7282, 0.8332, 0.8105]
2024-02-08 09:26:57.380708: Epoch time: 43.18 s
2024-02-08 09:26:58.386872: 
2024-02-08 09:26:58.388377: Epoch 212
2024-02-08 09:26:58.388877: Current learning rate: 0.00645
2024-02-08 09:27:41.566724: train_loss -0.5651
2024-02-08 09:27:41.568301: val_loss -0.3725
2024-02-08 09:27:41.568786: Pseudo dice [0.8326, 0.8232, 0.7367, 0.8301, 0.8287]
2024-02-08 09:27:41.569275: Epoch time: 43.18 s
2024-02-08 09:27:42.597318: 
2024-02-08 09:27:42.598621: Epoch 213
2024-02-08 09:27:42.599685: Current learning rate: 0.00643
2024-02-08 09:28:25.862108: train_loss -0.5655
2024-02-08 09:28:25.864102: val_loss -0.3596
2024-02-08 09:28:25.864609: Pseudo dice [0.8303, 0.8146, 0.7316, 0.8264, 0.8228]
2024-02-08 09:28:25.865040: Epoch time: 43.27 s
2024-02-08 09:28:27.060431: 
2024-02-08 09:28:27.062392: Epoch 214
2024-02-08 09:28:27.063231: Current learning rate: 0.00642
2024-02-08 09:29:10.058162: train_loss -0.5703
2024-02-08 09:29:10.059777: val_loss -0.3421
2024-02-08 09:29:10.060292: Pseudo dice [0.8282, 0.8219, 0.7172, 0.8272, 0.8131]
2024-02-08 09:29:10.060767: Epoch time: 43.0 s
2024-02-08 09:29:11.055942: 
2024-02-08 09:29:11.056771: Epoch 215
2024-02-08 09:29:11.057570: Current learning rate: 0.0064
2024-02-08 09:29:53.862881: train_loss -0.5649
2024-02-08 09:29:53.864523: val_loss -0.3554
2024-02-08 09:29:53.865000: Pseudo dice [0.8301, 0.8244, 0.7278, 0.8211, 0.8213]
2024-02-08 09:29:53.865468: Epoch time: 42.81 s
2024-02-08 09:29:54.872932: 
2024-02-08 09:29:54.874092: Epoch 216
2024-02-08 09:29:54.875009: Current learning rate: 0.00638
2024-02-08 09:30:37.560191: train_loss -0.5669
2024-02-08 09:30:37.561519: val_loss -0.357
2024-02-08 09:30:37.562152: Pseudo dice [0.8309, 0.8235, 0.7334, 0.8326, 0.8188]
2024-02-08 09:30:37.562614: Epoch time: 42.69 s
2024-02-08 09:30:38.559931: 
2024-02-08 09:30:38.561346: Epoch 217
2024-02-08 09:30:38.562268: Current learning rate: 0.00637
2024-02-08 09:31:21.544011: train_loss -0.5654
2024-02-08 09:31:21.545485: val_loss -0.3742
2024-02-08 09:31:21.545972: Pseudo dice [0.8405, 0.8226, 0.7329, 0.8333, 0.8252]
2024-02-08 09:31:21.546415: Epoch time: 42.99 s
2024-02-08 09:31:22.587214: 
2024-02-08 09:31:22.588652: Epoch 218
2024-02-08 09:31:22.589190: Current learning rate: 0.00635
2024-02-08 09:32:05.542479: train_loss -0.5635
2024-02-08 09:32:05.543890: val_loss -0.3696
2024-02-08 09:32:05.544355: Pseudo dice [0.8348, 0.8191, 0.7398, 0.8279, 0.8287]
2024-02-08 09:32:05.544791: Epoch time: 42.96 s
2024-02-08 09:32:06.531977: 
2024-02-08 09:32:06.562090: Epoch 219
2024-02-08 09:32:06.563308: Current learning rate: 0.00633
2024-02-08 09:32:49.446465: train_loss -0.5598
2024-02-08 09:32:49.464058: val_loss -0.3699
2024-02-08 09:32:49.464539: Pseudo dice [0.8355, 0.8211, 0.7381, 0.8364, 0.8129]
2024-02-08 09:32:49.465005: Epoch time: 42.92 s
2024-02-08 09:32:50.843885: 
2024-02-08 09:32:50.846364: Epoch 220
2024-02-08 09:32:50.847394: Current learning rate: 0.00631
2024-02-08 09:33:33.953711: train_loss -0.567
2024-02-08 09:33:33.954947: val_loss -0.3557
2024-02-08 09:33:33.955408: Pseudo dice [0.8342, 0.8177, 0.7316, 0.8131, 0.8117]
2024-02-08 09:33:33.955817: Epoch time: 43.11 s
2024-02-08 09:33:34.942373: 
2024-02-08 09:33:34.943049: Epoch 221
2024-02-08 09:33:34.943579: Current learning rate: 0.0063
2024-02-08 09:34:17.972022: train_loss -0.5631
2024-02-08 09:34:17.973482: val_loss -0.3408
2024-02-08 09:34:17.973971: Pseudo dice [0.8303, 0.8153, 0.7252, 0.8257, 0.8158]
2024-02-08 09:34:17.974405: Epoch time: 43.03 s
2024-02-08 09:34:18.961189: 
2024-02-08 09:34:18.961924: Epoch 222
2024-02-08 09:34:18.962464: Current learning rate: 0.00628
2024-02-08 09:35:02.058377: train_loss -0.5635
2024-02-08 09:35:02.060095: val_loss -0.3721
2024-02-08 09:35:02.060592: Pseudo dice [0.8352, 0.8313, 0.7347, 0.8313, 0.8243]
2024-02-08 09:35:02.061020: Epoch time: 43.1 s
2024-02-08 09:35:03.055315: 
2024-02-08 09:35:03.056253: Epoch 223
2024-02-08 09:35:03.057552: Current learning rate: 0.00626
2024-02-08 09:35:46.153948: train_loss -0.5679
2024-02-08 09:35:46.155346: val_loss -0.3884
2024-02-08 09:35:46.155828: Pseudo dice [0.8389, 0.8302, 0.7363, 0.8294, 0.8273]
2024-02-08 09:35:46.156266: Epoch time: 43.1 s
2024-02-08 09:35:47.153037: 
2024-02-08 09:35:47.154142: Epoch 224
2024-02-08 09:35:47.155242: Current learning rate: 0.00625
2024-02-08 09:36:30.222103: train_loss -0.5581
2024-02-08 09:36:30.223539: val_loss -0.3522
2024-02-08 09:36:30.224020: Pseudo dice [0.8315, 0.8171, 0.7295, 0.8118, 0.819]
2024-02-08 09:36:30.224492: Epoch time: 43.07 s
2024-02-08 09:36:31.574212: 
2024-02-08 09:36:31.605064: Epoch 225
2024-02-08 09:36:31.605803: Current learning rate: 0.00623
2024-02-08 09:37:14.806147: train_loss -0.5682
2024-02-08 09:37:14.807547: val_loss -0.3759
2024-02-08 09:37:14.808010: Pseudo dice [0.8348, 0.8289, 0.7395, 0.8371, 0.8246]
2024-02-08 09:37:14.808440: Epoch time: 43.23 s
2024-02-08 09:37:15.822519: 
2024-02-08 09:37:15.939830: Epoch 226
2024-02-08 09:37:15.940586: Current learning rate: 0.00621
2024-02-08 09:37:58.996362: train_loss -0.5654
2024-02-08 09:37:58.997882: val_loss -0.3894
2024-02-08 09:37:58.998372: Pseudo dice [0.8384, 0.8263, 0.7415, 0.8342, 0.8268]
2024-02-08 09:37:58.998793: Epoch time: 43.18 s
2024-02-08 09:37:58.999188: Yayy! New best EMA pseudo Dice: 0.8081
2024-02-08 09:38:00.304685: 
2024-02-08 09:38:00.306137: Epoch 227
2024-02-08 09:38:00.307227: Current learning rate: 0.00619
2024-02-08 09:38:43.297543: train_loss -0.5676
2024-02-08 09:38:43.299066: val_loss -0.3497
2024-02-08 09:38:43.299583: Pseudo dice [0.829, 0.8169, 0.7343, 0.8185, 0.8157]
2024-02-08 09:38:43.300066: Epoch time: 42.99 s
2024-02-08 09:38:44.327833: 
2024-02-08 09:38:44.329271: Epoch 228
2024-02-08 09:38:44.330075: Current learning rate: 0.00618
2024-02-08 09:39:27.344587: train_loss -0.5647
2024-02-08 09:39:27.346112: val_loss -0.3829
2024-02-08 09:39:27.346629: Pseudo dice [0.8378, 0.8267, 0.7397, 0.8327, 0.8272]
2024-02-08 09:39:27.347101: Epoch time: 43.02 s
2024-02-08 09:39:27.347540: Yayy! New best EMA pseudo Dice: 0.8081
2024-02-08 09:39:28.664003: 
2024-02-08 09:39:28.665686: Epoch 229
2024-02-08 09:39:28.666415: Current learning rate: 0.00616
2024-02-08 09:40:11.712452: train_loss -0.5727
2024-02-08 09:40:11.714006: val_loss -0.3446
2024-02-08 09:40:11.714502: Pseudo dice [0.8291, 0.818, 0.7265, 0.8303, 0.8232]
2024-02-08 09:40:11.714952: Epoch time: 43.05 s
2024-02-08 09:40:12.738955: 
2024-02-08 09:40:12.740060: Epoch 230
2024-02-08 09:40:12.740950: Current learning rate: 0.00614
2024-02-08 09:40:55.737478: train_loss -0.5712
2024-02-08 09:40:55.738853: val_loss -0.3516
2024-02-08 09:40:55.739322: Pseudo dice [0.8338, 0.8245, 0.7312, 0.8386, 0.8077]
2024-02-08 09:40:55.739781: Epoch time: 43.0 s
2024-02-08 09:40:56.951261: 
2024-02-08 09:40:56.952361: Epoch 231
2024-02-08 09:40:56.953227: Current learning rate: 0.00612
2024-02-08 09:41:39.747522: train_loss -0.5726
2024-02-08 09:41:39.748803: val_loss -0.3573
2024-02-08 09:41:39.749235: Pseudo dice [0.8343, 0.8197, 0.7294, 0.8234, 0.8234]
2024-02-08 09:41:39.749664: Epoch time: 42.8 s
2024-02-08 09:41:40.755846: 
2024-02-08 09:41:40.757403: Epoch 232
2024-02-08 09:41:40.757899: Current learning rate: 0.00611
2024-02-08 09:42:23.635386: train_loss -0.5653
2024-02-08 09:42:23.636900: val_loss -0.3675
2024-02-08 09:42:23.637421: Pseudo dice [0.836, 0.8259, 0.731, 0.8292, 0.8343]
2024-02-08 09:42:23.637895: Epoch time: 42.88 s
2024-02-08 09:42:24.662410: 
2024-02-08 09:42:24.663582: Epoch 233
2024-02-08 09:42:24.664710: Current learning rate: 0.00609
2024-02-08 09:43:07.332776: train_loss -0.5681
2024-02-08 09:43:07.334298: val_loss -0.3605
2024-02-08 09:43:07.334782: Pseudo dice [0.8339, 0.8277, 0.7307, 0.8343, 0.8219]
2024-02-08 09:43:07.335232: Epoch time: 42.67 s
2024-02-08 09:43:07.335639: Yayy! New best EMA pseudo Dice: 0.8081
2024-02-08 09:43:08.625204: 
2024-02-08 09:43:08.626205: Epoch 234
2024-02-08 09:43:08.627097: Current learning rate: 0.00607
2024-02-08 09:43:51.420691: train_loss -0.5712
2024-02-08 09:43:51.422046: val_loss -0.3566
2024-02-08 09:43:51.422518: Pseudo dice [0.8332, 0.82, 0.7234, 0.8328, 0.8286]
2024-02-08 09:43:51.422924: Epoch time: 42.8 s
2024-02-08 09:43:52.405501: 
2024-02-08 09:43:52.406675: Epoch 235
2024-02-08 09:43:52.407728: Current learning rate: 0.00606
2024-02-08 09:44:35.223360: train_loss -0.569
2024-02-08 09:44:35.224633: val_loss -0.3664
2024-02-08 09:44:35.225047: Pseudo dice [0.8327, 0.8211, 0.7341, 0.8397, 0.8236]
2024-02-08 09:44:35.225458: Epoch time: 42.82 s
2024-02-08 09:44:35.225827: Yayy! New best EMA pseudo Dice: 0.8083
2024-02-08 09:44:36.759718: 
2024-02-08 09:44:36.760695: Epoch 236
2024-02-08 09:44:36.761592: Current learning rate: 0.00604
2024-02-08 09:45:19.931906: train_loss -0.5704
2024-02-08 09:45:19.933301: val_loss -0.3689
2024-02-08 09:45:19.934460: Pseudo dice [0.8325, 0.8222, 0.7314, 0.8328, 0.8317]
2024-02-08 09:45:19.934911: Epoch time: 43.17 s
2024-02-08 09:45:19.935377: Yayy! New best EMA pseudo Dice: 0.8085
2024-02-08 09:45:21.299761: 
2024-02-08 09:45:21.300874: Epoch 237
2024-02-08 09:45:21.301861: Current learning rate: 0.00602
2024-02-08 09:46:04.437287: train_loss -0.5757
2024-02-08 09:46:04.438601: val_loss -0.3581
2024-02-08 09:46:04.439042: Pseudo dice [0.8304, 0.8225, 0.7336, 0.8206, 0.8251]
2024-02-08 09:46:04.439445: Epoch time: 43.14 s
2024-02-08 09:46:05.443326: 
2024-02-08 09:46:05.444379: Epoch 238
2024-02-08 09:46:05.445384: Current learning rate: 0.006
2024-02-08 09:46:48.430977: train_loss -0.5733
2024-02-08 09:46:48.432487: val_loss -0.3615
2024-02-08 09:46:48.432974: Pseudo dice [0.8338, 0.8214, 0.7282, 0.8228, 0.8253]
2024-02-08 09:46:48.433461: Epoch time: 42.99 s
2024-02-08 09:46:49.431039: 
2024-02-08 09:46:49.432306: Epoch 239
2024-02-08 09:46:49.433470: Current learning rate: 0.00599
2024-02-08 09:47:32.700373: train_loss -0.5765
2024-02-08 09:47:32.701986: val_loss -0.3768
2024-02-08 09:47:32.702543: Pseudo dice [0.8426, 0.8256, 0.7402, 0.8377, 0.8271]
2024-02-08 09:47:32.703021: Epoch time: 43.27 s
2024-02-08 09:47:32.703472: Yayy! New best EMA pseudo Dice: 0.8087
2024-02-08 09:47:34.014854: 
2024-02-08 09:47:34.016367: Epoch 240
2024-02-08 09:47:34.017303: Current learning rate: 0.00597
2024-02-08 09:48:16.989127: train_loss -0.5723
2024-02-08 09:48:16.990654: val_loss -0.3728
2024-02-08 09:48:16.991128: Pseudo dice [0.8385, 0.8236, 0.7396, 0.8289, 0.8353]
2024-02-08 09:48:16.991580: Epoch time: 42.98 s
2024-02-08 09:48:16.992016: Yayy! New best EMA pseudo Dice: 0.8092
2024-02-08 09:48:18.639815: 
2024-02-08 09:48:18.640728: Epoch 241
2024-02-08 09:48:18.641253: Current learning rate: 0.00595
2024-02-08 09:49:01.574313: train_loss -0.5753
2024-02-08 09:49:01.575861: val_loss -0.3614
2024-02-08 09:49:01.576367: Pseudo dice [0.8334, 0.8225, 0.7294, 0.8194, 0.8315]
2024-02-08 09:49:01.576848: Epoch time: 42.94 s
2024-02-08 09:49:02.641317: 
2024-02-08 09:49:02.643245: Epoch 242
2024-02-08 09:49:02.645288: Current learning rate: 0.00593
2024-02-08 09:49:45.721404: train_loss -0.5787
2024-02-08 09:49:45.722881: val_loss -0.3602
2024-02-08 09:49:45.723387: Pseudo dice [0.8347, 0.8241, 0.7272, 0.8241, 0.8214]
2024-02-08 09:49:45.723836: Epoch time: 43.08 s
2024-02-08 09:49:46.743293: 
2024-02-08 09:49:46.744843: Epoch 243
2024-02-08 09:49:46.745437: Current learning rate: 0.00592
2024-02-08 09:50:29.457639: train_loss -0.5765
2024-02-08 09:50:29.459426: val_loss -0.3372
2024-02-08 09:50:29.459953: Pseudo dice [0.8315, 0.8145, 0.7256, 0.8128, 0.8251]
2024-02-08 09:50:29.460452: Epoch time: 42.72 s
2024-02-08 09:50:30.478148: 
2024-02-08 09:50:30.479105: Epoch 244
2024-02-08 09:50:30.479898: Current learning rate: 0.0059
2024-02-08 09:51:14.158855: train_loss -0.5748
2024-02-08 09:51:14.160349: val_loss -0.3763
2024-02-08 09:51:14.160793: Pseudo dice [0.839, 0.823, 0.7372, 0.8224, 0.8293]
2024-02-08 09:51:14.161200: Epoch time: 43.68 s
2024-02-08 09:51:15.158630: 
2024-02-08 09:51:15.159236: Epoch 245
2024-02-08 09:51:15.159852: Current learning rate: 0.00588
2024-02-08 09:51:57.902816: train_loss -0.5706
2024-02-08 09:51:57.904262: val_loss -0.3485
2024-02-08 09:51:57.904751: Pseudo dice [0.8282, 0.8255, 0.7314, 0.8207, 0.821]
2024-02-08 09:51:57.905171: Epoch time: 42.75 s
2024-02-08 09:51:58.928823: 
2024-02-08 09:51:58.930555: Epoch 246
2024-02-08 09:51:58.931177: Current learning rate: 0.00586
2024-02-08 09:52:42.162074: train_loss -0.5744
2024-02-08 09:52:42.163521: val_loss -0.3634
2024-02-08 09:52:42.163986: Pseudo dice [0.8384, 0.8228, 0.7354, 0.8194, 0.8255]
2024-02-08 09:52:42.164419: Epoch time: 43.23 s
2024-02-08 09:52:43.317017: 
2024-02-08 09:52:43.318122: Epoch 247
2024-02-08 09:52:43.319250: Current learning rate: 0.00585
2024-02-08 09:53:26.219897: train_loss -0.5752
2024-02-08 09:53:26.221266: val_loss -0.3378
2024-02-08 09:53:26.221747: Pseudo dice [0.8294, 0.8131, 0.7287, 0.8193, 0.8162]
2024-02-08 09:53:26.222166: Epoch time: 42.9 s
2024-02-08 09:53:27.222958: 
2024-02-08 09:53:27.224370: Epoch 248
2024-02-08 09:53:27.225040: Current learning rate: 0.00583
2024-02-08 09:54:10.072288: train_loss -0.5755
2024-02-08 09:54:10.073754: val_loss -0.3655
2024-02-08 09:54:10.074249: Pseudo dice [0.8311, 0.8231, 0.7365, 0.8226, 0.8333]
2024-02-08 09:54:10.074708: Epoch time: 42.85 s
2024-02-08 09:54:11.083128: 
2024-02-08 09:54:11.084324: Epoch 249
2024-02-08 09:54:11.084857: Current learning rate: 0.00581
2024-02-08 09:54:54.044454: train_loss -0.5774
2024-02-08 09:54:54.045786: val_loss -0.3755
2024-02-08 09:54:54.046238: Pseudo dice [0.8342, 0.8232, 0.7401, 0.8325, 0.8289]
2024-02-08 09:54:54.046666: Epoch time: 42.96 s
2024-02-08 09:54:55.279261: 
2024-02-08 09:54:55.280197: Epoch 250
2024-02-08 09:54:55.281050: Current learning rate: 0.0058
2024-02-08 09:55:38.033090: train_loss -0.5728
2024-02-08 09:55:38.034364: val_loss -0.3506
2024-02-08 09:55:38.034813: Pseudo dice [0.8273, 0.8199, 0.7403, 0.8282, 0.8292]
2024-02-08 09:55:38.035227: Epoch time: 42.75 s
2024-02-08 09:55:39.096497: 
2024-02-08 09:55:39.098234: Epoch 251
2024-02-08 09:55:39.098847: Current learning rate: 0.00578
2024-02-08 09:56:21.952662: train_loss -0.5764
2024-02-08 09:56:21.954137: val_loss -0.3808
2024-02-08 09:56:21.954593: Pseudo dice [0.8377, 0.8238, 0.7396, 0.8407, 0.8264]
2024-02-08 09:56:21.955022: Epoch time: 42.86 s
2024-02-08 09:56:22.947774: 
2024-02-08 09:56:22.948562: Epoch 252
2024-02-08 09:56:22.949108: Current learning rate: 0.00576
2024-02-08 09:57:05.599219: train_loss -0.5719
2024-02-08 09:57:05.600853: val_loss -0.3574
2024-02-08 09:57:05.601377: Pseudo dice [0.8351, 0.8238, 0.7294, 0.839, 0.8122]
2024-02-08 09:57:05.601870: Epoch time: 42.65 s
2024-02-08 09:57:06.733793: 
2024-02-08 09:57:06.735329: Epoch 253
2024-02-08 09:57:06.735843: Current learning rate: 0.00574
2024-02-08 09:57:49.478765: train_loss -0.5692
2024-02-08 09:57:49.480236: val_loss -0.3744
2024-02-08 09:57:49.480766: Pseudo dice [0.8346, 0.8281, 0.7354, 0.8369, 0.8152]
2024-02-08 09:57:49.481266: Epoch time: 42.75 s
2024-02-08 09:57:50.489872: 
2024-02-08 09:57:50.490906: Epoch 254
2024-02-08 09:57:50.491791: Current learning rate: 0.00573
2024-02-08 09:58:33.661320: train_loss -0.5738
2024-02-08 09:58:33.662635: val_loss -0.3568
2024-02-08 09:58:33.663543: Pseudo dice [0.8334, 0.8189, 0.7363, 0.8417, 0.8232]
2024-02-08 09:58:33.664258: Epoch time: 43.17 s
2024-02-08 09:58:34.668163: 
2024-02-08 09:58:34.669113: Epoch 255
2024-02-08 09:58:34.669933: Current learning rate: 0.00571
2024-02-08 09:59:17.751633: train_loss -0.5744
2024-02-08 09:59:17.753361: val_loss -0.3668
2024-02-08 09:59:17.753880: Pseudo dice [0.836, 0.823, 0.7291, 0.8287, 0.8371]
2024-02-08 09:59:17.754307: Epoch time: 43.08 s
2024-02-08 09:59:18.769531: 
2024-02-08 09:59:18.771407: Epoch 256
2024-02-08 09:59:18.772044: Current learning rate: 0.00569
2024-02-08 10:00:01.919930: train_loss -0.5751
2024-02-08 10:00:01.921776: val_loss -0.3585
2024-02-08 10:00:01.922316: Pseudo dice [0.8352, 0.8252, 0.7275, 0.8179, 0.8249]
2024-02-08 10:00:01.922768: Epoch time: 43.15 s
2024-02-08 10:00:02.969433: 
2024-02-08 10:00:02.970882: Epoch 257
2024-02-08 10:00:02.972072: Current learning rate: 0.00567
2024-02-08 10:00:46.187963: train_loss -0.5725
2024-02-08 10:00:46.189475: val_loss -0.3525
2024-02-08 10:00:46.189939: Pseudo dice [0.8314, 0.8185, 0.7296, 0.8335, 0.8161]
2024-02-08 10:00:46.190380: Epoch time: 43.22 s
2024-02-08 10:00:47.403643: 
2024-02-08 10:00:47.404719: Epoch 258
2024-02-08 10:00:47.405930: Current learning rate: 0.00566
2024-02-08 10:01:30.419582: train_loss -0.5755
2024-02-08 10:01:30.421598: val_loss -0.3649
2024-02-08 10:01:30.422142: Pseudo dice [0.8382, 0.8233, 0.7298, 0.8166, 0.8258]
2024-02-08 10:01:30.422606: Epoch time: 43.02 s
2024-02-08 10:01:31.454516: 
2024-02-08 10:01:31.455617: Epoch 259
2024-02-08 10:01:31.456697: Current learning rate: 0.00564
2024-02-08 10:02:14.726764: train_loss -0.5777
2024-02-08 10:02:14.728265: val_loss -0.3414
2024-02-08 10:02:14.728737: Pseudo dice [0.834, 0.8167, 0.7234, 0.8136, 0.8249]
2024-02-08 10:02:14.729185: Epoch time: 43.27 s
2024-02-08 10:02:15.786627: 
2024-02-08 10:02:15.788154: Epoch 260
2024-02-08 10:02:15.788674: Current learning rate: 0.00562
2024-02-08 10:02:58.917850: train_loss -0.5817
2024-02-08 10:02:58.919304: val_loss -0.3486
2024-02-08 10:02:58.919807: Pseudo dice [0.8302, 0.8217, 0.7318, 0.8257, 0.8176]
2024-02-08 10:02:58.920327: Epoch time: 43.13 s
2024-02-08 10:02:59.929431: 
2024-02-08 10:02:59.931002: Epoch 261
2024-02-08 10:02:59.931534: Current learning rate: 0.0056
2024-02-08 10:03:42.766078: train_loss -0.5756
2024-02-08 10:03:42.768431: val_loss -0.3563
2024-02-08 10:03:42.768913: Pseudo dice [0.8313, 0.8211, 0.7359, 0.8279, 0.8179]
2024-02-08 10:03:42.769383: Epoch time: 42.84 s
2024-02-08 10:03:43.785636: 
2024-02-08 10:03:43.786835: Epoch 262
2024-02-08 10:03:43.787862: Current learning rate: 0.00559
2024-02-08 10:04:26.484439: train_loss -0.5827
2024-02-08 10:04:26.486252: val_loss -0.3443
2024-02-08 10:04:26.486767: Pseudo dice [0.8264, 0.827, 0.7253, 0.8223, 0.8261]
2024-02-08 10:04:26.487224: Epoch time: 42.7 s
2024-02-08 10:04:27.614637: 
2024-02-08 10:04:27.616130: Epoch 263
2024-02-08 10:04:27.616653: Current learning rate: 0.00557
2024-02-08 10:05:10.355786: train_loss -0.5799
2024-02-08 10:05:10.357111: val_loss -0.3966
2024-02-08 10:05:10.357571: Pseudo dice [0.8429, 0.8256, 0.7438, 0.8396, 0.8299]
2024-02-08 10:05:10.358011: Epoch time: 42.74 s
2024-02-08 10:05:11.355371: 
2024-02-08 10:05:11.356720: Epoch 264
2024-02-08 10:05:11.357753: Current learning rate: 0.00555
2024-02-08 10:05:54.393087: train_loss -0.581
2024-02-08 10:05:54.394694: val_loss -0.3486
2024-02-08 10:05:54.395207: Pseudo dice [0.8297, 0.8161, 0.7277, 0.8167, 0.8271]
2024-02-08 10:05:54.395664: Epoch time: 43.04 s
2024-02-08 10:05:55.405407: 
2024-02-08 10:05:55.407038: Epoch 265
2024-02-08 10:05:55.407526: Current learning rate: 0.00553
2024-02-08 10:06:38.325026: train_loss -0.5819
2024-02-08 10:06:38.326445: val_loss -0.3539
2024-02-08 10:06:38.326926: Pseudo dice [0.8306, 0.8246, 0.7354, 0.8303, 0.8127]
2024-02-08 10:06:38.327386: Epoch time: 42.92 s
2024-02-08 10:06:39.334204: 
2024-02-08 10:06:39.335947: Epoch 266
2024-02-08 10:06:39.336880: Current learning rate: 0.00552
2024-02-08 10:07:22.322770: train_loss -0.5728
2024-02-08 10:07:22.324033: val_loss -0.3753
2024-02-08 10:07:22.324467: Pseudo dice [0.8358, 0.8275, 0.7333, 0.8394, 0.8105]
2024-02-08 10:07:22.324862: Epoch time: 42.99 s
2024-02-08 10:07:23.330303: 
2024-02-08 10:07:23.331253: Epoch 267
2024-02-08 10:07:23.332062: Current learning rate: 0.0055
2024-02-08 10:08:06.545077: train_loss -0.576
2024-02-08 10:08:06.546583: val_loss -0.3658
2024-02-08 10:08:06.547083: Pseudo dice [0.8366, 0.8217, 0.7374, 0.819, 0.8235]
2024-02-08 10:08:06.547545: Epoch time: 43.22 s
2024-02-08 10:08:07.559857: 
2024-02-08 10:08:07.560795: Epoch 268
2024-02-08 10:08:07.561666: Current learning rate: 0.00548
2024-02-08 10:08:50.467390: train_loss -0.5859
2024-02-08 10:08:50.469144: val_loss -0.3665
2024-02-08 10:08:50.469696: Pseudo dice [0.8357, 0.8208, 0.7346, 0.8357, 0.827]
2024-02-08 10:08:50.470189: Epoch time: 42.91 s
2024-02-08 10:08:51.701749: 
2024-02-08 10:08:51.703069: Epoch 269
2024-02-08 10:08:51.703790: Current learning rate: 0.00546
2024-02-08 10:09:34.284250: train_loss -0.5871
2024-02-08 10:09:34.285636: val_loss -0.3414
2024-02-08 10:09:34.286084: Pseudo dice [0.8324, 0.8154, 0.7224, 0.84, 0.8108]
2024-02-08 10:09:34.286540: Epoch time: 42.58 s
2024-02-08 10:09:35.279010: 
2024-02-08 10:09:35.279830: Epoch 270
2024-02-08 10:09:35.280568: Current learning rate: 0.00545
2024-02-08 10:10:18.062248: train_loss -0.5825
2024-02-08 10:10:18.063640: val_loss -0.3821
2024-02-08 10:10:18.064105: Pseudo dice [0.8404, 0.8283, 0.7402, 0.8426, 0.8292]
2024-02-08 10:10:18.064525: Epoch time: 42.78 s
2024-02-08 10:10:19.069043: 
2024-02-08 10:10:19.070560: Epoch 271
2024-02-08 10:10:19.071079: Current learning rate: 0.00543
2024-02-08 10:11:01.896977: train_loss -0.5813
2024-02-08 10:11:01.898257: val_loss -0.362
2024-02-08 10:11:01.898738: Pseudo dice [0.8332, 0.8254, 0.7311, 0.8264, 0.8226]
2024-02-08 10:11:01.899175: Epoch time: 42.83 s
2024-02-08 10:11:02.897324: 
2024-02-08 10:11:02.898145: Epoch 272
2024-02-08 10:11:02.899262: Current learning rate: 0.00541
2024-02-08 10:11:45.766575: train_loss -0.5761
2024-02-08 10:11:45.767961: val_loss -0.3726
2024-02-08 10:11:45.768439: Pseudo dice [0.8376, 0.8238, 0.7335, 0.8327, 0.8296]
2024-02-08 10:11:45.768886: Epoch time: 42.87 s
2024-02-08 10:11:46.752831: 
2024-02-08 10:11:46.753813: Epoch 273
2024-02-08 10:11:46.754324: Current learning rate: 0.00539
2024-02-08 10:12:29.409246: train_loss -0.579
2024-02-08 10:12:29.411108: val_loss -0.3589
2024-02-08 10:12:29.411645: Pseudo dice [0.8325, 0.8245, 0.7272, 0.8175, 0.8198]
2024-02-08 10:12:29.412120: Epoch time: 42.66 s
2024-02-08 10:12:30.473794: 
2024-02-08 10:12:30.474967: Epoch 274
2024-02-08 10:12:30.476185: Current learning rate: 0.00538
2024-02-08 10:13:13.318847: train_loss -0.5843
2024-02-08 10:13:13.320165: val_loss -0.343
2024-02-08 10:13:13.320611: Pseudo dice [0.828, 0.8186, 0.7315, 0.8299, 0.8278]
2024-02-08 10:13:13.321030: Epoch time: 42.85 s
2024-02-08 10:13:14.481953: 
2024-02-08 10:13:14.483850: Epoch 275
2024-02-08 10:13:14.484655: Current learning rate: 0.00536
2024-02-08 10:13:57.376847: train_loss -0.5861
2024-02-08 10:13:57.378798: val_loss -0.3763
2024-02-08 10:13:57.379319: Pseudo dice [0.8395, 0.8231, 0.737, 0.8469, 0.8205]
2024-02-08 10:13:57.379837: Epoch time: 42.9 s
2024-02-08 10:13:58.413513: 
2024-02-08 10:13:58.414917: Epoch 276
2024-02-08 10:13:58.416131: Current learning rate: 0.00534
2024-02-08 10:14:41.060695: train_loss -0.5826
2024-02-08 10:14:41.062158: val_loss -0.3717
2024-02-08 10:14:41.062728: Pseudo dice [0.8335, 0.8254, 0.7348, 0.8292, 0.8298]
2024-02-08 10:14:41.063192: Epoch time: 42.65 s
2024-02-08 10:14:42.071853: 
2024-02-08 10:14:42.073122: Epoch 277
2024-02-08 10:14:42.074107: Current learning rate: 0.00532
2024-02-08 10:15:24.821604: train_loss -0.5759
2024-02-08 10:15:24.823778: val_loss -0.3657
2024-02-08 10:15:24.824518: Pseudo dice [0.8392, 0.8201, 0.7358, 0.846, 0.823]
2024-02-08 10:15:24.825067: Epoch time: 42.75 s
2024-02-08 10:15:24.825710: Yayy! New best EMA pseudo Dice: 0.8093
2024-02-08 10:15:26.160808: 
2024-02-08 10:15:26.162699: Epoch 278
2024-02-08 10:15:26.163275: Current learning rate: 0.00531
2024-02-08 10:16:09.204355: train_loss -0.5838
2024-02-08 10:16:09.206402: val_loss -0.3348
2024-02-08 10:16:09.206922: Pseudo dice [0.8283, 0.8176, 0.7219, 0.8313, 0.8194]
2024-02-08 10:16:09.207450: Epoch time: 43.04 s
2024-02-08 10:16:10.251768: 
2024-02-08 10:16:10.253908: Epoch 279
2024-02-08 10:16:10.254776: Current learning rate: 0.00529
2024-02-08 10:16:53.266328: train_loss -0.5795
2024-02-08 10:16:53.267968: val_loss -0.3506
2024-02-08 10:16:53.268544: Pseudo dice [0.834, 0.8178, 0.7322, 0.8365, 0.8332]
2024-02-08 10:16:53.269126: Epoch time: 43.02 s
2024-02-08 10:16:54.269131: 
2024-02-08 10:16:54.270271: Epoch 280
2024-02-08 10:16:54.271228: Current learning rate: 0.00527
2024-02-08 10:17:37.128391: train_loss -0.5838
2024-02-08 10:17:37.130757: val_loss -0.3446
2024-02-08 10:17:37.131418: Pseudo dice [0.8333, 0.8148, 0.729, 0.814, 0.8231]
2024-02-08 10:17:37.131995: Epoch time: 42.86 s
2024-02-08 10:17:38.272971: 
2024-02-08 10:17:38.274702: Epoch 281
2024-02-08 10:17:38.275417: Current learning rate: 0.00525
2024-02-08 10:18:21.057054: train_loss -0.5858
2024-02-08 10:18:21.067790: val_loss -0.3525
2024-02-08 10:18:21.068329: Pseudo dice [0.833, 0.8205, 0.7352, 0.8354, 0.8197]
2024-02-08 10:18:21.068839: Epoch time: 42.79 s
2024-02-08 10:18:22.064435: 
2024-02-08 10:18:22.065970: Epoch 282
2024-02-08 10:18:22.066515: Current learning rate: 0.00524
2024-02-08 10:19:04.991530: train_loss -0.5806
2024-02-08 10:19:04.992920: val_loss -0.3553
2024-02-08 10:19:04.993403: Pseudo dice [0.8316, 0.8176, 0.7356, 0.8183, 0.8249]
2024-02-08 10:19:04.993853: Epoch time: 42.93 s
2024-02-08 10:19:05.996148: 
2024-02-08 10:19:05.997268: Epoch 283
2024-02-08 10:19:05.998231: Current learning rate: 0.00522
2024-02-08 10:19:48.983780: train_loss -0.5852
2024-02-08 10:19:48.985265: val_loss -0.3648
2024-02-08 10:19:48.985701: Pseudo dice [0.8352, 0.827, 0.7318, 0.8371, 0.8237]
2024-02-08 10:19:48.986100: Epoch time: 42.99 s
2024-02-08 10:19:50.008715: 
2024-02-08 10:19:50.078165: Epoch 284
2024-02-08 10:19:50.078746: Current learning rate: 0.0052
2024-02-08 10:20:32.949118: train_loss -0.5859
2024-02-08 10:20:32.950890: val_loss -0.3382
2024-02-08 10:20:32.951390: Pseudo dice [0.8309, 0.8199, 0.7241, 0.8265, 0.8238]
2024-02-08 10:20:32.951825: Epoch time: 42.94 s
2024-02-08 10:20:33.992011: 
2024-02-08 10:20:33.993158: Epoch 285
2024-02-08 10:20:33.994303: Current learning rate: 0.00518
2024-02-08 10:21:17.252780: train_loss -0.5883
2024-02-08 10:21:17.254248: val_loss -0.3674
2024-02-08 10:21:17.254745: Pseudo dice [0.8342, 0.8262, 0.7301, 0.8227, 0.8248]
2024-02-08 10:21:17.255213: Epoch time: 43.26 s
2024-02-08 10:21:18.440894: 
2024-02-08 10:21:18.442879: Epoch 286
2024-02-08 10:21:18.443812: Current learning rate: 0.00517
2024-02-08 10:22:01.265972: train_loss -0.5882
2024-02-08 10:22:01.267725: val_loss -0.3527
2024-02-08 10:22:01.268182: Pseudo dice [0.8354, 0.819, 0.7373, 0.8326, 0.8172]
2024-02-08 10:22:01.268597: Epoch time: 42.83 s
2024-02-08 10:22:02.313510: 
2024-02-08 10:22:02.314522: Epoch 287
2024-02-08 10:22:02.315721: Current learning rate: 0.00515
2024-02-08 10:22:45.213072: train_loss -0.5872
2024-02-08 10:22:45.214446: val_loss -0.342
2024-02-08 10:22:45.214924: Pseudo dice [0.8319, 0.8256, 0.7261, 0.815, 0.825]
2024-02-08 10:22:45.215348: Epoch time: 42.9 s
2024-02-08 10:22:46.265517: 
2024-02-08 10:22:46.267444: Epoch 288
2024-02-08 10:22:46.268052: Current learning rate: 0.00513
2024-02-08 10:23:29.092789: train_loss -0.5818
2024-02-08 10:23:29.094512: val_loss -0.3532
2024-02-08 10:23:29.095013: Pseudo dice [0.8332, 0.8212, 0.7295, 0.8299, 0.8249]
2024-02-08 10:23:29.095477: Epoch time: 42.83 s
2024-02-08 10:23:30.112117: 
2024-02-08 10:23:30.113089: Epoch 289
2024-02-08 10:23:30.114206: Current learning rate: 0.00511
2024-02-08 10:24:12.920237: train_loss -0.5802
2024-02-08 10:24:12.921614: val_loss -0.3407
2024-02-08 10:24:12.922056: Pseudo dice [0.8283, 0.8232, 0.7296, 0.8301, 0.8146]
2024-02-08 10:24:12.922482: Epoch time: 42.81 s
2024-02-08 10:24:13.934373: 
2024-02-08 10:24:13.937562: Epoch 290
2024-02-08 10:24:13.938233: Current learning rate: 0.0051
2024-02-08 10:24:56.680499: train_loss -0.5854
2024-02-08 10:24:56.682287: val_loss -0.3624
2024-02-08 10:24:56.682814: Pseudo dice [0.836, 0.8247, 0.7312, 0.8332, 0.8366]
2024-02-08 10:24:56.683274: Epoch time: 42.75 s
2024-02-08 10:24:57.741845: 
2024-02-08 10:24:57.742812: Epoch 291
2024-02-08 10:24:57.743681: Current learning rate: 0.00508
2024-02-08 10:25:40.521098: train_loss -0.5911
2024-02-08 10:25:40.522611: val_loss -0.3754
2024-02-08 10:25:40.523078: Pseudo dice [0.8339, 0.8293, 0.7336, 0.8144, 0.8291]
2024-02-08 10:25:40.523543: Epoch time: 42.78 s
2024-02-08 10:25:41.672059: 
2024-02-08 10:25:41.673707: Epoch 292
2024-02-08 10:25:41.674204: Current learning rate: 0.00506
2024-02-08 10:26:24.457674: train_loss -0.5884
2024-02-08 10:26:24.458984: val_loss -0.3711
2024-02-08 10:26:24.459444: Pseudo dice [0.8359, 0.8221, 0.7384, 0.8247, 0.8254]
2024-02-08 10:26:24.459885: Epoch time: 42.79 s
2024-02-08 10:26:25.489390: 
2024-02-08 10:26:25.490321: Epoch 293
2024-02-08 10:26:25.491174: Current learning rate: 0.00504
2024-02-08 10:27:08.403701: train_loss -0.5822
2024-02-08 10:27:08.405131: val_loss -0.369
2024-02-08 10:27:08.405710: Pseudo dice [0.8332, 0.8187, 0.7365, 0.8261, 0.8245]
2024-02-08 10:27:08.406166: Epoch time: 42.92 s
2024-02-08 10:27:09.425618: 
2024-02-08 10:27:09.426738: Epoch 294
2024-02-08 10:27:09.427792: Current learning rate: 0.00502
2024-02-08 10:27:52.064409: train_loss -0.5836
2024-02-08 10:27:52.065854: val_loss -0.3448
2024-02-08 10:27:52.066294: Pseudo dice [0.8294, 0.8187, 0.7278, 0.8373, 0.8107]
2024-02-08 10:27:52.066719: Epoch time: 42.64 s
2024-02-08 10:27:53.103725: 
2024-02-08 10:27:53.104891: Epoch 295
2024-02-08 10:27:53.105913: Current learning rate: 0.00501
2024-02-08 10:28:36.384726: train_loss -0.5928
2024-02-08 10:28:36.386417: val_loss -0.3438
2024-02-08 10:28:36.386986: Pseudo dice [0.8312, 0.8196, 0.7265, 0.8108, 0.8346]
2024-02-08 10:28:36.387485: Epoch time: 43.28 s
2024-02-08 10:28:37.459122: 
2024-02-08 10:28:37.460389: Epoch 296
2024-02-08 10:28:37.461351: Current learning rate: 0.00499
2024-02-08 10:29:20.402141: train_loss -0.5885
2024-02-08 10:29:20.404104: val_loss -0.3613
2024-02-08 10:29:20.404681: Pseudo dice [0.8359, 0.8294, 0.7327, 0.8297, 0.8183]
2024-02-08 10:29:20.405165: Epoch time: 42.94 s
2024-02-08 10:29:21.764423: 
2024-02-08 10:29:21.765517: Epoch 297
2024-02-08 10:29:21.766776: Current learning rate: 0.00497
2024-02-08 10:30:04.553581: train_loss -0.587
2024-02-08 10:30:04.555040: val_loss -0.3588
2024-02-08 10:30:04.555597: Pseudo dice [0.8339, 0.8226, 0.7342, 0.8285, 0.828]
2024-02-08 10:30:04.556062: Epoch time: 42.79 s
2024-02-08 10:30:05.563981: 
2024-02-08 10:30:05.565585: Epoch 298
2024-02-08 10:30:05.566101: Current learning rate: 0.00495
2024-02-08 10:30:48.183814: train_loss -0.594
2024-02-08 10:30:48.185090: val_loss -0.3601
2024-02-08 10:30:48.185544: Pseudo dice [0.8344, 0.8229, 0.7401, 0.8325, 0.8259]
2024-02-08 10:30:48.185954: Epoch time: 42.62 s
2024-02-08 10:30:49.200357: 
2024-02-08 10:30:49.201443: Epoch 299
2024-02-08 10:30:49.202256: Current learning rate: 0.00494
2024-02-08 10:31:32.029055: train_loss -0.5897
2024-02-08 10:31:32.030880: val_loss -0.3329
2024-02-08 10:31:32.031453: Pseudo dice [0.8329, 0.8181, 0.7264, 0.8161, 0.8256]
2024-02-08 10:31:32.031949: Epoch time: 42.83 s
2024-02-08 10:31:33.382925: 
2024-02-08 10:31:33.383997: Epoch 300
2024-02-08 10:31:33.384473: Current learning rate: 0.00492
2024-02-08 10:32:16.466257: train_loss -0.5959
2024-02-08 10:32:16.467776: val_loss -0.3316
2024-02-08 10:32:16.468316: Pseudo dice [0.8282, 0.8182, 0.7206, 0.817, 0.8221]
2024-02-08 10:32:16.468820: Epoch time: 43.08 s
2024-02-08 10:32:17.502941: 
2024-02-08 10:32:17.504510: Epoch 301
2024-02-08 10:32:17.505129: Current learning rate: 0.0049
2024-02-08 10:33:00.498110: train_loss -0.5922
2024-02-08 10:33:00.499614: val_loss -0.3728
2024-02-08 10:33:00.500097: Pseudo dice [0.8345, 0.8298, 0.7304, 0.8346, 0.8247]
2024-02-08 10:33:00.500523: Epoch time: 43.0 s
2024-02-08 10:33:01.669767: 
2024-02-08 10:33:01.670746: Epoch 302
2024-02-08 10:33:01.671697: Current learning rate: 0.00488
2024-02-08 10:33:44.811901: train_loss -0.593
2024-02-08 10:33:44.813342: val_loss -0.3487
2024-02-08 10:33:44.813853: Pseudo dice [0.8335, 0.8189, 0.7314, 0.8268, 0.8256]
2024-02-08 10:33:44.814283: Epoch time: 43.14 s
2024-02-08 10:33:45.836562: 
2024-02-08 10:33:45.838149: Epoch 303
2024-02-08 10:33:45.838970: Current learning rate: 0.00487
2024-02-08 10:34:29.060747: train_loss -0.59
2024-02-08 10:34:29.062223: val_loss -0.368
2024-02-08 10:34:29.062700: Pseudo dice [0.8353, 0.8245, 0.7386, 0.8204, 0.8272]
2024-02-08 10:34:29.063131: Epoch time: 43.23 s
2024-02-08 10:34:30.090937: 
2024-02-08 10:34:30.092505: Epoch 304
2024-02-08 10:34:30.093037: Current learning rate: 0.00485
2024-02-08 10:35:12.911635: train_loss -0.5945
2024-02-08 10:35:12.912922: val_loss -0.3417
2024-02-08 10:35:12.913397: Pseudo dice [0.8347, 0.8194, 0.7304, 0.8304, 0.8244]
2024-02-08 10:35:12.913859: Epoch time: 42.82 s
2024-02-08 10:35:13.933291: 
2024-02-08 10:35:13.934308: Epoch 305
2024-02-08 10:35:13.935561: Current learning rate: 0.00483
2024-02-08 10:35:56.530111: train_loss -0.5925
2024-02-08 10:35:56.531678: val_loss -0.3471
2024-02-08 10:35:56.532212: Pseudo dice [0.8321, 0.8178, 0.7263, 0.8313, 0.8075]
2024-02-08 10:35:56.532701: Epoch time: 42.6 s
2024-02-08 10:35:57.567595: 
2024-02-08 10:35:57.569152: Epoch 306
2024-02-08 10:35:57.569661: Current learning rate: 0.00481
2024-02-08 10:36:40.206664: train_loss -0.5937
2024-02-08 10:36:40.208114: val_loss -0.3474
2024-02-08 10:36:40.208587: Pseudo dice [0.8275, 0.825, 0.731, 0.8206, 0.8259]
2024-02-08 10:36:40.209030: Epoch time: 42.64 s
2024-02-08 10:36:41.229494: 
2024-02-08 10:36:41.231089: Epoch 307
2024-02-08 10:36:41.231578: Current learning rate: 0.00479
2024-02-08 10:37:23.855423: train_loss -0.5923
2024-02-08 10:37:23.856792: val_loss -0.3593
2024-02-08 10:37:23.857236: Pseudo dice [0.8355, 0.822, 0.7328, 0.8383, 0.822]
2024-02-08 10:37:23.857668: Epoch time: 42.63 s
2024-02-08 10:37:25.001661: 
2024-02-08 10:37:25.002774: Epoch 308
2024-02-08 10:37:25.003648: Current learning rate: 0.00478
2024-02-08 10:38:07.787580: train_loss -0.5912
2024-02-08 10:38:07.789073: val_loss -0.3419
2024-02-08 10:38:07.789551: Pseudo dice [0.836, 0.8209, 0.7256, 0.8388, 0.8231]
2024-02-08 10:38:07.789984: Epoch time: 42.79 s
2024-02-08 10:38:08.814214: 
2024-02-08 10:38:08.815866: Epoch 309
2024-02-08 10:38:08.816410: Current learning rate: 0.00476
2024-02-08 10:38:51.775448: train_loss -0.5917
2024-02-08 10:38:51.776855: val_loss -0.3391
2024-02-08 10:38:51.777324: Pseudo dice [0.8303, 0.8205, 0.7274, 0.8354, 0.8243]
2024-02-08 10:38:51.777777: Epoch time: 42.96 s
2024-02-08 10:38:52.804240: 
2024-02-08 10:38:52.805439: Epoch 310
2024-02-08 10:38:52.806656: Current learning rate: 0.00474
2024-02-08 10:39:36.096426: train_loss -0.5898
2024-02-08 10:39:36.097729: val_loss -0.3755
2024-02-08 10:39:36.098181: Pseudo dice [0.8386, 0.8258, 0.733, 0.8496, 0.8158]
2024-02-08 10:39:36.098656: Epoch time: 43.29 s
2024-02-08 10:39:37.141556: 
2024-02-08 10:39:37.143102: Epoch 311
2024-02-08 10:39:37.144035: Current learning rate: 0.00472
2024-02-08 10:40:20.380357: train_loss -0.5883
2024-02-08 10:40:20.381720: val_loss -0.333
2024-02-08 10:40:20.382205: Pseudo dice [0.8271, 0.8221, 0.7216, 0.8328, 0.8153]
2024-02-08 10:40:20.382628: Epoch time: 43.24 s
2024-02-08 10:40:21.401122: 
2024-02-08 10:40:21.402369: Epoch 312
2024-02-08 10:40:21.403671: Current learning rate: 0.00471
2024-02-08 10:41:04.178841: train_loss -0.598
2024-02-08 10:41:04.180155: val_loss -0.3662
2024-02-08 10:41:04.180632: Pseudo dice [0.8364, 0.8184, 0.7426, 0.8349, 0.8275]
2024-02-08 10:41:04.181060: Epoch time: 42.78 s
2024-02-08 10:41:05.193397: 
2024-02-08 10:41:05.194675: Epoch 313
2024-02-08 10:41:05.195393: Current learning rate: 0.00469
2024-02-08 10:41:47.990712: train_loss -0.596
2024-02-08 10:41:47.991993: val_loss -0.3533
2024-02-08 10:41:47.992439: Pseudo dice [0.8349, 0.8267, 0.7272, 0.8395, 0.8145]
2024-02-08 10:41:47.992843: Epoch time: 42.8 s
2024-02-08 10:41:49.132590: 
2024-02-08 10:41:49.133776: Epoch 314
2024-02-08 10:41:49.134781: Current learning rate: 0.00467
2024-02-08 10:42:32.107519: train_loss -0.5973
2024-02-08 10:42:32.108938: val_loss -0.3572
2024-02-08 10:42:32.109440: Pseudo dice [0.8371, 0.8242, 0.7315, 0.8392, 0.8235]
2024-02-08 10:42:32.109869: Epoch time: 42.98 s
2024-02-08 10:42:33.131963: 
2024-02-08 10:42:33.133362: Epoch 315
2024-02-08 10:42:33.134543: Current learning rate: 0.00465
2024-02-08 10:43:16.440527: train_loss -0.6008
2024-02-08 10:43:16.442070: val_loss -0.3415
2024-02-08 10:43:16.442557: Pseudo dice [0.8295, 0.8219, 0.7335, 0.8312, 0.8266]
2024-02-08 10:43:16.442996: Epoch time: 43.31 s
2024-02-08 10:43:17.485300: 
2024-02-08 10:43:17.486350: Epoch 316
2024-02-08 10:43:17.487357: Current learning rate: 0.00463
2024-02-08 10:44:00.734019: train_loss -0.595
2024-02-08 10:44:00.735884: val_loss -0.3518
2024-02-08 10:44:00.736456: Pseudo dice [0.837, 0.8246, 0.727, 0.8228, 0.8175]
2024-02-08 10:44:00.737164: Epoch time: 43.25 s
2024-02-08 10:44:01.769841: 
2024-02-08 10:44:01.771540: Epoch 317
2024-02-08 10:44:01.772149: Current learning rate: 0.00462
2024-02-08 10:44:44.818770: train_loss -0.5986
2024-02-08 10:44:44.820075: val_loss -0.3036
2024-02-08 10:44:44.820542: Pseudo dice [0.8226, 0.8122, 0.7204, 0.8163, 0.8054]
2024-02-08 10:44:44.820978: Epoch time: 43.05 s
2024-02-08 10:44:45.847205: 
2024-02-08 10:44:45.848361: Epoch 318
2024-02-08 10:44:45.849307: Current learning rate: 0.0046
2024-02-08 10:45:28.919228: train_loss -0.595
2024-02-08 10:45:28.921099: val_loss -0.3527
2024-02-08 10:45:28.921663: Pseudo dice [0.8355, 0.822, 0.7364, 0.8331, 0.8196]
2024-02-08 10:45:28.922194: Epoch time: 43.07 s
2024-02-08 10:45:30.299562: 
2024-02-08 10:45:30.301055: Epoch 319
2024-02-08 10:45:30.301693: Current learning rate: 0.00458
2024-02-08 10:46:13.433417: train_loss -0.5974
2024-02-08 10:46:13.434834: val_loss -0.3585
2024-02-08 10:46:13.435318: Pseudo dice [0.8367, 0.8237, 0.731, 0.8293, 0.8286]
2024-02-08 10:46:13.435768: Epoch time: 43.14 s
2024-02-08 10:46:14.454885: 
2024-02-08 10:46:14.455921: Epoch 320
2024-02-08 10:46:14.456860: Current learning rate: 0.00456
2024-02-08 10:46:57.591887: train_loss -0.5968
2024-02-08 10:46:57.593246: val_loss -0.3401
2024-02-08 10:46:57.593700: Pseudo dice [0.8325, 0.8214, 0.7314, 0.8371, 0.8125]
2024-02-08 10:46:57.594170: Epoch time: 43.14 s
2024-02-08 10:46:58.614955: 
2024-02-08 10:46:58.616492: Epoch 321
2024-02-08 10:46:58.616996: Current learning rate: 0.00454
2024-02-08 10:47:41.467540: train_loss -0.6014
2024-02-08 10:47:41.468964: val_loss -0.3764
2024-02-08 10:47:41.469448: Pseudo dice [0.8398, 0.8245, 0.7393, 0.8368, 0.8359]
2024-02-08 10:47:41.469882: Epoch time: 42.85 s
2024-02-08 10:47:42.485238: 
2024-02-08 10:47:42.486212: Epoch 322
2024-02-08 10:47:42.487132: Current learning rate: 0.00453
2024-02-08 10:48:25.456049: train_loss -0.5949
2024-02-08 10:48:25.459668: val_loss -0.372
2024-02-08 10:48:25.461615: Pseudo dice [0.8382, 0.8271, 0.7433, 0.8341, 0.8174]
2024-02-08 10:48:25.462110: Epoch time: 42.97 s
2024-02-08 10:48:26.534568: 
2024-02-08 10:48:26.535851: Epoch 323
2024-02-08 10:48:26.536400: Current learning rate: 0.00451
2024-02-08 10:49:09.887563: train_loss -0.5933
2024-02-08 10:49:09.889131: val_loss -0.3567
2024-02-08 10:49:09.889648: Pseudo dice [0.8356, 0.8239, 0.7307, 0.84, 0.8131]
2024-02-08 10:49:09.890104: Epoch time: 43.35 s
2024-02-08 10:49:10.983939: 
2024-02-08 10:49:10.985094: Epoch 324
2024-02-08 10:49:10.986166: Current learning rate: 0.00449
2024-02-08 10:49:54.259953: train_loss -0.593
2024-02-08 10:49:54.261554: val_loss -0.3393
2024-02-08 10:49:54.262076: Pseudo dice [0.8314, 0.8234, 0.7249, 0.8271, 0.8294]
2024-02-08 10:49:54.262549: Epoch time: 43.28 s
2024-02-08 10:49:55.437253: 
2024-02-08 10:49:55.438301: Epoch 325
2024-02-08 10:49:55.439169: Current learning rate: 0.00447
2024-02-08 10:50:38.335558: train_loss -0.5994
2024-02-08 10:50:38.337080: val_loss -0.3376
2024-02-08 10:50:38.337572: Pseudo dice [0.8333, 0.8245, 0.7266, 0.8275, 0.8218]
2024-02-08 10:50:38.338036: Epoch time: 42.9 s
2024-02-08 10:50:39.370337: 
2024-02-08 10:50:39.371443: Epoch 326
2024-02-08 10:50:39.372325: Current learning rate: 0.00446
2024-02-08 10:51:22.453198: train_loss -0.601
2024-02-08 10:51:22.454883: val_loss -0.3147
2024-02-08 10:51:22.455350: Pseudo dice [0.8278, 0.8125, 0.7274, 0.8195, 0.8209]
2024-02-08 10:51:22.455748: Epoch time: 43.08 s
2024-02-08 10:51:23.478821: 
2024-02-08 10:51:23.480332: Epoch 327
2024-02-08 10:51:23.480829: Current learning rate: 0.00444
2024-02-08 10:52:06.693625: train_loss -0.5967
2024-02-08 10:52:06.695226: val_loss -0.3428
2024-02-08 10:52:06.695717: Pseudo dice [0.8344, 0.8175, 0.7316, 0.8266, 0.8371]
2024-02-08 10:52:06.696169: Epoch time: 43.22 s
2024-02-08 10:52:07.724027: 
2024-02-08 10:52:07.725409: Epoch 328
2024-02-08 10:52:07.725916: Current learning rate: 0.00442
2024-02-08 10:52:50.856714: train_loss -0.5991
2024-02-08 10:52:50.858164: val_loss -0.3744
2024-02-08 10:52:50.858904: Pseudo dice [0.8424, 0.824, 0.7378, 0.8471, 0.8328]
2024-02-08 10:52:50.859384: Epoch time: 43.13 s
2024-02-08 10:52:51.887434: 
2024-02-08 10:52:51.888525: Epoch 329
2024-02-08 10:52:51.889642: Current learning rate: 0.0044
2024-02-08 10:53:34.847751: train_loss -0.5959
2024-02-08 10:53:34.849324: val_loss -0.3269
2024-02-08 10:53:34.849815: Pseudo dice [0.8302, 0.8194, 0.723, 0.8221, 0.8212]
2024-02-08 10:53:34.850238: Epoch time: 42.96 s
2024-02-08 10:53:36.157155: 
2024-02-08 10:53:36.158311: Epoch 330
2024-02-08 10:53:36.159256: Current learning rate: 0.00438
2024-02-08 10:54:19.125915: train_loss -0.5927
2024-02-08 10:54:19.127834: val_loss -0.3317
2024-02-08 10:54:19.128386: Pseudo dice [0.8288, 0.8202, 0.7256, 0.8175, 0.8221]
2024-02-08 10:54:19.128867: Epoch time: 42.97 s
2024-02-08 10:54:20.222955: 
2024-02-08 10:54:20.224641: Epoch 331
2024-02-08 10:54:20.225299: Current learning rate: 0.00437
2024-02-08 10:55:02.999998: train_loss -0.5949
2024-02-08 10:55:03.001410: val_loss -0.372
2024-02-08 10:55:03.001942: Pseudo dice [0.8381, 0.8277, 0.7303, 0.8413, 0.8289]
2024-02-08 10:55:03.002495: Epoch time: 42.78 s
2024-02-08 10:55:04.017774: 
2024-02-08 10:55:04.018830: Epoch 332
2024-02-08 10:55:04.019797: Current learning rate: 0.00435
2024-02-08 10:55:46.755118: train_loss -0.5966
2024-02-08 10:55:46.756731: val_loss -0.341
2024-02-08 10:55:46.757230: Pseudo dice [0.8318, 0.8236, 0.7227, 0.8305, 0.8332]
2024-02-08 10:55:46.757656: Epoch time: 42.74 s
2024-02-08 10:55:47.795205: 
2024-02-08 10:55:47.796662: Epoch 333
2024-02-08 10:55:47.797124: Current learning rate: 0.00433
2024-02-08 10:56:30.850196: train_loss -0.5956
2024-02-08 10:56:30.852136: val_loss -0.3626
2024-02-08 10:56:30.852675: Pseudo dice [0.8331, 0.8251, 0.7396, 0.838, 0.8209]
2024-02-08 10:56:30.853138: Epoch time: 43.06 s
2024-02-08 10:56:31.918574: 
2024-02-08 10:56:31.920017: Epoch 334
2024-02-08 10:56:31.920644: Current learning rate: 0.00431
2024-02-08 10:57:15.051055: train_loss -0.6005
2024-02-08 10:57:15.052580: val_loss -0.3595
2024-02-08 10:57:15.053066: Pseudo dice [0.8379, 0.8245, 0.7353, 0.8316, 0.8105]
2024-02-08 10:57:15.053526: Epoch time: 43.13 s
2024-02-08 10:57:16.229793: 
2024-02-08 10:57:16.230849: Epoch 335
2024-02-08 10:57:16.231697: Current learning rate: 0.00429
2024-02-08 10:57:59.025887: train_loss -0.6003
2024-02-08 10:57:59.027355: val_loss -0.3506
2024-02-08 10:57:59.027865: Pseudo dice [0.8326, 0.8154, 0.732, 0.8173, 0.8235]
2024-02-08 10:57:59.028481: Epoch time: 42.8 s
2024-02-08 10:58:00.087432: 
2024-02-08 10:58:00.088499: Epoch 336
2024-02-08 10:58:00.089710: Current learning rate: 0.00428
2024-02-08 10:58:42.963051: train_loss -0.5957
2024-02-08 10:58:42.964356: val_loss -0.339
2024-02-08 10:58:42.964794: Pseudo dice [0.8304, 0.8186, 0.7292, 0.8302, 0.824]
2024-02-08 10:58:42.965232: Epoch time: 42.88 s
2024-02-08 10:58:44.005593: 
2024-02-08 10:58:44.006965: Epoch 337
2024-02-08 10:58:44.007493: Current learning rate: 0.00426
2024-02-08 10:59:27.362690: train_loss -0.5946
2024-02-08 10:59:27.364064: val_loss -0.335
2024-02-08 10:59:27.364534: Pseudo dice [0.8319, 0.8163, 0.7211, 0.8327, 0.8166]
2024-02-08 10:59:27.364921: Epoch time: 43.36 s
2024-02-08 10:59:28.460171: 
2024-02-08 10:59:28.461631: Epoch 338
2024-02-08 10:59:28.462667: Current learning rate: 0.00424
2024-02-08 11:00:11.740921: train_loss -0.5995
2024-02-08 11:00:11.742787: val_loss -0.3111
2024-02-08 11:00:11.743363: Pseudo dice [0.8249, 0.8207, 0.7135, 0.8208, 0.8216]
2024-02-08 11:00:11.743877: Epoch time: 43.28 s
2024-02-08 11:00:12.850239: 
2024-02-08 11:00:12.851684: Epoch 339
2024-02-08 11:00:12.852194: Current learning rate: 0.00422
2024-02-08 11:00:56.035574: train_loss -0.6004
2024-02-08 11:00:56.037291: val_loss -0.368
2024-02-08 11:00:56.037818: Pseudo dice [0.8391, 0.8244, 0.7396, 0.8383, 0.8329]
2024-02-08 11:00:56.038245: Epoch time: 43.19 s
2024-02-08 11:00:57.375210: 
2024-02-08 11:00:57.376244: Epoch 340
2024-02-08 11:00:57.377197: Current learning rate: 0.0042
2024-02-08 11:01:40.570495: train_loss -0.5952
2024-02-08 11:01:40.572141: val_loss -0.35
2024-02-08 11:01:40.572643: Pseudo dice [0.8351, 0.8206, 0.7271, 0.8358, 0.8308]
2024-02-08 11:01:40.573094: Epoch time: 43.2 s
2024-02-08 11:01:41.622556: 
2024-02-08 11:01:41.624051: Epoch 341
2024-02-08 11:01:41.624579: Current learning rate: 0.00419
2024-02-08 11:02:24.837913: train_loss -0.6024
2024-02-08 11:02:24.839863: val_loss -0.3303
2024-02-08 11:02:24.840416: Pseudo dice [0.8321, 0.8155, 0.7287, 0.8308, 0.8231]
2024-02-08 11:02:24.840892: Epoch time: 43.22 s
2024-02-08 11:02:25.930802: 
2024-02-08 11:02:25.932367: Epoch 342
2024-02-08 11:02:25.932882: Current learning rate: 0.00417
2024-02-08 11:03:09.021621: train_loss -0.6042
2024-02-08 11:03:09.022897: val_loss -0.3575
2024-02-08 11:03:09.023346: Pseudo dice [0.8338, 0.8226, 0.7273, 0.8372, 0.832]
2024-02-08 11:03:09.023773: Epoch time: 43.09 s
2024-02-08 11:03:10.067536: 
2024-02-08 11:03:10.069171: Epoch 343
2024-02-08 11:03:10.069701: Current learning rate: 0.00415
2024-02-08 11:03:52.890435: train_loss -0.5986
2024-02-08 11:03:52.891795: val_loss -0.3469
2024-02-08 11:03:52.892247: Pseudo dice [0.8352, 0.8224, 0.7275, 0.838, 0.8201]
2024-02-08 11:03:52.892653: Epoch time: 42.82 s
2024-02-08 11:03:53.930898: 
2024-02-08 11:03:53.932425: Epoch 344
2024-02-08 11:03:53.932889: Current learning rate: 0.00413
2024-02-08 11:04:36.718786: train_loss -0.6026
2024-02-08 11:04:36.723464: val_loss -0.3507
2024-02-08 11:04:36.724680: Pseudo dice [0.838, 0.8203, 0.7333, 0.8255, 0.8339]
2024-02-08 11:04:36.725096: Epoch time: 42.79 s
2024-02-08 11:04:37.922374: 
2024-02-08 11:04:37.923644: Epoch 345
2024-02-08 11:04:37.924131: Current learning rate: 0.00411
2024-02-08 11:05:20.749177: train_loss -0.607
2024-02-08 11:05:20.750811: val_loss -0.3614
2024-02-08 11:05:20.751318: Pseudo dice [0.8366, 0.8277, 0.7347, 0.8342, 0.8228]
2024-02-08 11:05:20.751782: Epoch time: 42.83 s
2024-02-08 11:05:21.858355: 
2024-02-08 11:05:21.859879: Epoch 346
2024-02-08 11:05:21.860420: Current learning rate: 0.0041
2024-02-08 11:06:04.705417: train_loss -0.6028
2024-02-08 11:06:04.706683: val_loss -0.3647
2024-02-08 11:06:04.707132: Pseudo dice [0.8379, 0.8294, 0.7369, 0.8317, 0.832]
2024-02-08 11:06:04.707551: Epoch time: 42.85 s
2024-02-08 11:06:05.750442: 
2024-02-08 11:06:05.751688: Epoch 347
2024-02-08 11:06:05.752568: Current learning rate: 0.00408
2024-02-08 11:06:48.681151: train_loss -0.6027
2024-02-08 11:06:48.682852: val_loss -0.3426
2024-02-08 11:06:48.683357: Pseudo dice [0.8315, 0.8269, 0.7285, 0.8288, 0.8176]
2024-02-08 11:06:48.683827: Epoch time: 42.93 s
2024-02-08 11:06:49.756336: 
2024-02-08 11:06:49.757793: Epoch 348
2024-02-08 11:06:49.758319: Current learning rate: 0.00406
2024-02-08 11:07:32.486419: train_loss -0.6014
2024-02-08 11:07:32.487767: val_loss -0.3676
2024-02-08 11:07:32.488229: Pseudo dice [0.8355, 0.8201, 0.7342, 0.8331, 0.8273]
2024-02-08 11:07:32.488667: Epoch time: 42.73 s
2024-02-08 11:07:33.527141: 
2024-02-08 11:07:33.528602: Epoch 349
2024-02-08 11:07:33.529088: Current learning rate: 0.00404
2024-02-08 11:08:16.047854: train_loss -0.605
2024-02-08 11:08:16.049537: val_loss -0.3514
2024-02-08 11:08:16.050038: Pseudo dice [0.834, 0.8236, 0.7279, 0.8336, 0.824]
2024-02-08 11:08:16.050495: Epoch time: 42.52 s
2024-02-08 11:08:17.527000: 
2024-02-08 11:08:17.528099: Epoch 350
2024-02-08 11:08:17.529026: Current learning rate: 0.00402
2024-02-08 11:09:00.558128: train_loss -0.5937
2024-02-08 11:09:00.559687: val_loss -0.3576
2024-02-08 11:09:00.560168: Pseudo dice [0.838, 0.8228, 0.732, 0.8322, 0.8331]
2024-02-08 11:09:00.560614: Epoch time: 43.03 s
2024-02-08 11:09:01.641397: 
2024-02-08 11:09:01.642603: Epoch 351
2024-02-08 11:09:01.643801: Current learning rate: 0.00401
2024-02-08 11:09:44.961176: train_loss -0.5992
2024-02-08 11:09:44.964018: val_loss -0.3435
2024-02-08 11:09:44.964609: Pseudo dice [0.8329, 0.8231, 0.7329, 0.8233, 0.8177]
2024-02-08 11:09:44.965163: Epoch time: 43.32 s
2024-02-08 11:09:46.042820: 
2024-02-08 11:09:46.044573: Epoch 352
2024-02-08 11:09:46.045175: Current learning rate: 0.00399
2024-02-08 11:10:29.275094: train_loss -0.608
2024-02-08 11:10:29.276654: val_loss -0.3123
2024-02-08 11:10:29.277145: Pseudo dice [0.8272, 0.8187, 0.723, 0.8364, 0.8149]
2024-02-08 11:10:29.277650: Epoch time: 43.23 s
2024-02-08 11:10:30.353746: 
2024-02-08 11:10:30.373739: Epoch 353
2024-02-08 11:10:30.374438: Current learning rate: 0.00397
2024-02-08 11:11:13.435021: train_loss -0.6026
2024-02-08 11:11:13.436404: val_loss -0.3512
2024-02-08 11:11:13.436898: Pseudo dice [0.8373, 0.8246, 0.7342, 0.8371, 0.8189]
2024-02-08 11:11:13.437335: Epoch time: 43.08 s
2024-02-08 11:11:14.515122: 
2024-02-08 11:11:14.516771: Epoch 354
2024-02-08 11:11:14.517384: Current learning rate: 0.00395
2024-02-08 11:11:57.485896: train_loss -0.611
2024-02-08 11:11:57.487160: val_loss -0.3405
2024-02-08 11:11:57.487854: Pseudo dice [0.8338, 0.8222, 0.7263, 0.8227, 0.8275]
2024-02-08 11:11:57.488350: Epoch time: 42.97 s
2024-02-08 11:11:58.713362: 
2024-02-08 11:11:58.715461: Epoch 355
2024-02-08 11:11:58.716402: Current learning rate: 0.00393
2024-02-08 11:12:41.873501: train_loss -0.6062
2024-02-08 11:12:41.875083: val_loss -0.3459
2024-02-08 11:12:41.875567: Pseudo dice [0.8335, 0.8213, 0.7346, 0.8371, 0.8177]
2024-02-08 11:12:41.876022: Epoch time: 43.16 s
2024-02-08 11:12:42.959851: 
2024-02-08 11:12:42.961037: Epoch 356
2024-02-08 11:12:42.961964: Current learning rate: 0.00391
2024-02-08 11:13:25.891973: train_loss -0.6062
2024-02-08 11:13:25.893510: val_loss -0.3442
2024-02-08 11:13:25.894057: Pseudo dice [0.831, 0.8216, 0.7325, 0.8377, 0.8181]
2024-02-08 11:13:25.894508: Epoch time: 42.93 s
2024-02-08 11:13:26.987854: 
2024-02-08 11:13:26.988799: Epoch 357
2024-02-08 11:13:26.989687: Current learning rate: 0.0039
2024-02-08 11:14:09.568693: train_loss -0.6074
2024-02-08 11:14:09.569998: val_loss -0.3537
2024-02-08 11:14:09.570455: Pseudo dice [0.8348, 0.8266, 0.7318, 0.8227, 0.8171]
2024-02-08 11:14:09.570860: Epoch time: 42.58 s
2024-02-08 11:14:10.642869: 
2024-02-08 11:14:10.644137: Epoch 358
2024-02-08 11:14:10.645244: Current learning rate: 0.00388
2024-02-08 11:14:53.883371: train_loss -0.6081
2024-02-08 11:14:53.884736: val_loss -0.3495
2024-02-08 11:14:53.885224: Pseudo dice [0.8373, 0.822, 0.7289, 0.8368, 0.8255]
2024-02-08 11:14:53.885651: Epoch time: 43.24 s
2024-02-08 11:14:54.974792: 
2024-02-08 11:14:54.975783: Epoch 359
2024-02-08 11:14:54.976664: Current learning rate: 0.00386
2024-02-08 11:15:38.195267: train_loss -0.6064
2024-02-08 11:15:38.196710: val_loss -0.3614
2024-02-08 11:15:38.197404: Pseudo dice [0.8365, 0.8284, 0.7343, 0.8365, 0.8272]
2024-02-08 11:15:38.197886: Epoch time: 43.22 s
2024-02-08 11:15:39.280393: 
2024-02-08 11:15:39.281457: Epoch 360
2024-02-08 11:15:39.282644: Current learning rate: 0.00384
2024-02-08 11:16:22.421111: train_loss -0.6037
2024-02-08 11:16:22.422958: val_loss -0.3607
2024-02-08 11:16:22.423579: Pseudo dice [0.8364, 0.8288, 0.7299, 0.8377, 0.8229]
2024-02-08 11:16:22.424087: Epoch time: 43.14 s
2024-02-08 11:16:23.636612: 
2024-02-08 11:16:23.637558: Epoch 361
2024-02-08 11:16:23.638420: Current learning rate: 0.00382
2024-02-08 11:17:06.701370: train_loss -0.61
2024-02-08 11:17:06.702788: val_loss -0.3537
2024-02-08 11:17:06.703440: Pseudo dice [0.8383, 0.824, 0.7346, 0.8392, 0.8281]
2024-02-08 11:17:06.703840: Epoch time: 43.07 s
2024-02-08 11:17:06.704213: Yayy! New best EMA pseudo Dice: 0.8094
2024-02-08 11:17:07.982532: 
2024-02-08 11:17:07.983580: Epoch 362
2024-02-08 11:17:07.984646: Current learning rate: 0.00381
2024-02-08 11:17:50.783206: train_loss -0.6095
2024-02-08 11:17:50.784632: val_loss -0.3663
2024-02-08 11:17:50.785131: Pseudo dice [0.8375, 0.8263, 0.7351, 0.8422, 0.8301]
2024-02-08 11:17:50.785592: Epoch time: 42.8 s
2024-02-08 11:17:50.785986: Yayy! New best EMA pseudo Dice: 0.8099
2024-02-08 11:17:52.124708: 
2024-02-08 11:17:52.125707: Epoch 363
2024-02-08 11:17:52.126570: Current learning rate: 0.00379
2024-02-08 11:18:35.136137: train_loss -0.6071
2024-02-08 11:18:35.138758: val_loss -0.3728
2024-02-08 11:18:35.139409: Pseudo dice [0.8403, 0.8234, 0.744, 0.8395, 0.8207]
2024-02-08 11:18:35.140101: Epoch time: 43.01 s
2024-02-08 11:18:35.140653: Yayy! New best EMA pseudo Dice: 0.8103
2024-02-08 11:18:36.513622: 
2024-02-08 11:18:36.514777: Epoch 364
2024-02-08 11:18:36.516021: Current learning rate: 0.00377
2024-02-08 11:19:19.418092: train_loss -0.6028
2024-02-08 11:19:19.419487: val_loss -0.3631
2024-02-08 11:19:19.419952: Pseudo dice [0.8392, 0.8268, 0.7319, 0.8368, 0.8303]
2024-02-08 11:19:19.420387: Epoch time: 42.91 s
2024-02-08 11:19:19.420808: Yayy! New best EMA pseudo Dice: 0.8105
2024-02-08 11:19:20.887834: 
2024-02-08 11:19:20.889374: Epoch 365
2024-02-08 11:19:20.889939: Current learning rate: 0.00375
2024-02-08 11:20:04.126231: train_loss -0.6033
2024-02-08 11:20:04.147722: val_loss -0.3645
2024-02-08 11:20:04.148194: Pseudo dice [0.8355, 0.8288, 0.7308, 0.829, 0.8376]
2024-02-08 11:20:04.152472: Epoch time: 43.24 s
2024-02-08 11:20:04.160847: Yayy! New best EMA pseudo Dice: 0.8107
2024-02-08 11:20:05.807345: 
2024-02-08 11:20:05.808471: Epoch 366
2024-02-08 11:20:05.808992: Current learning rate: 0.00373
2024-02-08 11:20:48.830958: train_loss -0.602
2024-02-08 11:20:48.832437: val_loss -0.3686
2024-02-08 11:20:48.832855: Pseudo dice [0.8317, 0.8261, 0.7383, 0.8292, 0.8234]
2024-02-08 11:20:48.833300: Epoch time: 43.02 s
2024-02-08 11:20:49.903540: 
2024-02-08 11:20:49.904675: Epoch 367
2024-02-08 11:20:49.905633: Current learning rate: 0.00371
2024-02-08 11:21:33.090016: train_loss -0.6034
2024-02-08 11:21:33.091696: val_loss -0.3774
2024-02-08 11:21:33.092189: Pseudo dice [0.8356, 0.8324, 0.74, 0.8378, 0.8262]
2024-02-08 11:21:33.092639: Epoch time: 43.19 s
2024-02-08 11:21:33.093048: Yayy! New best EMA pseudo Dice: 0.811
2024-02-08 11:21:34.478866: 
2024-02-08 11:21:34.479877: Epoch 368
2024-02-08 11:21:34.480735: Current learning rate: 0.0037
2024-02-08 11:22:17.871136: train_loss -0.6115
2024-02-08 11:22:17.872518: val_loss -0.3379
2024-02-08 11:22:17.872985: Pseudo dice [0.8318, 0.8198, 0.7355, 0.8197, 0.8197]
2024-02-08 11:22:17.873449: Epoch time: 43.39 s
2024-02-08 11:22:18.915373: 
2024-02-08 11:22:18.916480: Epoch 369
2024-02-08 11:22:18.917326: Current learning rate: 0.00368
2024-02-08 11:23:02.218587: train_loss -0.6044
2024-02-08 11:23:02.220384: val_loss -0.3251
2024-02-08 11:23:02.220910: Pseudo dice [0.8287, 0.8181, 0.7283, 0.8141, 0.8283]
2024-02-08 11:23:02.221404: Epoch time: 43.3 s
2024-02-08 11:23:03.397334: 
2024-02-08 11:23:03.398245: Epoch 370
2024-02-08 11:23:03.399072: Current learning rate: 0.00366
2024-02-08 11:23:46.286119: train_loss -0.6113
2024-02-08 11:23:46.287477: val_loss -0.3569
2024-02-08 11:23:46.287909: Pseudo dice [0.8366, 0.8237, 0.7334, 0.8345, 0.82]
2024-02-08 11:23:46.288341: Epoch time: 42.89 s
2024-02-08 11:23:47.316867: 
2024-02-08 11:23:47.318606: Epoch 371
2024-02-08 11:23:47.319225: Current learning rate: 0.00364
2024-02-08 11:24:30.241291: train_loss -0.6085
2024-02-08 11:24:30.242593: val_loss -0.3423
2024-02-08 11:24:30.243071: Pseudo dice [0.8324, 0.8226, 0.7306, 0.8308, 0.8194]
2024-02-08 11:24:30.243495: Epoch time: 42.93 s
2024-02-08 11:24:31.285969: 
2024-02-08 11:24:31.287271: Epoch 372
2024-02-08 11:24:31.287755: Current learning rate: 0.00362
2024-02-08 11:25:14.650259: train_loss -0.6081
2024-02-08 11:25:14.651715: val_loss -0.3619
2024-02-08 11:25:14.652196: Pseudo dice [0.8371, 0.829, 0.734, 0.8351, 0.8269]
2024-02-08 11:25:14.652652: Epoch time: 43.37 s
2024-02-08 11:25:15.712659: 
2024-02-08 11:25:15.713883: Epoch 373
2024-02-08 11:25:15.714835: Current learning rate: 0.0036
2024-02-08 11:25:59.056688: train_loss -0.6084
2024-02-08 11:25:59.058486: val_loss -0.3651
2024-02-08 11:25:59.059002: Pseudo dice [0.8357, 0.828, 0.7289, 0.8333, 0.8389]
2024-02-08 11:25:59.059537: Epoch time: 43.35 s
2024-02-08 11:26:00.116260: 
2024-02-08 11:26:00.117416: Epoch 374
2024-02-08 11:26:00.118593: Current learning rate: 0.00359
2024-02-08 11:26:43.219079: train_loss -0.6163
2024-02-08 11:26:43.220613: val_loss -0.3392
2024-02-08 11:26:43.221096: Pseudo dice [0.8338, 0.8249, 0.727, 0.8259, 0.8173]
2024-02-08 11:26:43.221510: Epoch time: 43.1 s
2024-02-08 11:26:44.288177: 
2024-02-08 11:26:44.289164: Epoch 375
2024-02-08 11:26:44.290182: Current learning rate: 0.00357
2024-02-08 11:27:27.564720: train_loss -0.606
2024-02-08 11:27:27.566171: val_loss -0.3648
2024-02-08 11:27:27.566667: Pseudo dice [0.8379, 0.8291, 0.7372, 0.8382, 0.8225]
2024-02-08 11:27:27.567106: Epoch time: 43.28 s
2024-02-08 11:27:28.938506: 
2024-02-08 11:27:28.939671: Epoch 376
2024-02-08 11:27:28.940611: Current learning rate: 0.00355
2024-02-08 11:28:12.163901: train_loss -0.6168
2024-02-08 11:28:12.165337: val_loss -0.3462
2024-02-08 11:28:12.165816: Pseudo dice [0.8344, 0.8219, 0.7262, 0.8215, 0.8199]
2024-02-08 11:28:12.166301: Epoch time: 43.23 s
2024-02-08 11:28:13.226916: 
2024-02-08 11:28:13.228595: Epoch 377
2024-02-08 11:28:13.229123: Current learning rate: 0.00353
2024-02-08 11:28:56.358403: train_loss -0.6125
2024-02-08 11:28:56.359914: val_loss -0.3227
2024-02-08 11:28:56.360519: Pseudo dice [0.8346, 0.8211, 0.7262, 0.8336, 0.8184]
2024-02-08 11:28:56.361006: Epoch time: 43.13 s
2024-02-08 11:28:57.420829: 
2024-02-08 11:28:57.422327: Epoch 378
2024-02-08 11:28:57.422863: Current learning rate: 0.00351
2024-02-08 11:29:39.993018: train_loss -0.6089
2024-02-08 11:29:39.994612: val_loss -0.3253
2024-02-08 11:29:39.995106: Pseudo dice [0.8254, 0.8218, 0.7213, 0.8394, 0.8265]
2024-02-08 11:29:39.995697: Epoch time: 42.57 s
2024-02-08 11:29:41.057188: 
2024-02-08 11:29:41.058747: Epoch 379
2024-02-08 11:29:41.059230: Current learning rate: 0.00349
2024-02-08 11:30:23.997967: train_loss -0.6123
2024-02-08 11:30:23.999525: val_loss -0.3561
2024-02-08 11:30:24.000051: Pseudo dice [0.8355, 0.8168, 0.7405, 0.847, 0.8194]
2024-02-08 11:30:24.000506: Epoch time: 42.94 s
2024-02-08 11:30:25.048617: 
2024-02-08 11:30:25.050318: Epoch 380
2024-02-08 11:30:25.050852: Current learning rate: 0.00348
2024-02-08 11:31:07.910854: train_loss -0.6178
2024-02-08 11:31:07.912349: val_loss -0.3574
2024-02-08 11:31:07.912867: Pseudo dice [0.8356, 0.8247, 0.7335, 0.8407, 0.8271]
2024-02-08 11:31:07.913304: Epoch time: 42.86 s
2024-02-08 11:31:09.277497: 
2024-02-08 11:31:09.279190: Epoch 381
2024-02-08 11:31:09.280365: Current learning rate: 0.00346
2024-02-08 11:31:52.479100: train_loss -0.6127
2024-02-08 11:31:52.480503: val_loss -0.3423
2024-02-08 11:31:52.480987: Pseudo dice [0.8326, 0.8233, 0.732, 0.8401, 0.8228]
2024-02-08 11:31:52.481409: Epoch time: 43.2 s
2024-02-08 11:31:53.536155: 
2024-02-08 11:31:53.537195: Epoch 382
2024-02-08 11:31:53.538306: Current learning rate: 0.00344
2024-02-08 11:32:36.486309: train_loss -0.6114
2024-02-08 11:32:36.487897: val_loss -0.3583
2024-02-08 11:32:36.488395: Pseudo dice [0.8378, 0.8245, 0.7416, 0.8363, 0.8223]
2024-02-08 11:32:36.488815: Epoch time: 42.95 s
2024-02-08 11:32:37.554855: 
2024-02-08 11:32:37.556391: Epoch 383
2024-02-08 11:32:37.557164: Current learning rate: 0.00342
2024-02-08 11:33:20.607268: train_loss -0.6088
2024-02-08 11:33:20.608709: val_loss -0.3685
2024-02-08 11:33:20.609174: Pseudo dice [0.834, 0.8291, 0.7382, 0.8399, 0.8252]
2024-02-08 11:33:20.609591: Epoch time: 43.05 s
2024-02-08 11:33:21.695997: 
2024-02-08 11:33:21.697140: Epoch 384
2024-02-08 11:33:21.698031: Current learning rate: 0.0034
2024-02-08 11:34:04.694294: train_loss -0.6091
2024-02-08 11:34:04.695606: val_loss -0.3429
2024-02-08 11:34:04.696057: Pseudo dice [0.8337, 0.8228, 0.7335, 0.8291, 0.8295]
2024-02-08 11:34:04.696467: Epoch time: 43.0 s
2024-02-08 11:34:05.766082: 
2024-02-08 11:34:05.767715: Epoch 385
2024-02-08 11:34:05.768399: Current learning rate: 0.00338
2024-02-08 11:34:48.720853: train_loss -0.6022
2024-02-08 11:34:48.722151: val_loss -0.3161
2024-02-08 11:34:48.722640: Pseudo dice [0.827, 0.8118, 0.7286, 0.8346, 0.8138]
2024-02-08 11:34:48.723085: Epoch time: 42.96 s
2024-02-08 11:34:50.009576: 
2024-02-08 11:34:50.011193: Epoch 386
2024-02-08 11:34:50.012143: Current learning rate: 0.00337
2024-02-08 11:35:32.971801: train_loss -0.6055
2024-02-08 11:35:32.973115: val_loss -0.376
2024-02-08 11:35:32.973588: Pseudo dice [0.8409, 0.8294, 0.7371, 0.8305, 0.8314]
2024-02-08 11:35:32.974039: Epoch time: 42.96 s
2024-02-08 11:35:34.065891: 
2024-02-08 11:35:34.067024: Epoch 387
2024-02-08 11:35:34.068029: Current learning rate: 0.00335
2024-02-08 11:36:17.399620: train_loss -0.6157
2024-02-08 11:36:17.401098: val_loss -0.3582
2024-02-08 11:36:17.401546: Pseudo dice [0.8396, 0.8253, 0.7357, 0.8286, 0.8237]
2024-02-08 11:36:17.401970: Epoch time: 43.34 s
2024-02-08 11:36:18.513862: 
2024-02-08 11:36:18.515686: Epoch 388
2024-02-08 11:36:18.516761: Current learning rate: 0.00333
2024-02-08 11:37:01.710992: train_loss -0.612
2024-02-08 11:37:01.712543: val_loss -0.3263
2024-02-08 11:37:01.713061: Pseudo dice [0.8281, 0.8229, 0.7271, 0.8186, 0.8195]
2024-02-08 11:37:01.713560: Epoch time: 43.2 s
2024-02-08 11:37:02.787200: 
2024-02-08 11:37:02.788766: Epoch 389
2024-02-08 11:37:02.789273: Current learning rate: 0.00331
2024-02-08 11:37:45.945506: train_loss -0.6103
2024-02-08 11:37:45.947086: val_loss -0.3586
2024-02-08 11:37:45.947554: Pseudo dice [0.8399, 0.821, 0.7341, 0.844, 0.8226]
2024-02-08 11:37:45.948076: Epoch time: 43.16 s
2024-02-08 11:37:47.242405: 
2024-02-08 11:37:47.243809: Epoch 390
2024-02-08 11:37:47.244407: Current learning rate: 0.00329
2024-02-08 11:38:30.390587: train_loss -0.6138
2024-02-08 11:38:30.392045: val_loss -0.3584
2024-02-08 11:38:30.392528: Pseudo dice [0.8356, 0.8322, 0.7276, 0.8317, 0.8418]
2024-02-08 11:38:30.393048: Epoch time: 43.15 s
2024-02-08 11:38:31.458879: 
2024-02-08 11:38:31.460470: Epoch 391
2024-02-08 11:38:31.460982: Current learning rate: 0.00327
2024-02-08 11:39:14.847697: train_loss -0.6167
2024-02-08 11:39:14.849181: val_loss -0.3551
2024-02-08 11:39:14.849646: Pseudo dice [0.8369, 0.8278, 0.7311, 0.8374, 0.822]
2024-02-08 11:39:14.850065: Epoch time: 43.39 s
2024-02-08 11:39:15.918904: 
2024-02-08 11:39:15.920860: Epoch 392
2024-02-08 11:39:15.921791: Current learning rate: 0.00325
2024-02-08 11:39:59.285226: train_loss -0.6144
2024-02-08 11:39:59.286662: val_loss -0.349
2024-02-08 11:39:59.287170: Pseudo dice [0.8351, 0.8187, 0.7347, 0.8196, 0.8298]
2024-02-08 11:39:59.287628: Epoch time: 43.37 s
2024-02-08 11:40:00.356999: 
2024-02-08 11:40:00.358634: Epoch 393
2024-02-08 11:40:00.359384: Current learning rate: 0.00324
2024-02-08 11:40:43.373557: train_loss -0.6141
2024-02-08 11:40:43.374931: val_loss -0.327
2024-02-08 11:40:43.375391: Pseudo dice [0.8322, 0.8209, 0.7271, 0.8249, 0.8264]
2024-02-08 11:40:43.375836: Epoch time: 43.02 s
2024-02-08 11:40:44.444775: 
2024-02-08 11:40:44.446275: Epoch 394
2024-02-08 11:40:44.446846: Current learning rate: 0.00322
2024-02-08 11:41:27.555385: train_loss -0.616
2024-02-08 11:41:27.556652: val_loss -0.337
2024-02-08 11:41:27.557081: Pseudo dice [0.8371, 0.8237, 0.7334, 0.8319, 0.8219]
2024-02-08 11:41:27.557500: Epoch time: 43.11 s
2024-02-08 11:41:28.642909: 
2024-02-08 11:41:28.644410: Epoch 395
2024-02-08 11:41:28.645028: Current learning rate: 0.0032
2024-02-08 11:42:11.607024: train_loss -0.6163
2024-02-08 11:42:11.608663: val_loss -0.3446
2024-02-08 11:42:11.609159: Pseudo dice [0.8337, 0.818, 0.7326, 0.8344, 0.8328]
2024-02-08 11:42:11.609597: Epoch time: 42.97 s
2024-02-08 11:42:12.906134: 
2024-02-08 11:42:12.907409: Epoch 396
2024-02-08 11:42:12.907976: Current learning rate: 0.00318
2024-02-08 11:42:55.948606: train_loss -0.6148
2024-02-08 11:42:55.950101: val_loss -0.3264
2024-02-08 11:42:55.950608: Pseudo dice [0.8311, 0.823, 0.7253, 0.8216, 0.814]
2024-02-08 11:42:55.951115: Epoch time: 43.04 s
2024-02-08 11:42:57.018781: 
2024-02-08 11:42:57.019766: Epoch 397
2024-02-08 11:42:57.020847: Current learning rate: 0.00316
2024-02-08 11:43:40.415942: train_loss -0.6167
2024-02-08 11:43:40.417363: val_loss -0.3439
2024-02-08 11:43:40.417853: Pseudo dice [0.8343, 0.8239, 0.7328, 0.8295, 0.8263]
2024-02-08 11:43:40.418329: Epoch time: 43.4 s
2024-02-08 11:43:41.498763: 
2024-02-08 11:43:41.500128: Epoch 398
2024-02-08 11:43:41.501368: Current learning rate: 0.00314
2024-02-08 11:44:24.772579: train_loss -0.614
2024-02-08 11:44:24.774578: val_loss -0.3351
2024-02-08 11:44:24.775139: Pseudo dice [0.8305, 0.8213, 0.7255, 0.8305, 0.8318]
2024-02-08 11:44:24.775633: Epoch time: 43.28 s
2024-02-08 11:44:25.856314: 
2024-02-08 11:44:25.857886: Epoch 399
2024-02-08 11:44:25.858463: Current learning rate: 0.00312
2024-02-08 11:45:09.030622: train_loss -0.6161
2024-02-08 11:45:09.032139: val_loss -0.3372
2024-02-08 11:45:09.032628: Pseudo dice [0.8372, 0.824, 0.7346, 0.8403, 0.8063]
2024-02-08 11:45:09.033067: Epoch time: 43.18 s
2024-02-08 11:45:10.436404: 
2024-02-08 11:45:10.437840: Epoch 400
2024-02-08 11:45:10.438371: Current learning rate: 0.00311
2024-02-08 11:45:53.592075: train_loss -0.6155
2024-02-08 11:45:53.594533: val_loss -0.3397
2024-02-08 11:45:53.595070: Pseudo dice [0.8358, 0.8253, 0.7315, 0.8316, 0.8275]
2024-02-08 11:45:53.595535: Epoch time: 43.16 s
2024-02-08 11:45:55.028692: 
2024-02-08 11:45:55.030202: Epoch 401
2024-02-08 11:45:55.030779: Current learning rate: 0.00309
2024-02-08 11:46:37.838668: train_loss -0.6125
2024-02-08 11:46:37.840123: val_loss -0.3587
2024-02-08 11:46:37.840616: Pseudo dice [0.8403, 0.8259, 0.7327, 0.8413, 0.8302]
2024-02-08 11:46:37.841027: Epoch time: 42.81 s
2024-02-08 11:46:38.937402: 
2024-02-08 11:46:39.090657: Epoch 402
2024-02-08 11:46:39.177008: Current learning rate: 0.00307
2024-02-08 11:47:22.149485: train_loss -0.6163
2024-02-08 11:47:22.150901: val_loss -0.3507
2024-02-08 11:47:22.151357: Pseudo dice [0.8313, 0.8302, 0.7336, 0.8289, 0.8275]
2024-02-08 11:47:22.151809: Epoch time: 43.21 s
2024-02-08 11:47:23.236424: 
2024-02-08 11:47:23.238304: Epoch 403
2024-02-08 11:47:23.238869: Current learning rate: 0.00305
2024-02-08 11:48:06.225170: train_loss -0.6162
2024-02-08 11:48:06.226585: val_loss -0.3332
2024-02-08 11:48:06.227109: Pseudo dice [0.8335, 0.8209, 0.7257, 0.8353, 0.8191]
2024-02-08 11:48:06.227574: Epoch time: 42.99 s
2024-02-08 11:48:07.294548: 
2024-02-08 11:48:07.296063: Epoch 404
2024-02-08 11:48:07.297472: Current learning rate: 0.00303
2024-02-08 11:48:50.001633: train_loss -0.6189
2024-02-08 11:48:50.002970: val_loss -0.3436
2024-02-08 11:48:50.003445: Pseudo dice [0.8353, 0.8284, 0.7255, 0.8349, 0.816]
2024-02-08 11:48:50.003880: Epoch time: 42.71 s
2024-02-08 11:48:51.067891: 
2024-02-08 11:48:51.068851: Epoch 405
2024-02-08 11:48:51.069872: Current learning rate: 0.00301
2024-02-08 11:49:33.939130: train_loss -0.6194
2024-02-08 11:49:33.940466: val_loss -0.3448
2024-02-08 11:49:33.940942: Pseudo dice [0.8376, 0.8209, 0.7332, 0.8385, 0.8271]
2024-02-08 11:49:33.941612: Epoch time: 42.87 s
2024-02-08 11:49:35.327444: 
2024-02-08 11:49:35.329705: Epoch 406
2024-02-08 11:49:35.330737: Current learning rate: 0.00299
2024-02-08 11:50:18.529648: train_loss -0.6172
2024-02-08 11:50:18.531440: val_loss -0.3379
2024-02-08 11:50:18.532047: Pseudo dice [0.833, 0.8209, 0.7361, 0.8358, 0.8247]
2024-02-08 11:50:18.532588: Epoch time: 43.2 s
2024-02-08 11:50:19.657716: 
2024-02-08 11:50:19.659228: Epoch 407
2024-02-08 11:50:19.660127: Current learning rate: 0.00297
2024-02-08 11:51:02.867206: train_loss -0.6219
2024-02-08 11:51:02.868746: val_loss -0.3447
2024-02-08 11:51:02.869226: Pseudo dice [0.8375, 0.823, 0.7332, 0.8385, 0.817]
2024-02-08 11:51:02.869671: Epoch time: 43.21 s
2024-02-08 11:51:03.950215: 
2024-02-08 11:51:03.951366: Epoch 408
2024-02-08 11:51:03.952724: Current learning rate: 0.00296
2024-02-08 11:51:46.843724: train_loss -0.6204
2024-02-08 11:51:46.845372: val_loss -0.3422
2024-02-08 11:51:46.845875: Pseudo dice [0.8343, 0.8274, 0.7289, 0.8277, 0.8203]
2024-02-08 11:51:46.846349: Epoch time: 42.89 s
2024-02-08 11:51:47.937430: 
2024-02-08 11:51:47.938611: Epoch 409
2024-02-08 11:51:47.939123: Current learning rate: 0.00294
2024-02-08 11:52:30.907642: train_loss -0.6179
2024-02-08 11:52:30.908933: val_loss -0.3407
2024-02-08 11:52:30.909375: Pseudo dice [0.83, 0.8191, 0.7337, 0.8345, 0.822]
2024-02-08 11:52:30.909776: Epoch time: 42.97 s
2024-02-08 11:52:31.969154: 
2024-02-08 11:52:31.971402: Epoch 410
2024-02-08 11:52:31.972236: Current learning rate: 0.00292
2024-02-08 11:53:15.001820: train_loss -0.624
2024-02-08 11:53:15.003149: val_loss -0.3328
2024-02-08 11:53:15.003617: Pseudo dice [0.8287, 0.8252, 0.7269, 0.8318, 0.8177]
2024-02-08 11:53:15.004060: Epoch time: 43.03 s
2024-02-08 11:53:16.008327: 
2024-02-08 11:53:16.009373: Epoch 411
2024-02-08 11:53:16.010520: Current learning rate: 0.0029
2024-02-08 11:53:58.572930: train_loss -0.6177
2024-02-08 11:53:58.574361: val_loss -0.356
2024-02-08 11:53:58.574959: Pseudo dice [0.8349, 0.8247, 0.7357, 0.8295, 0.8301]
2024-02-08 11:53:58.575421: Epoch time: 42.57 s
2024-02-08 11:53:59.838596: 
2024-02-08 11:53:59.840217: Epoch 412
2024-02-08 11:53:59.840828: Current learning rate: 0.00288
2024-02-08 11:54:43.258111: train_loss -0.6189
2024-02-08 11:54:43.259400: val_loss -0.3387
2024-02-08 11:54:43.259858: Pseudo dice [0.8299, 0.8259, 0.7305, 0.8273, 0.8215]
2024-02-08 11:54:43.260288: Epoch time: 43.42 s
2024-02-08 11:54:44.315018: 
2024-02-08 11:54:44.316375: Epoch 413
2024-02-08 11:54:44.317374: Current learning rate: 0.00286
2024-02-08 11:55:27.168575: train_loss -0.6168
2024-02-08 11:55:27.170000: val_loss -0.3762
2024-02-08 11:55:27.170506: Pseudo dice [0.8387, 0.8293, 0.7441, 0.8421, 0.8332]
2024-02-08 11:55:27.170963: Epoch time: 42.85 s
2024-02-08 11:55:28.154459: 
2024-02-08 11:55:28.155313: Epoch 414
2024-02-08 11:55:28.155856: Current learning rate: 0.00284
2024-02-08 11:56:11.000098: train_loss -0.6206
2024-02-08 11:56:11.001545: val_loss -0.3387
2024-02-08 11:56:11.002006: Pseudo dice [0.8356, 0.8221, 0.733, 0.8392, 0.8196]
2024-02-08 11:56:11.002430: Epoch time: 42.85 s
2024-02-08 11:56:12.030907: 
2024-02-08 11:56:12.032906: Epoch 415
2024-02-08 11:56:12.033488: Current learning rate: 0.00282
2024-02-08 11:56:55.097898: train_loss -0.6156
2024-02-08 11:56:55.099342: val_loss -0.3488
2024-02-08 11:56:55.099794: Pseudo dice [0.8361, 0.8226, 0.7273, 0.8315, 0.8341]
2024-02-08 11:56:55.100209: Epoch time: 43.07 s
2024-02-08 11:56:56.087508: 
2024-02-08 11:56:56.088502: Epoch 416
2024-02-08 11:56:56.089014: Current learning rate: 0.00281
2024-02-08 11:57:38.893456: train_loss -0.6197
2024-02-08 11:57:38.895201: val_loss -0.3292
2024-02-08 11:57:38.895695: Pseudo dice [0.8324, 0.8143, 0.7246, 0.8368, 0.822]
2024-02-08 11:57:38.896123: Epoch time: 42.81 s
2024-02-08 11:57:40.044412: 
2024-02-08 11:57:40.045873: Epoch 417
2024-02-08 11:57:40.046426: Current learning rate: 0.00279
2024-02-08 11:58:23.100952: train_loss -0.6196
2024-02-08 11:58:23.102273: val_loss -0.3401
2024-02-08 11:58:23.102772: Pseudo dice [0.831, 0.8234, 0.73, 0.829, 0.8252]
2024-02-08 11:58:23.103216: Epoch time: 43.06 s
2024-02-08 11:58:24.096985: 
2024-02-08 11:58:24.097711: Epoch 418
2024-02-08 11:58:24.098222: Current learning rate: 0.00277
2024-02-08 11:59:07.019452: train_loss -0.621
2024-02-08 11:59:07.021945: val_loss -0.3696
2024-02-08 11:59:07.022453: Pseudo dice [0.8401, 0.8284, 0.7384, 0.8405, 0.8269]
2024-02-08 11:59:07.022865: Epoch time: 42.92 s
2024-02-08 11:59:08.079426: 
2024-02-08 11:59:08.080996: Epoch 419
2024-02-08 11:59:08.081587: Current learning rate: 0.00275
2024-02-08 11:59:51.163869: train_loss -0.6223
2024-02-08 11:59:51.165346: val_loss -0.3192
2024-02-08 11:59:51.165811: Pseudo dice [0.8301, 0.8242, 0.7214, 0.8221, 0.8172]
2024-02-08 11:59:51.166262: Epoch time: 43.09 s
2024-02-08 11:59:52.153903: 
2024-02-08 11:59:52.154650: Epoch 420
2024-02-08 11:59:52.155216: Current learning rate: 0.00273
2024-02-08 12:00:35.107725: train_loss -0.625
2024-02-08 12:00:35.109216: val_loss -0.3273
2024-02-08 12:00:35.109708: Pseudo dice [0.8291, 0.8246, 0.73, 0.822, 0.8214]
2024-02-08 12:00:35.110154: Epoch time: 42.96 s
2024-02-08 12:00:36.094384: 
2024-02-08 12:00:36.095365: Epoch 421
2024-02-08 12:00:36.095898: Current learning rate: 0.00271
2024-02-08 12:01:18.836339: train_loss -0.6236
2024-02-08 12:01:18.837730: val_loss -0.3276
2024-02-08 12:01:18.838189: Pseudo dice [0.8311, 0.8256, 0.7318, 0.8226, 0.819]
2024-02-08 12:01:18.838607: Epoch time: 42.74 s
2024-02-08 12:01:19.827336: 
2024-02-08 12:01:19.828015: Epoch 422
2024-02-08 12:01:19.828784: Current learning rate: 0.00269
2024-02-08 12:02:02.551457: train_loss -0.6209
2024-02-08 12:02:02.553230: val_loss -0.3609
2024-02-08 12:02:02.553718: Pseudo dice [0.8388, 0.8272, 0.7339, 0.8347, 0.8297]
2024-02-08 12:02:02.554173: Epoch time: 42.72 s
2024-02-08 12:02:03.901966: 
2024-02-08 12:02:03.904011: Epoch 423
2024-02-08 12:02:03.904660: Current learning rate: 0.00267
2024-02-08 12:02:46.716710: train_loss -0.6223
2024-02-08 12:02:46.718169: val_loss -0.3674
2024-02-08 12:02:46.718644: Pseudo dice [0.84, 0.8297, 0.7416, 0.8383, 0.8231]
2024-02-08 12:02:46.719118: Epoch time: 42.82 s
2024-02-08 12:02:47.700349: 
2024-02-08 12:02:47.701046: Epoch 424
2024-02-08 12:02:47.702073: Current learning rate: 0.00265
2024-02-08 12:03:30.995501: train_loss -0.6248
2024-02-08 12:03:30.996852: val_loss -0.3488
2024-02-08 12:03:30.997301: Pseudo dice [0.8369, 0.8211, 0.7321, 0.8264, 0.8323]
2024-02-08 12:03:30.997699: Epoch time: 43.3 s
2024-02-08 12:03:31.989776: 
2024-02-08 12:03:31.990872: Epoch 425
2024-02-08 12:03:31.991407: Current learning rate: 0.00264
2024-02-08 12:04:15.181472: train_loss -0.6218
2024-02-08 12:04:15.183586: val_loss -0.3632
2024-02-08 12:04:15.184126: Pseudo dice [0.8406, 0.8294, 0.738, 0.8505, 0.8177]
2024-02-08 12:04:15.184976: Epoch time: 43.19 s
2024-02-08 12:04:16.207210: 
2024-02-08 12:04:16.208801: Epoch 426
2024-02-08 12:04:16.209408: Current learning rate: 0.00262
2024-02-08 12:04:59.206244: train_loss -0.6159
2024-02-08 12:04:59.207584: val_loss -0.3342
2024-02-08 12:04:59.208048: Pseudo dice [0.8352, 0.8242, 0.7311, 0.8336, 0.8256]
2024-02-08 12:04:59.208483: Epoch time: 43.0 s
2024-02-08 12:05:00.192086: 
2024-02-08 12:05:00.192813: Epoch 427
2024-02-08 12:05:00.193547: Current learning rate: 0.0026
2024-02-08 12:05:43.311951: train_loss -0.6194
2024-02-08 12:05:43.313360: val_loss -0.3538
2024-02-08 12:05:43.313847: Pseudo dice [0.8408, 0.8206, 0.7324, 0.8397, 0.8231]
2024-02-08 12:05:43.314302: Epoch time: 43.12 s
2024-02-08 12:05:44.313420: 
2024-02-08 12:05:44.314718: Epoch 428
2024-02-08 12:05:44.315399: Current learning rate: 0.00258
2024-02-08 12:06:27.359131: train_loss -0.623
2024-02-08 12:06:27.360554: val_loss -0.3477
2024-02-08 12:06:27.361221: Pseudo dice [0.8392, 0.8229, 0.737, 0.8248, 0.824]
2024-02-08 12:06:27.361684: Epoch time: 43.05 s
2024-02-08 12:06:28.514851: 
2024-02-08 12:06:28.516004: Epoch 429
2024-02-08 12:06:28.517079: Current learning rate: 0.00256
2024-02-08 12:07:11.756549: train_loss -0.6255
2024-02-08 12:07:11.758484: val_loss -0.3433
2024-02-08 12:07:11.759409: Pseudo dice [0.8314, 0.8286, 0.7322, 0.8357, 0.8149]
2024-02-08 12:07:11.759892: Epoch time: 43.24 s
2024-02-08 12:07:12.755491: 
2024-02-08 12:07:12.756244: Epoch 430
2024-02-08 12:07:12.756819: Current learning rate: 0.00254
2024-02-08 12:07:55.900758: train_loss -0.6279
2024-02-08 12:07:55.902710: val_loss -0.3518
2024-02-08 12:07:55.903241: Pseudo dice [0.8381, 0.8246, 0.7379, 0.8361, 0.8138]
2024-02-08 12:07:55.903730: Epoch time: 43.15 s
2024-02-08 12:07:56.899601: 
2024-02-08 12:07:56.900477: Epoch 431
2024-02-08 12:07:56.900986: Current learning rate: 0.00252
2024-02-08 12:08:39.934310: train_loss -0.6216
2024-02-08 12:08:39.935747: val_loss -0.3393
2024-02-08 12:08:39.936245: Pseudo dice [0.8333, 0.8191, 0.734, 0.8387, 0.8136]
2024-02-08 12:08:39.936696: Epoch time: 43.04 s
2024-02-08 12:08:40.920449: 
2024-02-08 12:08:40.921196: Epoch 432
2024-02-08 12:08:40.921726: Current learning rate: 0.0025
2024-02-08 12:09:23.868800: train_loss -0.6196
2024-02-08 12:09:23.870176: val_loss -0.3451
2024-02-08 12:09:23.870670: Pseudo dice [0.8325, 0.8223, 0.7359, 0.8141, 0.8327]
2024-02-08 12:09:23.871102: Epoch time: 42.95 s
2024-02-08 12:09:24.863300: 
2024-02-08 12:09:24.864437: Epoch 433
2024-02-08 12:09:24.864945: Current learning rate: 0.00248
2024-02-08 12:10:08.241319: train_loss -0.6208
2024-02-08 12:10:08.242651: val_loss -0.3347
2024-02-08 12:10:08.243114: Pseudo dice [0.8359, 0.8217, 0.7348, 0.8272, 0.8137]
2024-02-08 12:10:08.243524: Epoch time: 43.38 s
2024-02-08 12:10:09.381249: 
2024-02-08 12:10:09.382717: Epoch 434
2024-02-08 12:10:09.383207: Current learning rate: 0.00246
2024-02-08 12:10:52.529109: train_loss -0.624
2024-02-08 12:10:52.530731: val_loss -0.3445
2024-02-08 12:10:52.531245: Pseudo dice [0.8392, 0.8206, 0.7325, 0.8337, 0.8179]
2024-02-08 12:10:52.532307: Epoch time: 43.15 s
2024-02-08 12:10:53.545128: 
2024-02-08 12:10:53.546251: Epoch 435
2024-02-08 12:10:53.547183: Current learning rate: 0.00245
2024-02-08 12:11:36.802224: train_loss -0.6245
2024-02-08 12:11:36.803741: val_loss -0.352
2024-02-08 12:11:36.804267: Pseudo dice [0.8365, 0.8239, 0.7383, 0.8468, 0.8284]
2024-02-08 12:11:36.804742: Epoch time: 43.26 s
2024-02-08 12:11:37.794191: 
2024-02-08 12:11:37.795345: Epoch 436
2024-02-08 12:11:37.795976: Current learning rate: 0.00243
2024-02-08 12:12:21.093212: train_loss -0.6223
2024-02-08 12:12:21.094513: val_loss -0.3284
2024-02-08 12:12:21.094995: Pseudo dice [0.834, 0.8261, 0.7265, 0.8411, 0.8153]
2024-02-08 12:12:21.095475: Epoch time: 43.3 s
2024-02-08 12:12:22.113124: 
2024-02-08 12:12:22.114924: Epoch 437
2024-02-08 12:12:22.115462: Current learning rate: 0.00241
2024-02-08 12:13:05.209892: train_loss -0.6213
2024-02-08 12:13:05.211430: val_loss -0.3695
2024-02-08 12:13:05.211914: Pseudo dice [0.8385, 0.8233, 0.7399, 0.8434, 0.8279]
2024-02-08 12:13:05.212375: Epoch time: 43.1 s
2024-02-08 12:13:06.217834: 
2024-02-08 12:13:06.218853: Epoch 438
2024-02-08 12:13:06.219994: Current learning rate: 0.00239
2024-02-08 12:13:49.107076: train_loss -0.6227
2024-02-08 12:13:49.108830: val_loss -0.3525
2024-02-08 12:13:49.109289: Pseudo dice [0.833, 0.829, 0.7366, 0.8421, 0.8334]
2024-02-08 12:13:49.109711: Epoch time: 42.89 s
2024-02-08 12:13:50.295743: 
2024-02-08 12:13:50.296742: Epoch 439
2024-02-08 12:13:50.297620: Current learning rate: 0.00237
2024-02-08 12:14:33.155831: train_loss -0.6181
2024-02-08 12:14:33.157151: val_loss -0.335
2024-02-08 12:14:33.157612: Pseudo dice [0.8315, 0.8237, 0.7294, 0.8292, 0.8161]
2024-02-08 12:14:33.158034: Epoch time: 42.86 s
2024-02-08 12:14:34.191248: 
2024-02-08 12:14:34.192603: Epoch 440
2024-02-08 12:14:34.193626: Current learning rate: 0.00235
2024-02-08 12:15:16.908796: train_loss -0.6273
2024-02-08 12:15:16.911817: val_loss -0.3514
2024-02-08 12:15:16.912394: Pseudo dice [0.8363, 0.8259, 0.7347, 0.8353, 0.8276]
2024-02-08 12:15:16.912870: Epoch time: 42.72 s
2024-02-08 12:15:17.958721: 
2024-02-08 12:15:17.960261: Epoch 441
2024-02-08 12:15:17.960805: Current learning rate: 0.00233
2024-02-08 12:16:00.756609: train_loss -0.6306
2024-02-08 12:16:00.758105: val_loss -0.3503
2024-02-08 12:16:00.758604: Pseudo dice [0.8358, 0.8289, 0.7316, 0.8277, 0.8249]
2024-02-08 12:16:00.759020: Epoch time: 42.8 s
2024-02-08 12:16:01.758247: 
2024-02-08 12:16:01.759637: Epoch 442
2024-02-08 12:16:01.760115: Current learning rate: 0.00231
2024-02-08 12:16:44.606099: train_loss -0.6256
2024-02-08 12:16:44.607429: val_loss -0.3052
2024-02-08 12:16:44.607886: Pseudo dice [0.8257, 0.8168, 0.7215, 0.8324, 0.8169]
2024-02-08 12:16:44.608309: Epoch time: 42.85 s
2024-02-08 12:16:45.618034: 
2024-02-08 12:16:45.619588: Epoch 443
2024-02-08 12:16:45.620079: Current learning rate: 0.00229
2024-02-08 12:17:28.539370: train_loss -0.6271
2024-02-08 12:17:28.540746: val_loss -0.3421
2024-02-08 12:17:28.541224: Pseudo dice [0.8366, 0.8283, 0.7413, 0.8279, 0.8266]
2024-02-08 12:17:28.541652: Epoch time: 42.92 s
2024-02-08 12:17:29.536384: 
2024-02-08 12:17:29.537274: Epoch 444
2024-02-08 12:17:29.538107: Current learning rate: 0.00227
2024-02-08 12:18:12.434315: train_loss -0.6294
2024-02-08 12:18:12.435806: val_loss -0.3625
2024-02-08 12:18:12.436322: Pseudo dice [0.8415, 0.8284, 0.7353, 0.8339, 0.8271]
2024-02-08 12:18:12.436829: Epoch time: 42.9 s
2024-02-08 12:18:13.716670: 
2024-02-08 12:18:13.718277: Epoch 445
2024-02-08 12:18:13.718859: Current learning rate: 0.00225
2024-02-08 12:18:56.716022: train_loss -0.6272
2024-02-08 12:18:56.717486: val_loss -0.3266
2024-02-08 12:18:56.717940: Pseudo dice [0.8328, 0.8216, 0.7313, 0.8186, 0.8282]
2024-02-08 12:18:56.718337: Epoch time: 43.0 s
2024-02-08 12:18:57.734055: 
2024-02-08 12:18:57.735541: Epoch 446
2024-02-08 12:18:57.736049: Current learning rate: 0.00223
2024-02-08 12:19:40.935044: train_loss -0.6286
2024-02-08 12:19:40.937266: val_loss -0.3317
2024-02-08 12:19:40.937794: Pseudo dice [0.8353, 0.8235, 0.7306, 0.8304, 0.8222]
2024-02-08 12:19:40.938250: Epoch time: 43.2 s
2024-02-08 12:19:41.974152: 
2024-02-08 12:19:41.975987: Epoch 447
2024-02-08 12:19:41.977805: Current learning rate: 0.00221
2024-02-08 12:20:24.801550: train_loss -0.6287
2024-02-08 12:20:24.803052: val_loss -0.3447
2024-02-08 12:20:24.803523: Pseudo dice [0.8345, 0.8206, 0.7328, 0.8344, 0.8211]
2024-02-08 12:20:24.803935: Epoch time: 42.83 s
2024-02-08 12:20:25.833809: 
2024-02-08 12:20:25.835967: Epoch 448
2024-02-08 12:20:25.836651: Current learning rate: 0.00219
2024-02-08 12:21:08.697499: train_loss -0.6262
2024-02-08 12:21:08.698905: val_loss -0.3098
2024-02-08 12:21:08.699382: Pseudo dice [0.8279, 0.8164, 0.7325, 0.8196, 0.817]
2024-02-08 12:21:08.699817: Epoch time: 42.86 s
2024-02-08 12:21:09.711895: 
2024-02-08 12:21:09.713011: Epoch 449
2024-02-08 12:21:09.713909: Current learning rate: 0.00218
2024-02-08 12:21:52.497699: train_loss -0.6293
2024-02-08 12:21:52.499509: val_loss -0.3517
2024-02-08 12:21:52.500065: Pseudo dice [0.8335, 0.8204, 0.7352, 0.8365, 0.8288]
2024-02-08 12:21:52.500519: Epoch time: 42.79 s
2024-02-08 12:21:53.939007: 
2024-02-08 12:21:53.940839: Epoch 450
2024-02-08 12:21:53.941479: Current learning rate: 0.00216
2024-02-08 12:22:36.912077: train_loss -0.628
2024-02-08 12:22:36.913752: val_loss -0.3381
2024-02-08 12:22:36.914339: Pseudo dice [0.8335, 0.822, 0.7299, 0.8296, 0.8341]
2024-02-08 12:22:36.914800: Epoch time: 42.97 s
2024-02-08 12:22:37.905537: 
2024-02-08 12:22:37.906227: Epoch 451
2024-02-08 12:22:37.906727: Current learning rate: 0.00214
2024-02-08 12:23:20.750820: train_loss -0.6253
2024-02-08 12:23:20.752304: val_loss -0.3353
2024-02-08 12:23:20.752826: Pseudo dice [0.8347, 0.8202, 0.7353, 0.8292, 0.8278]
2024-02-08 12:23:20.753254: Epoch time: 42.85 s
2024-02-08 12:23:21.760383: 
2024-02-08 12:23:21.761486: Epoch 452
2024-02-08 12:23:21.762435: Current learning rate: 0.00212
2024-02-08 12:24:04.784356: train_loss -0.6307
2024-02-08 12:24:04.785811: val_loss -0.3422
2024-02-08 12:24:04.786305: Pseudo dice [0.8349, 0.8217, 0.7288, 0.8309, 0.8296]
2024-02-08 12:24:04.786773: Epoch time: 43.03 s
2024-02-08 12:24:05.774847: 
2024-02-08 12:24:05.775665: Epoch 453
2024-02-08 12:24:05.776263: Current learning rate: 0.0021
2024-02-08 12:24:48.715672: train_loss -0.6245
2024-02-08 12:24:48.717560: val_loss -0.3548
2024-02-08 12:24:48.718095: Pseudo dice [0.8396, 0.8264, 0.7326, 0.8473, 0.83]
2024-02-08 12:24:48.718577: Epoch time: 42.94 s
2024-02-08 12:24:49.705141: 
2024-02-08 12:24:49.706545: Epoch 454
2024-02-08 12:24:49.707546: Current learning rate: 0.00208
2024-02-08 12:25:32.708308: train_loss -0.629
2024-02-08 12:25:32.709753: val_loss -0.3385
2024-02-08 12:25:32.710195: Pseudo dice [0.837, 0.8216, 0.7265, 0.8404, 0.8233]
2024-02-08 12:25:32.710619: Epoch time: 43.0 s
2024-02-08 12:25:33.706286: 
2024-02-08 12:25:33.707798: Epoch 455
2024-02-08 12:25:33.708509: Current learning rate: 0.00206
2024-02-08 12:26:16.515091: train_loss -0.6257
2024-02-08 12:26:16.517017: val_loss -0.3427
2024-02-08 12:26:16.517602: Pseudo dice [0.8358, 0.8209, 0.7346, 0.8213, 0.8229]
2024-02-08 12:26:16.518099: Epoch time: 42.81 s
2024-02-08 12:26:17.944062: 
2024-02-08 12:26:17.945097: Epoch 456
2024-02-08 12:26:17.945947: Current learning rate: 0.00204
2024-02-08 12:27:00.915257: train_loss -0.6336
2024-02-08 12:27:00.916609: val_loss -0.3324
2024-02-08 12:27:00.917076: Pseudo dice [0.8351, 0.8225, 0.7362, 0.8399, 0.8201]
2024-02-08 12:27:00.917501: Epoch time: 42.97 s
2024-02-08 12:27:01.926178: 
2024-02-08 12:27:01.927885: Epoch 457
2024-02-08 12:27:01.928475: Current learning rate: 0.00202
2024-02-08 12:27:45.125956: train_loss -0.6316
2024-02-08 12:27:45.127352: val_loss -0.3341
2024-02-08 12:27:45.127855: Pseudo dice [0.83, 0.827, 0.7288, 0.8186, 0.8262]
2024-02-08 12:27:45.128504: Epoch time: 43.2 s
2024-02-08 12:27:46.115631: 
2024-02-08 12:27:46.116976: Epoch 458
2024-02-08 12:27:46.117488: Current learning rate: 0.002
2024-02-08 12:28:29.314166: train_loss -0.6338
2024-02-08 12:28:29.315601: val_loss -0.3427
2024-02-08 12:28:29.316082: Pseudo dice [0.8393, 0.818, 0.7341, 0.8479, 0.8264]
2024-02-08 12:28:29.316527: Epoch time: 43.2 s
2024-02-08 12:28:30.316971: 
2024-02-08 12:28:30.317915: Epoch 459
2024-02-08 12:28:30.318832: Current learning rate: 0.00198
2024-02-08 12:29:13.232460: train_loss -0.6341
2024-02-08 12:29:13.233796: val_loss -0.3376
2024-02-08 12:29:13.234256: Pseudo dice [0.8348, 0.8233, 0.7338, 0.8298, 0.8226]
2024-02-08 12:29:13.234656: Epoch time: 42.92 s
2024-02-08 12:29:14.229358: 
2024-02-08 12:29:14.230308: Epoch 460
2024-02-08 12:29:14.230996: Current learning rate: 0.00196
2024-02-08 12:29:57.207481: train_loss -0.6274
2024-02-08 12:29:57.209016: val_loss -0.339
2024-02-08 12:29:57.209495: Pseudo dice [0.8352, 0.8266, 0.7325, 0.8427, 0.8215]
2024-02-08 12:29:57.209950: Epoch time: 42.98 s
2024-02-08 12:29:58.204223: 
2024-02-08 12:29:58.205299: Epoch 461
2024-02-08 12:29:58.205880: Current learning rate: 0.00194
2024-02-08 12:30:41.481770: train_loss -0.6351
2024-02-08 12:30:41.483256: val_loss -0.3605
2024-02-08 12:30:41.483751: Pseudo dice [0.8377, 0.8286, 0.7364, 0.8348, 0.8215]
2024-02-08 12:30:41.484205: Epoch time: 43.28 s
2024-02-08 12:30:42.668381: 
2024-02-08 12:30:42.669851: Epoch 462
2024-02-08 12:30:42.670467: Current learning rate: 0.00192
2024-02-08 12:31:25.868018: train_loss -0.6295
2024-02-08 12:31:25.869472: val_loss -0.3443
2024-02-08 12:31:25.869965: Pseudo dice [0.8428, 0.821, 0.7357, 0.8502, 0.8227]
2024-02-08 12:31:25.870395: Epoch time: 43.2 s
2024-02-08 12:31:26.867507: 
2024-02-08 12:31:26.868933: Epoch 463
2024-02-08 12:31:26.869816: Current learning rate: 0.0019
2024-02-08 12:32:09.600875: train_loss -0.6283
2024-02-08 12:32:09.602252: val_loss -0.3424
2024-02-08 12:32:09.602721: Pseudo dice [0.8368, 0.8203, 0.7368, 0.8425, 0.8129]
2024-02-08 12:32:09.603149: Epoch time: 42.73 s
2024-02-08 12:32:10.586492: 
2024-02-08 12:32:10.587190: Epoch 464
2024-02-08 12:32:10.587728: Current learning rate: 0.00188
2024-02-08 12:32:53.401697: train_loss -0.632
2024-02-08 12:32:53.403121: val_loss -0.3581
2024-02-08 12:32:53.403669: Pseudo dice [0.8349, 0.8291, 0.738, 0.8402, 0.8283]
2024-02-08 12:32:53.404141: Epoch time: 42.82 s
2024-02-08 12:32:54.408971: 
2024-02-08 12:32:54.410399: Epoch 465
2024-02-08 12:32:54.411132: Current learning rate: 0.00186
2024-02-08 12:33:37.026598: train_loss -0.6361
2024-02-08 12:33:37.028356: val_loss -0.3629
2024-02-08 12:33:37.028913: Pseudo dice [0.8379, 0.8253, 0.7383, 0.8432, 0.8276]
2024-02-08 12:33:37.029343: Epoch time: 42.62 s
2024-02-08 12:33:37.029802: Yayy! New best EMA pseudo Dice: 0.8111
2024-02-08 12:33:38.280623: 
2024-02-08 12:33:38.282063: Epoch 466
2024-02-08 12:33:38.282573: Current learning rate: 0.00184
2024-02-08 12:34:21.115597: train_loss -0.6322
2024-02-08 12:34:21.117239: val_loss -0.3424
2024-02-08 12:34:21.117764: Pseudo dice [0.8352, 0.8249, 0.7335, 0.8346, 0.8227]
2024-02-08 12:34:21.118199: Epoch time: 42.84 s
2024-02-08 12:34:22.242946: 
2024-02-08 12:34:22.244759: Epoch 467
2024-02-08 12:34:22.245411: Current learning rate: 0.00182
2024-02-08 12:35:05.058491: train_loss -0.6341
2024-02-08 12:35:05.060132: val_loss -0.3354
2024-02-08 12:35:05.060611: Pseudo dice [0.832, 0.8252, 0.7365, 0.8319, 0.8158]
2024-02-08 12:35:05.061090: Epoch time: 42.82 s
2024-02-08 12:35:06.077562: 
2024-02-08 12:35:06.078728: Epoch 468
2024-02-08 12:35:06.079880: Current learning rate: 0.0018
2024-02-08 12:35:48.832770: train_loss -0.6296
2024-02-08 12:35:48.834340: val_loss -0.3481
2024-02-08 12:35:48.834850: Pseudo dice [0.8314, 0.8271, 0.7358, 0.8411, 0.826]
2024-02-08 12:35:48.835397: Epoch time: 42.76 s
2024-02-08 12:35:49.859349: 
2024-02-08 12:35:49.860707: Epoch 469
2024-02-08 12:35:49.861889: Current learning rate: 0.00178
2024-02-08 12:36:32.565506: train_loss -0.6283
2024-02-08 12:36:32.567012: val_loss -0.3851
2024-02-08 12:36:32.567487: Pseudo dice [0.847, 0.8277, 0.7451, 0.855, 0.8311]
2024-02-08 12:36:32.567928: Epoch time: 42.71 s
2024-02-08 12:36:32.570295: Yayy! New best EMA pseudo Dice: 0.8119
2024-02-08 12:36:33.915376: 
2024-02-08 12:36:33.916509: Epoch 470
2024-02-08 12:36:33.917459: Current learning rate: 0.00176
2024-02-08 12:37:17.174734: train_loss -0.6291
2024-02-08 12:37:17.176020: val_loss -0.3448
2024-02-08 12:37:17.176488: Pseudo dice [0.8378, 0.8228, 0.7386, 0.8335, 0.8316]
2024-02-08 12:37:17.176898: Epoch time: 43.26 s
2024-02-08 12:37:17.177288: Yayy! New best EMA pseudo Dice: 0.812
2024-02-08 12:37:18.481514: 
2024-02-08 12:37:18.482551: Epoch 471
2024-02-08 12:37:18.483418: Current learning rate: 0.00174
2024-02-08 12:38:01.678318: train_loss -0.6324
2024-02-08 12:38:01.679868: val_loss -0.3391
2024-02-08 12:38:01.680345: Pseudo dice [0.8342, 0.8293, 0.729, 0.8388, 0.8235]
2024-02-08 12:38:01.680753: Epoch time: 43.2 s
2024-02-08 12:38:02.977660: 
2024-02-08 12:38:02.979198: Epoch 472
2024-02-08 12:38:02.979819: Current learning rate: 0.00172
2024-02-08 12:38:46.033150: train_loss -0.6285
2024-02-08 12:38:46.034583: val_loss -0.342
2024-02-08 12:38:46.035083: Pseudo dice [0.8331, 0.8245, 0.7328, 0.8396, 0.8297]
2024-02-08 12:38:46.035556: Epoch time: 43.06 s
2024-02-08 12:38:47.045436: 
2024-02-08 12:38:47.047439: Epoch 473
2024-02-08 12:38:47.049105: Current learning rate: 0.0017
2024-02-08 12:39:30.159619: train_loss -0.6342
2024-02-08 12:39:30.161270: val_loss -0.3359
2024-02-08 12:39:30.162008: Pseudo dice [0.8346, 0.821, 0.7302, 0.8421, 0.8243]
2024-02-08 12:39:30.162507: Epoch time: 43.12 s
2024-02-08 12:39:31.138058: 
2024-02-08 12:39:31.138836: Epoch 474
2024-02-08 12:39:31.139561: Current learning rate: 0.00168
2024-02-08 12:40:14.062776: train_loss -0.6336
2024-02-08 12:40:14.064285: val_loss -0.359
2024-02-08 12:40:14.064796: Pseudo dice [0.8357, 0.8259, 0.7397, 0.8408, 0.8266]
2024-02-08 12:40:14.065256: Epoch time: 42.93 s
2024-02-08 12:40:15.054753: 
2024-02-08 12:40:15.056113: Epoch 475
2024-02-08 12:40:15.056676: Current learning rate: 0.00166
2024-02-08 12:40:57.900133: train_loss -0.6308
2024-02-08 12:40:57.901575: val_loss -0.3141
2024-02-08 12:40:57.902051: Pseudo dice [0.8314, 0.8176, 0.7301, 0.8336, 0.8145]
2024-02-08 12:40:57.902499: Epoch time: 42.85 s
2024-02-08 12:40:58.879461: 
2024-02-08 12:40:58.880332: Epoch 476
2024-02-08 12:40:58.881154: Current learning rate: 0.00164
2024-02-08 12:41:41.643625: train_loss -0.6341
2024-02-08 12:41:41.645550: val_loss -0.3477
2024-02-08 12:41:41.646054: Pseudo dice [0.8408, 0.826, 0.7376, 0.8301, 0.8203]
2024-02-08 12:41:41.646510: Epoch time: 42.76 s
2024-02-08 12:41:42.639784: 
2024-02-08 12:41:42.641219: Epoch 477
2024-02-08 12:41:42.641723: Current learning rate: 0.00162
2024-02-08 12:42:25.451979: train_loss -0.6358
2024-02-08 12:42:25.453294: val_loss -0.3407
2024-02-08 12:42:25.453753: Pseudo dice [0.8335, 0.8218, 0.7282, 0.8457, 0.8234]
2024-02-08 12:42:25.454183: Epoch time: 42.81 s
2024-02-08 12:42:26.611789: 
2024-02-08 12:42:26.613431: Epoch 478
2024-02-08 12:42:26.614786: Current learning rate: 0.0016
2024-02-08 12:43:09.716536: train_loss -0.6399
2024-02-08 12:43:09.718120: val_loss -0.3125
2024-02-08 12:43:09.718657: Pseudo dice [0.8328, 0.8166, 0.7259, 0.8178, 0.829]
2024-02-08 12:43:09.719097: Epoch time: 43.11 s
2024-02-08 12:43:10.727371: 
2024-02-08 12:43:10.729285: Epoch 479
2024-02-08 12:43:10.729831: Current learning rate: 0.00158
2024-02-08 12:43:54.483769: train_loss -0.6368
2024-02-08 12:43:54.485623: val_loss -0.3238
2024-02-08 12:43:54.486151: Pseudo dice [0.8333, 0.816, 0.7324, 0.8292, 0.8205]
2024-02-08 12:43:54.486638: Epoch time: 43.76 s
2024-02-08 12:43:55.493651: 
2024-02-08 12:43:55.494809: Epoch 480
2024-02-08 12:43:55.495943: Current learning rate: 0.00156
2024-02-08 12:44:38.350591: train_loss -0.634
2024-02-08 12:44:38.352432: val_loss -0.3604
2024-02-08 12:44:38.353155: Pseudo dice [0.8406, 0.8277, 0.7373, 0.8418, 0.8249]
2024-02-08 12:44:38.353610: Epoch time: 42.86 s
2024-02-08 12:44:39.360564: 
2024-02-08 12:44:39.361599: Epoch 481
2024-02-08 12:44:39.362650: Current learning rate: 0.00154
2024-02-08 12:45:22.513201: train_loss -0.6383
2024-02-08 12:45:22.514550: val_loss -0.3024
2024-02-08 12:45:22.515032: Pseudo dice [0.8307, 0.8167, 0.7254, 0.8225, 0.8183]
2024-02-08 12:45:22.515469: Epoch time: 43.15 s
2024-02-08 12:45:23.521109: 
2024-02-08 12:45:23.522388: Epoch 482
2024-02-08 12:45:23.523651: Current learning rate: 0.00152
2024-02-08 12:46:06.576220: train_loss -0.6393
2024-02-08 12:46:06.577672: val_loss -0.327
2024-02-08 12:46:06.578142: Pseudo dice [0.8346, 0.8202, 0.7351, 0.8282, 0.8297]
2024-02-08 12:46:06.578592: Epoch time: 43.06 s
2024-02-08 12:46:07.612102: 
2024-02-08 12:46:07.613158: Epoch 483
2024-02-08 12:46:07.614615: Current learning rate: 0.0015
2024-02-08 12:46:50.682657: train_loss -0.6392
2024-02-08 12:46:50.683981: val_loss -0.362
2024-02-08 12:46:50.684452: Pseudo dice [0.842, 0.8273, 0.739, 0.8438, 0.8259]
2024-02-08 12:46:50.684867: Epoch time: 43.07 s
2024-02-08 12:46:51.846882: 
2024-02-08 12:46:51.848492: Epoch 484
2024-02-08 12:46:51.849035: Current learning rate: 0.00148
2024-02-08 12:47:34.649624: train_loss -0.6344
2024-02-08 12:47:34.651491: val_loss -0.3322
2024-02-08 12:47:34.652172: Pseudo dice [0.836, 0.8207, 0.7306, 0.8426, 0.8202]
2024-02-08 12:47:34.652609: Epoch time: 42.8 s
2024-02-08 12:47:35.655996: 
2024-02-08 12:47:35.657298: Epoch 485
2024-02-08 12:47:35.658225: Current learning rate: 0.00146
2024-02-08 12:48:18.362734: train_loss -0.639
2024-02-08 12:48:18.364434: val_loss -0.3597
2024-02-08 12:48:18.365001: Pseudo dice [0.8375, 0.8259, 0.7376, 0.8343, 0.8245]
2024-02-08 12:48:18.365497: Epoch time: 42.71 s
2024-02-08 12:48:19.461251: 
2024-02-08 12:48:19.463202: Epoch 486
2024-02-08 12:48:19.464394: Current learning rate: 0.00144
2024-02-08 12:49:02.271317: train_loss -0.6406
2024-02-08 12:49:02.272882: val_loss -0.3301
2024-02-08 12:49:02.273384: Pseudo dice [0.8353, 0.8237, 0.7306, 0.8253, 0.8262]
2024-02-08 12:49:02.273860: Epoch time: 42.81 s
2024-02-08 12:49:03.284484: 
2024-02-08 12:49:03.285555: Epoch 487
2024-02-08 12:49:03.286416: Current learning rate: 0.00142
2024-02-08 12:49:46.050325: train_loss -0.6375
2024-02-08 12:49:46.052229: val_loss -0.3416
2024-02-08 12:49:46.052741: Pseudo dice [0.8344, 0.8271, 0.7354, 0.8283, 0.8224]
2024-02-08 12:49:46.053218: Epoch time: 42.77 s
2024-02-08 12:49:47.058922: 
2024-02-08 12:49:47.060955: Epoch 488
2024-02-08 12:49:47.061533: Current learning rate: 0.0014
2024-02-08 12:50:29.998505: train_loss -0.6394
2024-02-08 12:50:29.999929: val_loss -0.3433
2024-02-08 12:50:30.000391: Pseudo dice [0.8351, 0.8247, 0.7373, 0.8359, 0.8256]
2024-02-08 12:50:30.000974: Epoch time: 42.94 s
2024-02-08 12:50:31.000806: 
2024-02-08 12:50:31.001885: Epoch 489
2024-02-08 12:50:31.003076: Current learning rate: 0.00138
2024-02-08 12:51:14.034108: train_loss -0.6436
2024-02-08 12:51:14.035695: val_loss -0.335
2024-02-08 12:51:14.036216: Pseudo dice [0.8404, 0.8224, 0.7325, 0.8308, 0.8301]
2024-02-08 12:51:14.036687: Epoch time: 43.03 s
2024-02-08 12:51:15.358759: 
2024-02-08 12:51:15.360744: Epoch 490
2024-02-08 12:51:15.361391: Current learning rate: 0.00136
2024-02-08 12:51:58.460056: train_loss -0.6319
2024-02-08 12:51:58.461819: val_loss -0.3219
2024-02-08 12:51:58.462375: Pseudo dice [0.8344, 0.8192, 0.7321, 0.8304, 0.8302]
2024-02-08 12:51:58.463039: Epoch time: 43.1 s
2024-02-08 12:51:59.490223: 
2024-02-08 12:51:59.491370: Epoch 491
2024-02-08 12:51:59.492316: Current learning rate: 0.00134
2024-02-08 12:52:42.630295: train_loss -0.6361
2024-02-08 12:52:42.631611: val_loss -0.3301
2024-02-08 12:52:42.632059: Pseudo dice [0.8309, 0.8214, 0.7324, 0.8346, 0.8298]
2024-02-08 12:52:42.632483: Epoch time: 43.14 s
2024-02-08 12:52:43.635910: 
2024-02-08 12:52:43.637675: Epoch 492
2024-02-08 12:52:43.638199: Current learning rate: 0.00132
2024-02-08 12:53:26.641685: train_loss -0.6376
2024-02-08 12:53:26.643027: val_loss -0.3305
2024-02-08 12:53:26.643488: Pseudo dice [0.8382, 0.8187, 0.7339, 0.8288, 0.8256]
2024-02-08 12:53:26.643912: Epoch time: 43.01 s
2024-02-08 12:53:27.676189: 
2024-02-08 12:53:27.677538: Epoch 493
2024-02-08 12:53:27.678685: Current learning rate: 0.0013
2024-02-08 12:54:10.763971: train_loss -0.6319
2024-02-08 12:54:10.765400: val_loss -0.3448
2024-02-08 12:54:10.765882: Pseudo dice [0.8392, 0.8216, 0.738, 0.8335, 0.8321]
2024-02-08 12:54:10.766333: Epoch time: 43.09 s
2024-02-08 12:54:11.788949: 
2024-02-08 12:54:11.790824: Epoch 494
2024-02-08 12:54:11.791476: Current learning rate: 0.00128
2024-02-08 12:54:54.973630: train_loss -0.637
2024-02-08 12:54:54.974952: val_loss -0.3235
2024-02-08 12:54:54.975393: Pseudo dice [0.833, 0.8223, 0.7297, 0.8272, 0.8241]
2024-02-08 12:54:54.975801: Epoch time: 43.19 s
2024-02-08 12:54:56.144082: 
2024-02-08 12:54:56.145079: Epoch 495
2024-02-08 12:54:56.146220: Current learning rate: 0.00126
2024-02-08 12:55:39.017144: train_loss -0.6368
2024-02-08 12:55:39.018591: val_loss -0.3598
2024-02-08 12:55:39.019089: Pseudo dice [0.8408, 0.8297, 0.7407, 0.8294, 0.8213]
2024-02-08 12:55:39.019510: Epoch time: 42.87 s
2024-02-08 12:55:40.032058: 
2024-02-08 12:55:40.033432: Epoch 496
2024-02-08 12:55:40.034647: Current learning rate: 0.00124
2024-02-08 12:56:22.721241: train_loss -0.6393
2024-02-08 12:56:22.722634: val_loss -0.3466
2024-02-08 12:56:22.723114: Pseudo dice [0.8358, 0.8263, 0.7344, 0.8389, 0.8307]
2024-02-08 12:56:22.723534: Epoch time: 42.69 s
2024-02-08 12:56:23.724549: 
2024-02-08 12:56:23.726108: Epoch 497
2024-02-08 12:56:23.726613: Current learning rate: 0.00122
2024-02-08 12:57:06.517531: train_loss -0.638
2024-02-08 12:57:06.519197: val_loss -0.362
2024-02-08 12:57:06.519701: Pseudo dice [0.841, 0.8261, 0.7442, 0.8439, 0.8285]
2024-02-08 12:57:06.520122: Epoch time: 42.79 s
2024-02-08 12:57:07.518978: 
2024-02-08 12:57:07.519826: Epoch 498
2024-02-08 12:57:07.521176: Current learning rate: 0.0012
2024-02-08 12:57:50.159015: train_loss -0.6339
2024-02-08 12:57:50.160350: val_loss -0.3407
2024-02-08 12:57:50.160787: Pseudo dice [0.8366, 0.8215, 0.7383, 0.8346, 0.8195]
2024-02-08 12:57:50.161196: Epoch time: 42.64 s
2024-02-08 12:57:51.155828: 
2024-02-08 12:57:51.157110: Epoch 499
2024-02-08 12:57:51.158271: Current learning rate: 0.00118
2024-02-08 12:58:33.708761: train_loss -0.6346
2024-02-08 12:58:33.710183: val_loss -0.3345
2024-02-08 12:58:33.710643: Pseudo dice [0.8318, 0.8205, 0.7339, 0.8312, 0.8228]
2024-02-08 12:58:33.711090: Epoch time: 42.55 s
2024-02-08 12:58:35.124293: 
2024-02-08 12:58:35.125918: Epoch 500
2024-02-08 12:58:35.126445: Current learning rate: 0.00116
2024-02-08 12:59:18.236406: train_loss -0.6441
2024-02-08 12:59:18.238249: val_loss -0.3503
2024-02-08 12:59:18.238781: Pseudo dice [0.8366, 0.8302, 0.7283, 0.841, 0.8242]
2024-02-08 12:59:18.239259: Epoch time: 43.11 s
2024-02-08 12:59:19.280958: 
2024-02-08 12:59:19.282645: Epoch 501
2024-02-08 12:59:19.283251: Current learning rate: 0.00113
2024-02-08 13:00:02.258539: train_loss -0.6435
2024-02-08 13:00:02.260428: val_loss -0.3479
2024-02-08 13:00:02.260924: Pseudo dice [0.8362, 0.8301, 0.7355, 0.8418, 0.8202]
2024-02-08 13:00:02.261352: Epoch time: 42.98 s
2024-02-08 13:00:03.303014: 
2024-02-08 13:00:03.304131: Epoch 502
2024-02-08 13:00:03.305093: Current learning rate: 0.00111
2024-02-08 13:00:46.513692: train_loss -0.64
2024-02-08 13:00:46.515130: val_loss -0.3101
2024-02-08 13:00:46.515614: Pseudo dice [0.8316, 0.8162, 0.7326, 0.843, 0.8173]
2024-02-08 13:00:46.516039: Epoch time: 43.21 s
2024-02-08 13:00:47.536980: 
2024-02-08 13:00:47.538550: Epoch 503
2024-02-08 13:00:47.539523: Current learning rate: 0.00109
2024-02-08 13:01:30.315650: train_loss -0.6413
2024-02-08 13:01:30.316980: val_loss -0.3066
2024-02-08 13:01:30.317463: Pseudo dice [0.8282, 0.8223, 0.7275, 0.8301, 0.8167]
2024-02-08 13:01:30.317887: Epoch time: 42.78 s
2024-02-08 13:01:31.332774: 
2024-02-08 13:01:31.334505: Epoch 504
2024-02-08 13:01:31.335065: Current learning rate: 0.00107
2024-02-08 13:02:14.232578: train_loss -0.6388
2024-02-08 13:02:14.234079: val_loss -0.3371
2024-02-08 13:02:14.234588: Pseudo dice [0.8344, 0.8231, 0.7353, 0.8349, 0.8205]
2024-02-08 13:02:14.235044: Epoch time: 42.9 s
2024-02-08 13:02:15.236880: 
2024-02-08 13:02:15.238344: Epoch 505
2024-02-08 13:02:15.238856: Current learning rate: 0.00105
2024-02-08 13:02:58.036194: train_loss -0.6421
2024-02-08 13:02:58.037684: val_loss -0.3659
2024-02-08 13:02:58.038200: Pseudo dice [0.8403, 0.8364, 0.7364, 0.843, 0.8294]
2024-02-08 13:02:58.038677: Epoch time: 42.8 s
2024-02-08 13:02:59.256175: 
2024-02-08 13:02:59.257396: Epoch 506
2024-02-08 13:02:59.258257: Current learning rate: 0.00103
2024-02-08 13:03:42.122095: train_loss -0.6424
2024-02-08 13:03:42.123426: val_loss -0.3312
2024-02-08 13:03:42.123864: Pseudo dice [0.8358, 0.8175, 0.7297, 0.8314, 0.8287]
2024-02-08 13:03:42.124285: Epoch time: 42.87 s
2024-02-08 13:03:43.134896: 
2024-02-08 13:03:43.135811: Epoch 507
2024-02-08 13:03:43.136853: Current learning rate: 0.00101
2024-02-08 13:04:26.007601: train_loss -0.6413
2024-02-08 13:04:26.009065: val_loss -0.3228
2024-02-08 13:04:26.009539: Pseudo dice [0.8331, 0.8236, 0.7222, 0.8317, 0.8141]
2024-02-08 13:04:26.009947: Epoch time: 42.87 s
2024-02-08 13:04:27.011189: 
2024-02-08 13:04:27.012812: Epoch 508
2024-02-08 13:04:27.013313: Current learning rate: 0.00099
2024-02-08 13:05:09.877692: train_loss -0.6403
2024-02-08 13:05:09.879424: val_loss -0.3633
2024-02-08 13:05:09.879956: Pseudo dice [0.8408, 0.8257, 0.739, 0.8283, 0.8287]
2024-02-08 13:05:09.880392: Epoch time: 42.87 s
2024-02-08 13:05:10.897292: 
2024-02-08 13:05:10.898484: Epoch 509
2024-02-08 13:05:10.899486: Current learning rate: 0.00097
2024-02-08 13:05:53.753978: train_loss -0.6354
2024-02-08 13:05:53.755348: val_loss -0.3503
2024-02-08 13:05:53.755799: Pseudo dice [0.8391, 0.8279, 0.7372, 0.8329, 0.8277]
2024-02-08 13:05:53.756215: Epoch time: 42.86 s
2024-02-08 13:05:54.764879: 
2024-02-08 13:05:54.766453: Epoch 510
2024-02-08 13:05:54.766993: Current learning rate: 0.00095
2024-02-08 13:06:37.550775: train_loss -0.6403
2024-02-08 13:06:37.554141: val_loss -0.3316
2024-02-08 13:06:37.554812: Pseudo dice [0.8375, 0.8245, 0.7384, 0.8415, 0.8289]
2024-02-08 13:06:37.555264: Epoch time: 42.79 s
2024-02-08 13:06:38.554388: 
2024-02-08 13:06:38.555407: Epoch 511
2024-02-08 13:06:38.556575: Current learning rate: 0.00092
2024-02-08 13:07:21.385727: train_loss -0.6456
2024-02-08 13:07:21.386978: val_loss -0.3488
2024-02-08 13:07:21.387468: Pseudo dice [0.8359, 0.8241, 0.7379, 0.8403, 0.8219]
2024-02-08 13:07:21.387883: Epoch time: 42.83 s
2024-02-08 13:07:22.524905: 
2024-02-08 13:07:22.526193: Epoch 512
2024-02-08 13:07:22.526751: Current learning rate: 0.0009
2024-02-08 13:08:05.676805: train_loss -0.6431
2024-02-08 13:08:05.678342: val_loss -0.3172
2024-02-08 13:08:05.678921: Pseudo dice [0.8328, 0.8234, 0.7302, 0.8305, 0.8202]
2024-02-08 13:08:05.679381: Epoch time: 43.15 s
2024-02-08 13:08:06.703632: 
2024-02-08 13:08:06.705374: Epoch 513
2024-02-08 13:08:06.706852: Current learning rate: 0.00088
2024-02-08 13:08:49.702683: train_loss -0.644
2024-02-08 13:08:49.704683: val_loss -0.3165
2024-02-08 13:08:49.705240: Pseudo dice [0.8332, 0.8221, 0.7266, 0.8233, 0.8307]
2024-02-08 13:08:49.705727: Epoch time: 43.0 s
2024-02-08 13:08:50.761962: 
2024-02-08 13:08:50.763034: Epoch 514
2024-02-08 13:08:50.764040: Current learning rate: 0.00086
2024-02-08 13:09:33.932538: train_loss -0.6441
2024-02-08 13:09:33.933933: val_loss -0.3382
2024-02-08 13:09:33.934414: Pseudo dice [0.8405, 0.823, 0.7335, 0.8521, 0.8276]
2024-02-08 13:09:33.934828: Epoch time: 43.17 s
2024-02-08 13:09:34.954503: 
2024-02-08 13:09:34.956714: Epoch 515
2024-02-08 13:09:34.957509: Current learning rate: 0.00084
2024-02-08 13:10:18.240957: train_loss -0.6404
2024-02-08 13:10:18.242479: val_loss -0.3442
2024-02-08 13:10:18.242993: Pseudo dice [0.837, 0.8243, 0.7353, 0.8353, 0.8253]
2024-02-08 13:10:18.243505: Epoch time: 43.29 s
2024-02-08 13:10:19.284580: 
2024-02-08 13:10:19.285777: Epoch 516
2024-02-08 13:10:19.286766: Current learning rate: 0.00082
2024-02-08 13:11:02.625772: train_loss -0.649
2024-02-08 13:11:02.627354: val_loss -0.3141
2024-02-08 13:11:02.627891: Pseudo dice [0.8304, 0.8221, 0.7213, 0.8315, 0.8199]
2024-02-08 13:11:02.628394: Epoch time: 43.34 s
2024-02-08 13:11:03.988433: 
2024-02-08 13:11:03.989965: Epoch 517
2024-02-08 13:11:03.990548: Current learning rate: 0.00079
2024-02-08 13:11:47.133942: train_loss -0.6437
2024-02-08 13:11:47.135341: val_loss -0.3685
2024-02-08 13:11:47.135880: Pseudo dice [0.8379, 0.8331, 0.7389, 0.841, 0.8263]
2024-02-08 13:11:47.136347: Epoch time: 43.15 s
2024-02-08 13:11:48.139539: 
2024-02-08 13:11:48.140592: Epoch 518
2024-02-08 13:11:48.141709: Current learning rate: 0.00077
2024-02-08 13:12:31.133756: train_loss -0.6482
2024-02-08 13:12:31.135098: val_loss -0.3498
2024-02-08 13:12:31.135587: Pseudo dice [0.835, 0.8296, 0.7344, 0.8382, 0.8329]
2024-02-08 13:12:31.136048: Epoch time: 43.0 s
2024-02-08 13:12:32.149837: 
2024-02-08 13:12:32.150770: Epoch 519
2024-02-08 13:12:32.151549: Current learning rate: 0.00075
2024-02-08 13:13:14.990737: train_loss -0.643
2024-02-08 13:13:14.991983: val_loss -0.3392
2024-02-08 13:13:14.992420: Pseudo dice [0.8374, 0.824, 0.734, 0.8411, 0.8156]
2024-02-08 13:13:14.992852: Epoch time: 42.84 s
2024-02-08 13:13:16.020197: 
2024-02-08 13:13:16.021562: Epoch 520
2024-02-08 13:13:16.022662: Current learning rate: 0.00073
2024-02-08 13:13:58.901443: train_loss -0.6407
2024-02-08 13:13:58.902863: val_loss -0.3554
2024-02-08 13:13:58.903368: Pseudo dice [0.8393, 0.8301, 0.7366, 0.8312, 0.8222]
2024-02-08 13:13:58.903835: Epoch time: 42.88 s
2024-02-08 13:13:59.906005: 
2024-02-08 13:13:59.907373: Epoch 521
2024-02-08 13:13:59.908687: Current learning rate: 0.00071
2024-02-08 13:14:42.607380: train_loss -0.6439
2024-02-08 13:14:42.608969: val_loss -0.3583
2024-02-08 13:14:42.609488: Pseudo dice [0.8394, 0.8334, 0.7364, 0.8404, 0.827]
2024-02-08 13:14:42.609945: Epoch time: 42.7 s
2024-02-08 13:14:43.611360: 
2024-02-08 13:14:43.612423: Epoch 522
2024-02-08 13:14:43.613234: Current learning rate: 0.00069
2024-02-08 13:15:26.342948: train_loss -0.6435
2024-02-08 13:15:26.344381: val_loss -0.3189
2024-02-08 13:15:26.344848: Pseudo dice [0.8307, 0.8239, 0.7242, 0.8262, 0.8203]
2024-02-08 13:15:26.345295: Epoch time: 42.73 s
2024-02-08 13:15:27.495493: 
2024-02-08 13:15:27.496515: Epoch 523
2024-02-08 13:15:27.497778: Current learning rate: 0.00066
2024-02-08 13:16:10.105728: train_loss -0.6467
2024-02-08 13:16:10.107110: val_loss -0.3349
2024-02-08 13:16:10.107581: Pseudo dice [0.8378, 0.8231, 0.7343, 0.841, 0.8331]
2024-02-08 13:16:10.108218: Epoch time: 42.61 s
2024-02-08 13:16:11.122852: 
2024-02-08 13:16:11.123837: Epoch 524
2024-02-08 13:16:11.124811: Current learning rate: 0.00064
2024-02-08 13:16:53.677703: train_loss -0.6463
2024-02-08 13:16:53.679084: val_loss -0.3409
2024-02-08 13:16:53.679582: Pseudo dice [0.8324, 0.8242, 0.7321, 0.836, 0.8333]
2024-02-08 13:16:53.680030: Epoch time: 42.56 s
2024-02-08 13:16:54.680337: 
2024-02-08 13:16:54.681502: Epoch 525
2024-02-08 13:16:54.682334: Current learning rate: 0.00062
2024-02-08 13:17:37.367876: train_loss -0.6434
2024-02-08 13:17:37.369183: val_loss -0.3131
2024-02-08 13:17:37.369657: Pseudo dice [0.8319, 0.8241, 0.7303, 0.8322, 0.8165]
2024-02-08 13:17:37.370074: Epoch time: 42.69 s
2024-02-08 13:17:38.369796: 
2024-02-08 13:17:38.370680: Epoch 526
2024-02-08 13:17:38.371810: Current learning rate: 0.0006
2024-02-08 13:18:21.295618: train_loss -0.6433
2024-02-08 13:18:21.296906: val_loss -0.3503
2024-02-08 13:18:21.297404: Pseudo dice [0.8349, 0.8306, 0.7343, 0.8392, 0.8248]
2024-02-08 13:18:21.297826: Epoch time: 42.93 s
2024-02-08 13:18:22.317958: 
2024-02-08 13:18:22.319194: Epoch 527
2024-02-08 13:18:22.320413: Current learning rate: 0.00057
2024-02-08 13:19:05.487545: train_loss -0.645
2024-02-08 13:19:05.488969: val_loss -0.3538
2024-02-08 13:19:05.489471: Pseudo dice [0.8416, 0.8235, 0.7357, 0.8477, 0.8271]
2024-02-08 13:19:05.489909: Epoch time: 43.17 s
2024-02-08 13:19:06.495978: 
2024-02-08 13:19:06.497459: Epoch 528
2024-02-08 13:19:06.497969: Current learning rate: 0.00055
2024-02-08 13:19:49.565536: train_loss -0.6478
2024-02-08 13:19:49.566974: val_loss -0.3223
2024-02-08 13:19:49.567425: Pseudo dice [0.8339, 0.8252, 0.7281, 0.837, 0.8307]
2024-02-08 13:19:49.567832: Epoch time: 43.07 s
2024-02-08 13:19:50.695426: 
2024-02-08 13:19:50.696392: Epoch 529
2024-02-08 13:19:50.697298: Current learning rate: 0.00053
2024-02-08 13:20:33.850195: train_loss -0.6479
2024-02-08 13:20:33.851660: val_loss -0.3199
2024-02-08 13:20:33.852170: Pseudo dice [0.8306, 0.8214, 0.7284, 0.8311, 0.8226]
2024-02-08 13:20:33.852603: Epoch time: 43.16 s
2024-02-08 13:20:34.856577: 
2024-02-08 13:20:34.857631: Epoch 530
2024-02-08 13:20:34.858491: Current learning rate: 0.00051
2024-02-08 13:21:18.089272: train_loss -0.6443
2024-02-08 13:21:18.090804: val_loss -0.3371
2024-02-08 13:21:18.091289: Pseudo dice [0.8368, 0.8252, 0.7345, 0.8263, 0.8219]
2024-02-08 13:21:18.091763: Epoch time: 43.23 s
2024-02-08 13:21:19.103061: 
2024-02-08 13:21:19.104121: Epoch 531
2024-02-08 13:21:19.105407: Current learning rate: 0.00048
2024-02-08 13:22:01.919353: train_loss -0.6465
2024-02-08 13:22:01.921009: val_loss -0.2866
2024-02-08 13:22:01.921504: Pseudo dice [0.8286, 0.8194, 0.7181, 0.8259, 0.8236]
2024-02-08 13:22:01.921966: Epoch time: 42.82 s
2024-02-08 13:22:02.987993: 
2024-02-08 13:22:03.018222: Epoch 532
2024-02-08 13:22:03.018804: Current learning rate: 0.00046
2024-02-08 13:22:46.161678: train_loss -0.6463
2024-02-08 13:22:46.164100: val_loss -0.3726
2024-02-08 13:22:46.164607: Pseudo dice [0.8432, 0.8333, 0.744, 0.8451, 0.8322]
2024-02-08 13:22:46.165096: Epoch time: 43.18 s
2024-02-08 13:22:47.202967: 
2024-02-08 13:22:47.204113: Epoch 533
2024-02-08 13:22:47.205113: Current learning rate: 0.00044
2024-02-08 13:23:30.334819: train_loss -0.645
2024-02-08 13:23:30.336907: val_loss -0.3262
2024-02-08 13:23:30.337405: Pseudo dice [0.8371, 0.8221, 0.7323, 0.8296, 0.8266]
2024-02-08 13:23:30.337840: Epoch time: 43.13 s
2024-02-08 13:23:31.588187: 
2024-02-08 13:23:31.589166: Epoch 534
2024-02-08 13:23:31.590076: Current learning rate: 0.00041
2024-02-08 13:24:14.641949: train_loss -0.6497
2024-02-08 13:24:14.643516: val_loss -0.3415
2024-02-08 13:24:14.644029: Pseudo dice [0.8378, 0.8245, 0.7387, 0.8389, 0.8224]
2024-02-08 13:24:14.644473: Epoch time: 43.05 s
2024-02-08 13:24:15.660018: 
2024-02-08 13:24:15.661579: Epoch 535
2024-02-08 13:24:15.663134: Current learning rate: 0.00039
2024-02-08 13:24:58.361738: train_loss -0.6454
2024-02-08 13:24:58.400586: val_loss -0.3464
2024-02-08 13:24:58.401110: Pseudo dice [0.8395, 0.8275, 0.7364, 0.8451, 0.8202]
2024-02-08 13:24:58.401559: Epoch time: 42.7 s
2024-02-08 13:24:59.420882: 
2024-02-08 13:24:59.422302: Epoch 536
2024-02-08 13:24:59.422798: Current learning rate: 0.00037
2024-02-08 13:25:42.185303: train_loss -0.6488
2024-02-08 13:25:42.186779: val_loss -0.3289
2024-02-08 13:25:42.187258: Pseudo dice [0.8377, 0.8222, 0.7307, 0.8267, 0.8262]
2024-02-08 13:25:42.187718: Epoch time: 42.77 s
2024-02-08 13:25:43.198421: 
2024-02-08 13:25:43.199778: Epoch 537
2024-02-08 13:25:43.201150: Current learning rate: 0.00034
2024-02-08 13:26:26.022991: train_loss -0.6521
2024-02-08 13:26:26.024321: val_loss -0.3364
2024-02-08 13:26:26.025008: Pseudo dice [0.8361, 0.824, 0.7343, 0.8304, 0.8284]
2024-02-08 13:26:26.025665: Epoch time: 42.83 s
2024-02-08 13:26:27.035501: 
2024-02-08 13:26:27.036484: Epoch 538
2024-02-08 13:26:27.037556: Current learning rate: 0.00032
2024-02-08 13:27:10.022029: train_loss -0.649
2024-02-08 13:27:10.023627: val_loss -0.3515
2024-02-08 13:27:10.024097: Pseudo dice [0.8365, 0.8313, 0.7362, 0.8404, 0.8246]
2024-02-08 13:27:10.024525: Epoch time: 42.99 s
2024-02-08 13:27:11.170076: 
2024-02-08 13:27:11.171567: Epoch 539
2024-02-08 13:27:11.172134: Current learning rate: 0.0003
2024-02-08 13:27:54.297607: train_loss -0.6511
2024-02-08 13:27:54.299037: val_loss -0.3497
2024-02-08 13:27:54.299534: Pseudo dice [0.8394, 0.8271, 0.738, 0.8442, 0.8211]
2024-02-08 13:27:54.299998: Epoch time: 43.13 s
2024-02-08 13:27:55.308303: 
2024-02-08 13:27:55.309352: Epoch 540
2024-02-08 13:27:55.310267: Current learning rate: 0.00027
2024-02-08 13:28:37.980275: train_loss -0.6492
2024-02-08 13:28:37.982238: val_loss -0.3544
2024-02-08 13:28:37.982839: Pseudo dice [0.839, 0.8277, 0.7371, 0.8479, 0.8311]
2024-02-08 13:28:37.983346: Epoch time: 42.67 s
2024-02-08 13:28:39.032707: 
2024-02-08 13:28:39.033658: Epoch 541
2024-02-08 13:28:39.034607: Current learning rate: 0.00025
2024-02-08 13:29:21.743615: train_loss -0.647
2024-02-08 13:29:21.745040: val_loss -0.3403
2024-02-08 13:29:21.745536: Pseudo dice [0.8358, 0.8273, 0.735, 0.8474, 0.8243]
2024-02-08 13:29:21.745950: Epoch time: 42.71 s
2024-02-08 13:29:21.746345: Yayy! New best EMA pseudo Dice: 0.8122
2024-02-08 13:29:22.998582: 
2024-02-08 13:29:22.999941: Epoch 542
2024-02-08 13:29:23.000670: Current learning rate: 0.00022
2024-02-08 13:30:05.880789: train_loss -0.6472
2024-02-08 13:30:05.882772: val_loss -0.3354
2024-02-08 13:30:05.883328: Pseudo dice [0.8359, 0.8174, 0.739, 0.8419, 0.8244]
2024-02-08 13:30:05.883823: Epoch time: 42.88 s
2024-02-08 13:30:06.939454: 
2024-02-08 13:30:06.940786: Epoch 543
2024-02-08 13:30:06.942130: Current learning rate: 0.0002
2024-02-08 13:30:49.827475: train_loss -0.6513
2024-02-08 13:30:49.828847: val_loss -0.3242
2024-02-08 13:30:49.829333: Pseudo dice [0.8366, 0.8206, 0.7283, 0.8363, 0.8322]
2024-02-08 13:30:49.829753: Epoch time: 42.89 s
2024-02-08 13:30:50.950176: 
2024-02-08 13:30:50.951651: Epoch 544
2024-02-08 13:30:50.952161: Current learning rate: 0.00017
2024-02-08 13:31:33.437520: train_loss -0.6499
2024-02-08 13:31:33.438927: val_loss -0.3388
2024-02-08 13:31:33.439415: Pseudo dice [0.8384, 0.8295, 0.7365, 0.8333, 0.8224]
2024-02-08 13:31:33.439868: Epoch time: 42.49 s
2024-02-08 13:31:34.438692: 
2024-02-08 13:31:34.439502: Epoch 545
2024-02-08 13:31:34.440352: Current learning rate: 0.00015
2024-02-08 13:32:17.326416: train_loss -0.6416
2024-02-08 13:32:17.327842: val_loss -0.3402
2024-02-08 13:32:17.328314: Pseudo dice [0.8393, 0.831, 0.7315, 0.8401, 0.8263]
2024-02-08 13:32:17.328741: Epoch time: 42.89 s
2024-02-08 13:32:18.326422: 
2024-02-08 13:32:18.328309: Epoch 546
2024-02-08 13:32:18.328876: Current learning rate: 0.00012
2024-02-08 13:33:01.376453: train_loss -0.6468
2024-02-08 13:33:01.377920: val_loss -0.3231
2024-02-08 13:33:01.378386: Pseudo dice [0.8315, 0.8253, 0.7325, 0.8032, 0.8249]
2024-02-08 13:33:01.378814: Epoch time: 43.05 s
2024-02-08 13:33:02.395097: 
2024-02-08 13:33:02.396693: Epoch 547
2024-02-08 13:33:02.397201: Current learning rate: 9e-05
2024-02-08 13:33:45.605983: train_loss -0.6473
2024-02-08 13:33:45.607414: val_loss -0.3205
2024-02-08 13:33:45.607883: Pseudo dice [0.8359, 0.8242, 0.7264, 0.8457, 0.8172]
2024-02-08 13:33:45.609136: Epoch time: 43.21 s
2024-02-08 13:33:46.605313: 
2024-02-08 13:33:46.606814: Epoch 548
2024-02-08 13:33:46.607378: Current learning rate: 6e-05
2024-02-08 13:34:29.645444: train_loss -0.6495
2024-02-08 13:34:29.646781: val_loss -0.3063
2024-02-08 13:34:29.647252: Pseudo dice [0.8316, 0.819, 0.7268, 0.8309, 0.8213]
2024-02-08 13:34:29.647660: Epoch time: 43.04 s
2024-02-08 13:34:30.662670: 
2024-02-08 13:34:30.664181: Epoch 549
2024-02-08 13:34:30.664784: Current learning rate: 3e-05
2024-02-08 13:35:13.857069: train_loss -0.6492
2024-02-08 13:35:13.858434: val_loss -0.3378
2024-02-08 13:35:13.858900: Pseudo dice [0.836, 0.8284, 0.732, 0.8242, 0.8277]
2024-02-08 13:35:13.859353: Epoch time: 43.2 s
2024-02-08 13:35:15.607611: Training done.
2024-02-08 13:35:15.978927: Using splits from existing split file: /scratch/gilbreth/li2068/nnUNet_v2/nnUNet_preprocessed/Dataset301_HMstroke/splits_final.json
2024-02-08 13:35:15.980231: The split file contains 5 splits.
2024-02-08 13:35:15.980542: Desired fold for training: 4
2024-02-08 13:35:15.980870: This split has 64 training and 16 validation cases.
2024-02-08 13:35:15.981368: predicting HM_001
2024-02-08 13:35:20.006466: predicting HM_007
2024-02-08 13:35:24.264953: predicting HM_010
2024-02-08 13:35:27.115539: predicting HM_011
2024-02-08 13:35:29.044552: predicting HM_014
2024-02-08 13:35:30.957048: predicting HM_023
2024-02-08 13:35:33.806402: predicting HM_029
2024-02-08 13:35:36.665352: predicting HM_034
2024-02-08 13:35:38.589574: predicting HM_036
2024-02-08 13:35:40.519023: predicting HM_038
2024-02-08 13:35:44.770788: predicting HM_041
2024-02-08 13:35:46.690540: predicting HM_043
2024-02-08 13:35:48.606044: predicting HM_059
2024-02-08 13:35:51.454796: predicting HM_074
2024-02-08 13:35:53.372488: predicting HM_078
2024-02-08 13:35:55.297562: predicting HM_079
2024-02-08 13:36:03.245425: Validation complete
2024-02-08 13:36:03.246213: Mean Validation Dice:  0.8146345313953269
