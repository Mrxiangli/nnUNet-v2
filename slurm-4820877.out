
The following have been reloaded with a version change:
  1) cuda/11.2.0 => cuda/11.7.0

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################


This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 256, 224], 'median_image_size_in_voxels': [50.0, 379.5, 300.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [3, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset301_HMstroke', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [50, 380, 300], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 111.81842803955078, 'mean': 35.17890167236328, 'median': 36.134971618652344, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 66.58898174285878, 'std': 10.811899185180664}}} 

2024-02-08 00:28:11.316079: unpacking dataset...
2024-02-08 00:28:14.838483: unpacking done...
2024-02-08 00:28:14.842540: do_dummy_2d_data_aug: True
2024-02-08 00:28:14.845587: Using splits from existing split file: /scratch/gilbreth/li2068/nnUNet_v2/nnUNet_preprocessed/Dataset301_HMstroke/splits_final.json
2024-02-08 00:28:14.846817: The split file contains 5 splits.
2024-02-08 00:28:14.847169: Desired fold for training: 5
2024-02-08 00:28:14.847476: INFO: You requested fold 5 for training but splits contain only 5 folds. I am now creating a random (but seeded) 80:20 split!
2024-02-08 00:28:14.849097: This random 80:20 split has 64 training and 16 validation cases.
===============================================================================================
Layer (type:depth-idx)                                                 Param #
===============================================================================================
PlainConvUNet                                                          --
├─PlainConvEncoder: 1-1                                                --
│    └─Sequential: 2-1                                                 --
│    │    └─Sequential: 3-1                                            28,704
│    │    └─Sequential: 3-2                                            166,272
│    │    └─Sequential: 3-3                                            664,320
│    │    └─Sequential: 3-4                                            2,655,744
│    │    └─Sequential: 3-5                                            4,978,560
│    │    └─Sequential: 3-6                                            5,531,520
├─UNetDecoder: 1-2                                                     14,025,120
│    └─PlainConvEncoder: 2-2                                           (recursive)
│    │    └─Sequential: 3-7                                            (recursive)
│    └─ModuleList: 2-3                                                 --
│    │    └─StackedConvBlocks: 3-8                                     8,296,320
│    │    └─StackedConvBlocks: 3-9                                     5,309,952
│    │    └─StackedConvBlocks: 3-10                                    1,327,872
│    │    └─StackedConvBlocks: 3-11                                    332,160
│    │    └─StackedConvBlocks: 3-12                                    83,136
│    └─ModuleList: 2-4                                                 --
│    │    └─ConvTranspose3d: 3-13                                      409,920
│    │    └─ConvTranspose3d: 3-14                                      327,936
│    │    └─ConvTranspose3d: 3-15                                      262,272
│    │    └─ConvTranspose3d: 3-16                                      65,600
│    │    └─ConvTranspose3d: 3-17                                      16,416
│    └─ModuleList: 2-5                                                 --
│    │    └─Conv3d: 3-18                                               1,926
│    │    └─Conv3d: 3-19                                               1,542
│    │    └─Conv3d: 3-20                                               774
│    │    └─Conv3d: 3-21                                               390
│    │    └─Conv3d: 3-22                                               198
===============================================================================================
Total params: 73,861,214
Trainable params: 73,861,214
Non-trainable params: 0
===============================================================================================
finish writing the model summary file
2024-02-08 00:28:18.127309: 
2024-02-08 00:28:18.127909: Epoch 0
2024-02-08 00:28:18.128487: Current learning rate: 0.01
/home/li2068/.conda/envs/centos7/conda-4.9.2/nnunetv1/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py:1457: UserWarning: ONNX export mode is set to TrainingMode.EVAL, but operator 'instance_norm' is set to train=True. Exporting with train=True.
  warnings.warn(
using pin_memory on device 0
using pin_memory on device 0
2024-02-08 00:29:11.190375: train_loss 0.5325
2024-02-08 00:29:11.192502: val_loss 0.2522
2024-02-08 00:29:11.192898: Pseudo dice [0.7083, 0.6822, 0.5476, 0.0, 0.4868]
2024-02-08 00:29:11.193230: Epoch time: 53.06 s
2024-02-08 00:29:11.193544: Yayy! New best EMA pseudo Dice: 0.485
2024-02-08 00:29:12.350458: 
2024-02-08 00:29:12.351992: Epoch 1
2024-02-08 00:29:12.352917: Current learning rate: 0.00998
2024-02-08 00:29:54.844460: train_loss 0.145
2024-02-08 00:29:54.846141: val_loss 0.0311
2024-02-08 00:29:54.846572: Pseudo dice [0.7241, 0.7211, 0.6002, 0.629, 0.6191]
2024-02-08 00:29:54.846981: Epoch time: 42.5 s
2024-02-08 00:29:54.847411: Yayy! New best EMA pseudo Dice: 0.5024
2024-02-08 00:29:56.285187: 
2024-02-08 00:29:56.286603: Epoch 2
2024-02-08 00:29:56.287078: Current learning rate: 0.00997
2024-02-08 00:30:39.058007: train_loss -0.027
2024-02-08 00:30:39.059708: val_loss -0.1028
2024-02-08 00:30:39.060103: Pseudo dice [0.7514, 0.7324, 0.6572, 0.6878, 0.7058]
2024-02-08 00:30:39.060457: Epoch time: 42.77 s
2024-02-08 00:30:39.060753: Yayy! New best EMA pseudo Dice: 0.5228
2024-02-08 00:30:40.478459: 
2024-02-08 00:30:40.480161: Epoch 3
2024-02-08 00:30:40.480620: Current learning rate: 0.00995
2024-02-08 00:31:23.339999: train_loss -0.1117
2024-02-08 00:31:23.341421: val_loss -0.154
2024-02-08 00:31:23.341995: Pseudo dice [0.7613, 0.7409, 0.6721, 0.7314, 0.73]
2024-02-08 00:31:23.342440: Epoch time: 42.86 s
2024-02-08 00:31:23.342887: Yayy! New best EMA pseudo Dice: 0.5432
2024-02-08 00:31:24.664701: 
2024-02-08 00:31:24.666471: Epoch 4
2024-02-08 00:31:24.667087: Current learning rate: 0.00993
2024-02-08 00:32:07.717969: train_loss -0.1641
2024-02-08 00:32:07.720084: val_loss -0.1766
2024-02-08 00:32:07.720633: Pseudo dice [0.7661, 0.755, 0.6695, 0.7272, 0.7481]
2024-02-08 00:32:07.721156: Epoch time: 43.05 s
2024-02-08 00:32:07.721650: Yayy! New best EMA pseudo Dice: 0.5622
2024-02-08 00:32:09.113652: 
2024-02-08 00:32:09.114980: Epoch 5
2024-02-08 00:32:09.116373: Current learning rate: 0.00992
2024-02-08 00:32:52.214888: train_loss -0.188
2024-02-08 00:32:52.216257: val_loss -0.1882
2024-02-08 00:32:52.216722: Pseudo dice [0.769, 0.761, 0.6827, 0.7514, 0.7278]
2024-02-08 00:32:52.217135: Epoch time: 43.1 s
2024-02-08 00:32:52.217558: Yayy! New best EMA pseudo Dice: 0.5799
2024-02-08 00:32:53.815145: 
2024-02-08 00:32:53.832791: Epoch 6
2024-02-08 00:32:53.834486: Current learning rate: 0.0099
2024-02-08 00:33:36.817784: train_loss -0.2192
2024-02-08 00:33:36.819330: val_loss -0.2196
2024-02-08 00:33:36.819869: Pseudo dice [0.7736, 0.7685, 0.6848, 0.7612, 0.7751]
2024-02-08 00:33:36.820365: Epoch time: 43.0 s
2024-02-08 00:33:36.820791: Yayy! New best EMA pseudo Dice: 0.5971
2024-02-08 00:33:38.160159: 
2024-02-08 00:33:38.162529: Epoch 7
2024-02-08 00:33:38.163675: Current learning rate: 0.00989
2024-02-08 00:34:21.065796: train_loss -0.2275
2024-02-08 00:34:21.067591: val_loss -0.2423
2024-02-08 00:34:21.068123: Pseudo dice [0.7807, 0.7792, 0.698, 0.7556, 0.7703]
2024-02-08 00:34:21.068669: Epoch time: 42.91 s
2024-02-08 00:34:21.069104: Yayy! New best EMA pseudo Dice: 0.6131
2024-02-08 00:34:22.519724: 
2024-02-08 00:34:22.520823: Epoch 8
2024-02-08 00:34:22.521798: Current learning rate: 0.00987
2024-02-08 00:35:05.523883: train_loss -0.2361
2024-02-08 00:35:05.526009: val_loss -0.251
2024-02-08 00:35:05.526604: Pseudo dice [0.7895, 0.7708, 0.6968, 0.7768, 0.7952]
2024-02-08 00:35:05.527108: Epoch time: 43.01 s
2024-02-08 00:35:05.527534: Yayy! New best EMA pseudo Dice: 0.6284
2024-02-08 00:35:06.873362: 
2024-02-08 00:35:06.874559: Epoch 9
2024-02-08 00:35:06.875513: Current learning rate: 0.00985
2024-02-08 00:35:50.020501: train_loss -0.2549
2024-02-08 00:35:50.022009: val_loss -0.257
2024-02-08 00:35:50.022486: Pseudo dice [0.7931, 0.7711, 0.6856, 0.7728, 0.781]
2024-02-08 00:35:50.022921: Epoch time: 43.15 s
2024-02-08 00:35:50.023357: Yayy! New best EMA pseudo Dice: 0.6416
2024-02-08 00:35:51.298218: 
2024-02-08 00:35:51.299345: Epoch 10
2024-02-08 00:35:51.300582: Current learning rate: 0.00984
2024-02-08 00:36:34.204509: train_loss -0.264
2024-02-08 00:36:34.206199: val_loss -0.2769
2024-02-08 00:36:34.206702: Pseudo dice [0.793, 0.779, 0.7015, 0.793, 0.7971]
2024-02-08 00:36:34.207222: Epoch time: 42.91 s
2024-02-08 00:36:34.207698: Yayy! New best EMA pseudo Dice: 0.6547
2024-02-08 00:36:35.708732: 
2024-02-08 00:36:35.710158: Epoch 11
2024-02-08 00:36:35.711366: Current learning rate: 0.00982
2024-02-08 00:37:18.868857: train_loss -0.2737
2024-02-08 00:37:18.870683: val_loss -0.2708
2024-02-08 00:37:18.871181: Pseudo dice [0.7895, 0.7758, 0.7086, 0.7783, 0.7812]
2024-02-08 00:37:18.871657: Epoch time: 43.16 s
2024-02-08 00:37:18.872138: Yayy! New best EMA pseudo Dice: 0.6659
2024-02-08 00:37:20.195268: 
2024-02-08 00:37:20.196734: Epoch 12
2024-02-08 00:37:20.197403: Current learning rate: 0.0098
2024-02-08 00:38:03.282850: train_loss -0.2883
2024-02-08 00:38:03.284775: val_loss -0.2663
2024-02-08 00:38:03.285300: Pseudo dice [0.7934, 0.7802, 0.6985, 0.7633, 0.7775]
2024-02-08 00:38:03.285825: Epoch time: 43.09 s
2024-02-08 00:38:03.286249: Yayy! New best EMA pseudo Dice: 0.6756
2024-02-08 00:38:04.625037: 
2024-02-08 00:38:04.626201: Epoch 13
2024-02-08 00:38:04.627191: Current learning rate: 0.00979
2024-02-08 00:38:47.390149: train_loss -0.2941
2024-02-08 00:38:47.391854: val_loss -0.2997
2024-02-08 00:38:47.392377: Pseudo dice [0.8028, 0.7838, 0.7142, 0.7944, 0.7997]
2024-02-08 00:38:47.392850: Epoch time: 42.77 s
2024-02-08 00:38:47.393310: Yayy! New best EMA pseudo Dice: 0.6859
2024-02-08 00:38:48.712048: 
2024-02-08 00:38:48.713015: Epoch 14
2024-02-08 00:38:48.713866: Current learning rate: 0.00977
2024-02-08 00:39:31.557021: train_loss -0.3013
2024-02-08 00:39:31.558481: val_loss -0.3028
2024-02-08 00:39:31.558969: Pseudo dice [0.801, 0.7835, 0.7261, 0.7873, 0.8061]
2024-02-08 00:39:31.559381: Epoch time: 42.85 s
2024-02-08 00:39:31.559810: Yayy! New best EMA pseudo Dice: 0.6954
2024-02-08 00:39:32.882620: 
2024-02-08 00:39:32.883627: Epoch 15
2024-02-08 00:39:32.884896: Current learning rate: 0.00975
2024-02-08 00:40:16.031710: train_loss -0.3113
2024-02-08 00:40:16.033212: val_loss -0.3069
2024-02-08 00:40:16.033662: Pseudo dice [0.8006, 0.7954, 0.7176, 0.7976, 0.7955]
2024-02-08 00:40:16.034090: Epoch time: 43.15 s
2024-02-08 00:40:16.034487: Yayy! New best EMA pseudo Dice: 0.704
2024-02-08 00:40:17.367375: 
2024-02-08 00:40:17.368500: Epoch 16
2024-02-08 00:40:17.369571: Current learning rate: 0.00974
2024-02-08 00:41:00.606669: train_loss -0.3145
2024-02-08 00:41:00.608207: val_loss -0.3227
2024-02-08 00:41:00.608694: Pseudo dice [0.8045, 0.7925, 0.7152, 0.7931, 0.8132]
2024-02-08 00:41:00.609161: Epoch time: 43.24 s
2024-02-08 00:41:00.609579: Yayy! New best EMA pseudo Dice: 0.712
2024-02-08 00:41:02.152042: 
2024-02-08 00:41:02.153407: Epoch 17
2024-02-08 00:41:02.155020: Current learning rate: 0.00972
2024-02-08 00:41:45.283234: train_loss -0.3149
2024-02-08 00:41:45.284692: val_loss -0.3135
2024-02-08 00:41:45.285178: Pseudo dice [0.8003, 0.7946, 0.7223, 0.7874, 0.805]
2024-02-08 00:41:45.285638: Epoch time: 43.13 s
2024-02-08 00:41:45.286043: Yayy! New best EMA pseudo Dice: 0.719
2024-02-08 00:41:46.632895: 
2024-02-08 00:41:46.633943: Epoch 18
2024-02-08 00:41:46.634875: Current learning rate: 0.0097
2024-02-08 00:42:29.764207: train_loss -0.3257
2024-02-08 00:42:29.766234: val_loss -0.3184
2024-02-08 00:42:29.766772: Pseudo dice [0.8091, 0.7874, 0.715, 0.7997, 0.8031]
2024-02-08 00:42:29.767272: Epoch time: 43.13 s
2024-02-08 00:42:29.767708: Yayy! New best EMA pseudo Dice: 0.7254
2024-02-08 00:42:31.136153: 
2024-02-08 00:42:31.137193: Epoch 19
2024-02-08 00:42:31.138241: Current learning rate: 0.00969
2024-02-08 00:43:14.112620: train_loss -0.3362
2024-02-08 00:43:14.113971: val_loss -0.323
2024-02-08 00:43:14.114438: Pseudo dice [0.806, 0.7895, 0.7081, 0.8066, 0.8056]
2024-02-08 00:43:14.114884: Epoch time: 42.98 s
2024-02-08 00:43:14.115294: Yayy! New best EMA pseudo Dice: 0.7311
2024-02-08 00:43:15.483293: 
2024-02-08 00:43:15.484726: Epoch 20
2024-02-08 00:43:15.485960: Current learning rate: 0.00967
2024-02-08 00:43:58.473464: train_loss -0.3372
2024-02-08 00:43:58.475032: val_loss -0.3453
2024-02-08 00:43:58.475509: Pseudo dice [0.8159, 0.7918, 0.7246, 0.8105, 0.8224]
2024-02-08 00:43:58.475974: Epoch time: 42.99 s
2024-02-08 00:43:58.476524: Yayy! New best EMA pseudo Dice: 0.7373
2024-02-08 00:43:59.853500: 
2024-02-08 00:43:59.854670: Epoch 21
2024-02-08 00:43:59.855517: Current learning rate: 0.00966
2024-02-08 00:44:42.974389: train_loss -0.3423
2024-02-08 00:44:42.975924: val_loss -0.3097
2024-02-08 00:44:42.976391: Pseudo dice [0.8017, 0.7902, 0.7148, 0.7992, 0.7849]
2024-02-08 00:44:42.976852: Epoch time: 43.12 s
2024-02-08 00:44:42.977287: Yayy! New best EMA pseudo Dice: 0.7414
2024-02-08 00:44:44.304398: 
2024-02-08 00:44:44.306061: Epoch 22
2024-02-08 00:44:44.306605: Current learning rate: 0.00964
2024-02-08 00:45:27.427915: train_loss -0.3426
2024-02-08 00:45:27.429352: val_loss -0.3385
2024-02-08 00:45:27.429840: Pseudo dice [0.8127, 0.8068, 0.721, 0.8214, 0.8097]
2024-02-08 00:45:27.430278: Epoch time: 43.12 s
2024-02-08 00:45:27.430709: Yayy! New best EMA pseudo Dice: 0.7467
2024-02-08 00:45:28.771386: 
2024-02-08 00:45:28.772530: Epoch 23
2024-02-08 00:45:28.773559: Current learning rate: 0.00962
2024-02-08 00:46:11.813345: train_loss -0.3396
2024-02-08 00:46:11.814786: val_loss -0.3253
2024-02-08 00:46:11.815261: Pseudo dice [0.8059, 0.7952, 0.7246, 0.8107, 0.8043]
2024-02-08 00:46:11.815794: Epoch time: 43.04 s
2024-02-08 00:46:11.816208: Yayy! New best EMA pseudo Dice: 0.7508
2024-02-08 00:46:13.111766: 
2024-02-08 00:46:13.113228: Epoch 24
2024-02-08 00:46:13.114382: Current learning rate: 0.00961
2024-02-08 00:46:56.234048: train_loss -0.3471
2024-02-08 00:46:56.235435: val_loss -0.3453
2024-02-08 00:46:56.235884: Pseudo dice [0.8142, 0.8022, 0.7086, 0.8144, 0.8095]
2024-02-08 00:46:56.236296: Epoch time: 43.12 s
2024-02-08 00:46:56.236673: Yayy! New best EMA pseudo Dice: 0.7547
2024-02-08 00:46:57.570491: 
2024-02-08 00:46:57.571588: Epoch 25
2024-02-08 00:46:57.572516: Current learning rate: 0.00959
2024-02-08 00:47:40.841931: train_loss -0.3529
2024-02-08 00:47:40.843266: val_loss -0.3234
2024-02-08 00:47:40.843723: Pseudo dice [0.8035, 0.8011, 0.7248, 0.8099, 0.7967]
2024-02-08 00:47:40.844369: Epoch time: 43.27 s
2024-02-08 00:47:40.844779: Yayy! New best EMA pseudo Dice: 0.758
2024-02-08 00:47:42.181437: 
2024-02-08 00:47:42.182552: Epoch 26
2024-02-08 00:47:42.183752: Current learning rate: 0.00957
2024-02-08 00:48:25.456040: train_loss -0.3603
2024-02-08 00:48:25.458133: val_loss -0.3462
2024-02-08 00:48:25.458627: Pseudo dice [0.8106, 0.7982, 0.718, 0.7978, 0.7937]
2024-02-08 00:48:25.459286: Epoch time: 43.28 s
2024-02-08 00:48:25.459743: Yayy! New best EMA pseudo Dice: 0.7606
2024-02-08 00:48:26.794837: 
2024-02-08 00:48:26.796030: Epoch 27
2024-02-08 00:48:26.797044: Current learning rate: 0.00956
2024-02-08 00:49:10.006405: train_loss -0.3532
2024-02-08 00:49:10.007706: val_loss -0.3261
2024-02-08 00:49:10.008168: Pseudo dice [0.8048, 0.7855, 0.7223, 0.8048, 0.8097]
2024-02-08 00:49:10.008619: Epoch time: 43.21 s
2024-02-08 00:49:10.009048: Yayy! New best EMA pseudo Dice: 0.763
2024-02-08 00:49:11.340970: 
2024-02-08 00:49:11.342436: Epoch 28
2024-02-08 00:49:11.343848: Current learning rate: 0.00954
2024-02-08 00:49:54.643032: train_loss -0.3684
2024-02-08 00:49:54.644582: val_loss -0.3378
2024-02-08 00:49:54.645060: Pseudo dice [0.8047, 0.7988, 0.7297, 0.8024, 0.8161]
2024-02-08 00:49:54.645462: Epoch time: 43.3 s
2024-02-08 00:49:54.646053: Yayy! New best EMA pseudo Dice: 0.7658
2024-02-08 00:49:55.968402: 
2024-02-08 00:49:55.969421: Epoch 29
2024-02-08 00:49:55.970439: Current learning rate: 0.00952
2024-02-08 00:50:38.994761: train_loss -0.3646
2024-02-08 00:50:38.996342: val_loss -0.3275
2024-02-08 00:50:38.996801: Pseudo dice [0.8164, 0.7948, 0.7081, 0.8113, 0.8159]
2024-02-08 00:50:38.997243: Epoch time: 43.03 s
2024-02-08 00:50:38.997626: Yayy! New best EMA pseudo Dice: 0.7681
2024-02-08 00:50:40.381419: 
2024-02-08 00:50:40.382819: Epoch 30
2024-02-08 00:50:40.383342: Current learning rate: 0.00951
2024-02-08 00:51:23.313995: train_loss -0.3698
2024-02-08 00:51:23.315587: val_loss -0.3479
2024-02-08 00:51:23.316340: Pseudo dice [0.8148, 0.8018, 0.7089, 0.8088, 0.8138]
2024-02-08 00:51:23.316814: Epoch time: 42.93 s
2024-02-08 00:51:23.317258: Yayy! New best EMA pseudo Dice: 0.7703
2024-02-08 00:51:24.969487: 
2024-02-08 00:51:24.970486: Epoch 31
2024-02-08 00:51:24.971016: Current learning rate: 0.00949
2024-02-08 00:52:08.163173: train_loss -0.3716
2024-02-08 00:52:08.165327: val_loss -0.3473
2024-02-08 00:52:08.165816: Pseudo dice [0.8176, 0.8027, 0.7205, 0.8082, 0.8138]
2024-02-08 00:52:08.166270: Epoch time: 43.19 s
2024-02-08 00:52:08.166757: Yayy! New best EMA pseudo Dice: 0.7725
2024-02-08 00:52:09.512248: 
2024-02-08 00:52:09.513792: Epoch 32
2024-02-08 00:52:09.514791: Current learning rate: 0.00947
2024-02-08 00:52:52.694856: train_loss -0.376
2024-02-08 00:52:52.696339: val_loss -0.3658
2024-02-08 00:52:52.696785: Pseudo dice [0.8202, 0.806, 0.7303, 0.8299, 0.816]
2024-02-08 00:52:52.697193: Epoch time: 43.18 s
2024-02-08 00:52:52.697594: Yayy! New best EMA pseudo Dice: 0.7753
2024-02-08 00:52:54.020448: 
2024-02-08 00:52:54.022007: Epoch 33
2024-02-08 00:52:54.023711: Current learning rate: 0.00946
2024-02-08 00:53:37.283091: train_loss -0.3759
2024-02-08 00:53:37.285114: val_loss -0.355
2024-02-08 00:53:37.285621: Pseudo dice [0.8178, 0.7974, 0.7312, 0.8162, 0.8174]
2024-02-08 00:53:37.286086: Epoch time: 43.26 s
2024-02-08 00:53:37.286561: Yayy! New best EMA pseudo Dice: 0.7774
2024-02-08 00:53:38.660460: 
2024-02-08 00:53:38.661852: Epoch 34
2024-02-08 00:53:38.662861: Current learning rate: 0.00944
2024-02-08 00:54:22.009700: train_loss -0.3791
2024-02-08 00:54:22.011616: val_loss -0.3414
2024-02-08 00:54:22.012400: Pseudo dice [0.8121, 0.8017, 0.7263, 0.8154, 0.811]
2024-02-08 00:54:22.012902: Epoch time: 43.35 s
2024-02-08 00:54:22.013357: Yayy! New best EMA pseudo Dice: 0.779
2024-02-08 00:54:23.377448: 
2024-02-08 00:54:23.378825: Epoch 35
2024-02-08 00:54:23.380258: Current learning rate: 0.00943
2024-02-08 00:55:06.665068: train_loss -0.3846
2024-02-08 00:55:06.666440: val_loss -0.3511
2024-02-08 00:55:06.666951: Pseudo dice [0.8201, 0.7991, 0.725, 0.8187, 0.8111]
2024-02-08 00:55:06.667388: Epoch time: 43.29 s
2024-02-08 00:55:06.667824: Yayy! New best EMA pseudo Dice: 0.7805
2024-02-08 00:55:08.166560: 
2024-02-08 00:55:08.168077: Epoch 36
2024-02-08 00:55:08.169685: Current learning rate: 0.00941
2024-02-08 00:55:51.403320: train_loss -0.3871
2024-02-08 00:55:51.404679: val_loss -0.3563
2024-02-08 00:55:51.405175: Pseudo dice [0.8179, 0.8066, 0.718, 0.818, 0.804]
2024-02-08 00:55:51.405615: Epoch time: 43.24 s
2024-02-08 00:55:51.406018: Yayy! New best EMA pseudo Dice: 0.7818
2024-02-08 00:55:52.771383: 
2024-02-08 00:55:52.772761: Epoch 37
2024-02-08 00:55:52.774301: Current learning rate: 0.00939
2024-02-08 00:56:36.049245: train_loss -0.3924
2024-02-08 00:56:36.050603: val_loss -0.3553
2024-02-08 00:56:36.051054: Pseudo dice [0.8198, 0.7948, 0.7318, 0.8214, 0.8147]
2024-02-08 00:56:36.051511: Epoch time: 43.28 s
2024-02-08 00:56:36.051928: Yayy! New best EMA pseudo Dice: 0.7833
2024-02-08 00:56:37.409721: 
2024-02-08 00:56:37.410878: Epoch 38
2024-02-08 00:56:37.411842: Current learning rate: 0.00938
2024-02-08 00:57:20.654040: train_loss -0.3947
2024-02-08 00:57:20.655610: val_loss -0.3358
2024-02-08 00:57:20.656152: Pseudo dice [0.809, 0.7851, 0.7267, 0.7955, 0.8117]
2024-02-08 00:57:20.656635: Epoch time: 43.25 s
2024-02-08 00:57:20.657092: Yayy! New best EMA pseudo Dice: 0.7835
2024-02-08 00:57:22.026058: 
2024-02-08 00:57:22.027242: Epoch 39
2024-02-08 00:57:22.028430: Current learning rate: 0.00936
2024-02-08 00:58:05.180259: train_loss -0.3945
2024-02-08 00:58:05.181809: val_loss -0.3407
2024-02-08 00:58:05.182295: Pseudo dice [0.8168, 0.8044, 0.7102, 0.8184, 0.8169]
2024-02-08 00:58:05.182724: Epoch time: 43.16 s
2024-02-08 00:58:05.183128: Yayy! New best EMA pseudo Dice: 0.7845
2024-02-08 00:58:06.616384: 
2024-02-08 00:58:06.618102: Epoch 40
2024-02-08 00:58:06.619060: Current learning rate: 0.00934
2024-02-08 00:58:49.851299: train_loss -0.3919
2024-02-08 00:58:49.852900: val_loss -0.3575
2024-02-08 00:58:49.853347: Pseudo dice [0.8169, 0.7968, 0.7252, 0.8126, 0.8136]
2024-02-08 00:58:49.853762: Epoch time: 43.24 s
2024-02-08 00:58:49.854158: Yayy! New best EMA pseudo Dice: 0.7853
2024-02-08 00:58:51.222874: 
2024-02-08 00:58:51.223885: Epoch 41
2024-02-08 00:58:51.224885: Current learning rate: 0.00933
2024-02-08 00:59:34.644440: train_loss -0.3908
2024-02-08 00:59:34.645845: val_loss -0.3378
2024-02-08 00:59:34.646307: Pseudo dice [0.8152, 0.798, 0.7189, 0.8081, 0.8183]
2024-02-08 00:59:34.646751: Epoch time: 43.42 s
2024-02-08 00:59:34.647176: Yayy! New best EMA pseudo Dice: 0.786
2024-02-08 00:59:36.117826: 
2024-02-08 00:59:36.119447: Epoch 42
2024-02-08 00:59:36.120599: Current learning rate: 0.00931
2024-02-08 01:00:19.137530: train_loss -0.3991
2024-02-08 01:00:19.138809: val_loss -0.3626
2024-02-08 01:00:19.139297: Pseudo dice [0.8194, 0.8056, 0.736, 0.8271, 0.8038]
2024-02-08 01:00:19.139718: Epoch time: 43.02 s
2024-02-08 01:00:19.140179: Yayy! New best EMA pseudo Dice: 0.7872
2024-02-08 01:00:20.450582: 
2024-02-08 01:00:20.451563: Epoch 43
2024-02-08 01:00:20.452450: Current learning rate: 0.00929
2024-02-08 01:01:03.660770: train_loss -0.4022
2024-02-08 01:01:03.662584: val_loss -0.3474
2024-02-08 01:01:03.663042: Pseudo dice [0.8151, 0.8032, 0.7331, 0.8144, 0.8055]
2024-02-08 01:01:03.663498: Epoch time: 43.21 s
2024-02-08 01:01:03.663898: Yayy! New best EMA pseudo Dice: 0.7879
2024-02-08 01:01:04.990279: 
2024-02-08 01:01:04.991844: Epoch 44
2024-02-08 01:01:04.992353: Current learning rate: 0.00928
2024-02-08 01:01:48.046254: train_loss -0.3953
2024-02-08 01:01:48.047649: val_loss -0.3498
2024-02-08 01:01:48.048111: Pseudo dice [0.8145, 0.8019, 0.7238, 0.8096, 0.8135]
2024-02-08 01:01:48.048550: Epoch time: 43.06 s
2024-02-08 01:01:48.048964: Yayy! New best EMA pseudo Dice: 0.7884
2024-02-08 01:01:49.383987: 
2024-02-08 01:01:49.385781: Epoch 45
2024-02-08 01:01:49.387085: Current learning rate: 0.00926
2024-02-08 01:02:32.623340: train_loss -0.4025
2024-02-08 01:02:32.624985: val_loss -0.3682
2024-02-08 01:02:32.625525: Pseudo dice [0.8219, 0.8013, 0.7392, 0.8343, 0.816]
2024-02-08 01:02:32.626000: Epoch time: 43.24 s
2024-02-08 01:02:32.626442: Yayy! New best EMA pseudo Dice: 0.7898
2024-02-08 01:02:33.931141: 
2024-02-08 01:02:33.932219: Epoch 46
2024-02-08 01:02:33.933193: Current learning rate: 0.00924
2024-02-08 01:03:17.106481: train_loss -0.4134
2024-02-08 01:03:17.107805: val_loss -0.3602
2024-02-08 01:03:17.108255: Pseudo dice [0.8137, 0.8017, 0.7376, 0.821, 0.8137]
2024-02-08 01:03:17.108715: Epoch time: 43.18 s
2024-02-08 01:03:17.109138: Yayy! New best EMA pseudo Dice: 0.7906
2024-02-08 01:03:18.680003: 
2024-02-08 01:03:18.681147: Epoch 47
2024-02-08 01:03:18.681752: Current learning rate: 0.00923
2024-02-08 01:04:01.892797: train_loss -0.4092
2024-02-08 01:04:01.894599: val_loss -0.3549
2024-02-08 01:04:01.895150: Pseudo dice [0.8154, 0.8066, 0.7307, 0.8161, 0.8136]
2024-02-08 01:04:01.895700: Epoch time: 43.21 s
2024-02-08 01:04:01.896138: Yayy! New best EMA pseudo Dice: 0.7912
2024-02-08 01:04:03.209421: 
2024-02-08 01:04:03.211035: Epoch 48
2024-02-08 01:04:03.211986: Current learning rate: 0.00921
2024-02-08 01:04:46.396996: train_loss -0.4118
2024-02-08 01:04:46.398427: val_loss -0.3636
2024-02-08 01:04:46.398916: Pseudo dice [0.8214, 0.8072, 0.7295, 0.827, 0.825]
2024-02-08 01:04:46.399409: Epoch time: 43.19 s
2024-02-08 01:04:46.399803: Yayy! New best EMA pseudo Dice: 0.7923
2024-02-08 01:04:47.744772: 
2024-02-08 01:04:47.745870: Epoch 49
2024-02-08 01:04:47.746713: Current learning rate: 0.00919
2024-02-08 01:05:30.759520: train_loss -0.4103
2024-02-08 01:05:30.761374: val_loss -0.3642
2024-02-08 01:05:30.762123: Pseudo dice [0.8203, 0.8098, 0.7207, 0.8125, 0.8169]
2024-02-08 01:05:30.762586: Epoch time: 43.02 s
2024-02-08 01:05:30.988325: Yayy! New best EMA pseudo Dice: 0.7926
2024-02-08 01:05:32.353798: 
2024-02-08 01:05:32.355352: Epoch 50
2024-02-08 01:05:32.356039: Current learning rate: 0.00918
2024-02-08 01:06:15.521781: train_loss -0.4186
2024-02-08 01:06:15.523243: val_loss -0.3577
2024-02-08 01:06:15.523679: Pseudo dice [0.8207, 0.8001, 0.7289, 0.8216, 0.8124]
2024-02-08 01:06:15.524058: Epoch time: 43.17 s
2024-02-08 01:06:15.524353: Yayy! New best EMA pseudo Dice: 0.793
2024-02-08 01:06:16.817498: 
2024-02-08 01:06:16.818412: Epoch 51
2024-02-08 01:06:16.819489: Current learning rate: 0.00916
2024-02-08 01:06:59.905519: train_loss -0.4137
2024-02-08 01:06:59.907951: val_loss -0.3718
2024-02-08 01:06:59.908381: Pseudo dice [0.8229, 0.8061, 0.7375, 0.8287, 0.8183]
2024-02-08 01:06:59.908813: Epoch time: 43.09 s
2024-02-08 01:06:59.909192: Yayy! New best EMA pseudo Dice: 0.794
2024-02-08 01:07:01.362043: 
2024-02-08 01:07:01.363068: Epoch 52
2024-02-08 01:07:01.364259: Current learning rate: 0.00914
2024-02-08 01:07:44.456357: train_loss -0.4178
2024-02-08 01:07:44.458313: val_loss -0.3751
2024-02-08 01:07:44.458855: Pseudo dice [0.8202, 0.8027, 0.735, 0.8259, 0.8167]
2024-02-08 01:07:44.459515: Epoch time: 43.1 s
2024-02-08 01:07:44.459998: Yayy! New best EMA pseudo Dice: 0.7946
2024-02-08 01:07:45.781972: 
2024-02-08 01:07:45.783079: Epoch 53
2024-02-08 01:07:45.784291: Current learning rate: 0.00913
2024-02-08 01:08:29.025121: train_loss -0.4261
2024-02-08 01:08:29.026678: val_loss -0.3659
2024-02-08 01:08:29.027147: Pseudo dice [0.8164, 0.8105, 0.7377, 0.8295, 0.8171]
2024-02-08 01:08:29.027615: Epoch time: 43.24 s
2024-02-08 01:08:29.028044: Yayy! New best EMA pseudo Dice: 0.7954
2024-02-08 01:08:30.338164: 
2024-02-08 01:08:30.339420: Epoch 54
2024-02-08 01:08:30.340609: Current learning rate: 0.00911
2024-02-08 01:09:13.662547: train_loss -0.424
2024-02-08 01:09:13.663979: val_loss -0.3746
2024-02-08 01:09:13.664431: Pseudo dice [0.8258, 0.8028, 0.7377, 0.8261, 0.806]
2024-02-08 01:09:13.664859: Epoch time: 43.33 s
2024-02-08 01:09:13.665277: Yayy! New best EMA pseudo Dice: 0.7958
2024-02-08 01:09:14.988209: 
2024-02-08 01:09:14.989393: Epoch 55
2024-02-08 01:09:14.990306: Current learning rate: 0.0091
2024-02-08 01:09:58.077624: train_loss -0.4185
2024-02-08 01:09:58.079385: val_loss -0.3636
2024-02-08 01:09:58.079870: Pseudo dice [0.8204, 0.8009, 0.7303, 0.8138, 0.8197]
2024-02-08 01:09:58.080329: Epoch time: 43.09 s
2024-02-08 01:09:58.080837: Yayy! New best EMA pseudo Dice: 0.7959
2024-02-08 01:09:59.377814: 
2024-02-08 01:09:59.378890: Epoch 56
2024-02-08 01:09:59.380044: Current learning rate: 0.00908
2024-02-08 01:10:42.585648: train_loss -0.4267
2024-02-08 01:10:42.587049: val_loss -0.3788
2024-02-08 01:10:42.587473: Pseudo dice [0.8202, 0.8085, 0.7283, 0.8322, 0.8195]
2024-02-08 01:10:42.587916: Epoch time: 43.21 s
2024-02-08 01:10:42.588315: Yayy! New best EMA pseudo Dice: 0.7965
2024-02-08 01:10:44.013336: 
2024-02-08 01:10:44.014437: Epoch 57
2024-02-08 01:10:44.015578: Current learning rate: 0.00906
2024-02-08 01:11:27.103325: train_loss -0.4235
2024-02-08 01:11:27.104755: val_loss -0.3787
2024-02-08 01:11:27.105195: Pseudo dice [0.8248, 0.8019, 0.7383, 0.8191, 0.8216]
2024-02-08 01:11:27.105661: Epoch time: 43.09 s
2024-02-08 01:11:27.106071: Yayy! New best EMA pseudo Dice: 0.797
2024-02-08 01:11:28.405271: 
2024-02-08 01:11:28.406354: Epoch 58
2024-02-08 01:11:28.407296: Current learning rate: 0.00905
2024-02-08 01:12:11.447241: train_loss -0.432
2024-02-08 01:12:11.448621: val_loss -0.3713
2024-02-08 01:12:11.449137: Pseudo dice [0.8215, 0.8007, 0.7415, 0.8249, 0.8232]
2024-02-08 01:12:11.449565: Epoch time: 43.04 s
2024-02-08 01:12:11.449968: Yayy! New best EMA pseudo Dice: 0.7975
2024-02-08 01:12:12.778616: 
2024-02-08 01:12:12.779854: Epoch 59
2024-02-08 01:12:12.781129: Current learning rate: 0.00903
2024-02-08 01:12:55.874927: train_loss -0.4328
2024-02-08 01:12:55.876737: val_loss -0.3754
2024-02-08 01:12:55.877270: Pseudo dice [0.8218, 0.8088, 0.7363, 0.8266, 0.8167]
2024-02-08 01:12:55.877760: Epoch time: 43.1 s
2024-02-08 01:12:55.878208: Yayy! New best EMA pseudo Dice: 0.798
2024-02-08 01:12:57.251611: 
2024-02-08 01:12:57.253362: Epoch 60
2024-02-08 01:12:57.254556: Current learning rate: 0.00901
2024-02-08 01:13:40.385885: train_loss -0.4324
2024-02-08 01:13:40.387474: val_loss -0.3587
2024-02-08 01:13:40.387980: Pseudo dice [0.8227, 0.8015, 0.7265, 0.8215, 0.8164]
2024-02-08 01:13:40.388433: Epoch time: 43.14 s
2024-02-08 01:13:41.465043: 
2024-02-08 01:13:41.466953: Epoch 61
2024-02-08 01:13:41.468521: Current learning rate: 0.009
2024-02-08 01:14:24.574213: train_loss -0.437
2024-02-08 01:14:24.576047: val_loss -0.379
2024-02-08 01:14:24.576574: Pseudo dice [0.8306, 0.8112, 0.7273, 0.828, 0.8122]
2024-02-08 01:14:24.577080: Epoch time: 43.11 s
2024-02-08 01:14:24.577540: Yayy! New best EMA pseudo Dice: 0.7983
2024-02-08 01:14:26.068366: 
2024-02-08 01:14:26.069312: Epoch 62
2024-02-08 01:14:26.070427: Current learning rate: 0.00898
2024-02-08 01:15:09.260160: train_loss -0.4296
2024-02-08 01:15:09.261845: val_loss -0.3594
2024-02-08 01:15:09.262399: Pseudo dice [0.8208, 0.7968, 0.7372, 0.8182, 0.8087]
2024-02-08 01:15:09.262897: Epoch time: 43.19 s
2024-02-08 01:15:10.285696: 
2024-02-08 01:15:10.286778: Epoch 63
2024-02-08 01:15:10.287736: Current learning rate: 0.00896
2024-02-08 01:15:53.429950: train_loss -0.4347
2024-02-08 01:15:53.431442: val_loss -0.3811
2024-02-08 01:15:53.431886: Pseudo dice [0.8283, 0.8079, 0.7435, 0.8332, 0.8135]
2024-02-08 01:15:53.432331: Epoch time: 43.15 s
2024-02-08 01:15:53.432771: Yayy! New best EMA pseudo Dice: 0.7988
2024-02-08 01:15:54.721726: 
2024-02-08 01:15:54.722780: Epoch 64
2024-02-08 01:15:54.723754: Current learning rate: 0.00895
2024-02-08 01:16:38.001473: train_loss -0.4327
2024-02-08 01:16:38.002850: val_loss -0.3765
2024-02-08 01:16:38.003419: Pseudo dice [0.8221, 0.8124, 0.7319, 0.8343, 0.8158]
2024-02-08 01:16:38.003863: Epoch time: 43.28 s
2024-02-08 01:16:38.004276: Yayy! New best EMA pseudo Dice: 0.7993
2024-02-08 01:16:39.383396: 
2024-02-08 01:16:39.384531: Epoch 65
2024-02-08 01:16:39.385557: Current learning rate: 0.00893
2024-02-08 01:17:22.758777: train_loss -0.4417
2024-02-08 01:17:22.760381: val_loss -0.3775
2024-02-08 01:17:22.760875: Pseudo dice [0.825, 0.8077, 0.7341, 0.8198, 0.8096]
2024-02-08 01:17:22.761383: Epoch time: 43.38 s
2024-02-08 01:17:23.903368: 
2024-02-08 01:17:23.904356: Epoch 66
2024-02-08 01:17:23.905499: Current learning rate: 0.00891
2024-02-08 01:18:07.240757: train_loss -0.4493
2024-02-08 01:18:07.242164: val_loss -0.3842
2024-02-08 01:18:07.242722: Pseudo dice [0.8336, 0.8183, 0.7369, 0.8198, 0.8147]
2024-02-08 01:18:07.243128: Epoch time: 43.34 s
2024-02-08 01:18:07.243536: Yayy! New best EMA pseudo Dice: 0.7998
2024-02-08 01:18:08.626199: 
2024-02-08 01:18:08.627820: Epoch 67
2024-02-08 01:18:08.628911: Current learning rate: 0.0089
2024-02-08 01:18:51.913436: train_loss -0.4477
2024-02-08 01:18:51.914817: val_loss -0.3795
2024-02-08 01:18:51.915307: Pseudo dice [0.8235, 0.8066, 0.7351, 0.8175, 0.8134]
2024-02-08 01:18:51.915780: Epoch time: 43.29 s
2024-02-08 01:18:52.988746: 
2024-02-08 01:18:52.990943: Epoch 68
2024-02-08 01:18:52.992485: Current learning rate: 0.00888
2024-02-08 01:19:36.241244: train_loss -0.4426
2024-02-08 01:19:36.242695: val_loss -0.3659
2024-02-08 01:19:36.243156: Pseudo dice [0.8259, 0.811, 0.7307, 0.8253, 0.8173]
2024-02-08 01:19:36.243599: Epoch time: 43.25 s
2024-02-08 01:19:36.244008: Yayy! New best EMA pseudo Dice: 0.8
2024-02-08 01:19:37.609704: 
2024-02-08 01:19:37.611469: Epoch 69
2024-02-08 01:19:37.613084: Current learning rate: 0.00886
2024-02-08 01:20:20.960029: train_loss -0.45
2024-02-08 01:20:20.961555: val_loss -0.3862
2024-02-08 01:20:20.962026: Pseudo dice [0.8258, 0.8141, 0.7448, 0.8259, 0.8006]
2024-02-08 01:20:20.962610: Epoch time: 43.35 s
2024-02-08 01:20:20.963004: Yayy! New best EMA pseudo Dice: 0.8002
2024-02-08 01:20:22.326155: 
2024-02-08 01:20:22.327754: Epoch 70
2024-02-08 01:20:22.328290: Current learning rate: 0.00885
2024-02-08 01:21:05.802784: train_loss -0.4545
2024-02-08 01:21:05.805002: val_loss -0.3731
2024-02-08 01:21:05.805835: Pseudo dice [0.8201, 0.8104, 0.7366, 0.8157, 0.8144]
2024-02-08 01:21:05.806364: Epoch time: 43.48 s
2024-02-08 01:21:07.040887: 
2024-02-08 01:21:07.042047: Epoch 71
2024-02-08 01:21:07.043047: Current learning rate: 0.00883
2024-02-08 01:21:50.527426: train_loss -0.4589
2024-02-08 01:21:50.528963: val_loss -0.3751
2024-02-08 01:21:50.529545: Pseudo dice [0.8327, 0.8069, 0.7374, 0.8361, 0.8038]
2024-02-08 01:21:50.530020: Epoch time: 43.49 s
2024-02-08 01:21:50.530438: Yayy! New best EMA pseudo Dice: 0.8005
2024-02-08 01:21:51.907268: 
2024-02-08 01:21:51.908518: Epoch 72
2024-02-08 01:21:51.909508: Current learning rate: 0.00881
2024-02-08 01:22:34.378176: train_loss -0.4564
2024-02-08 01:22:34.379766: val_loss -0.3671
2024-02-08 01:22:34.380226: Pseudo dice [0.829, 0.805, 0.7383, 0.8237, 0.8117]
2024-02-08 01:22:34.380641: Epoch time: 42.47 s
2024-02-08 01:22:34.381021: Yayy! New best EMA pseudo Dice: 0.8006
2024-02-08 01:22:35.718420: 
2024-02-08 01:22:35.719281: Epoch 73
2024-02-08 01:22:35.720017: Current learning rate: 0.0088
2024-02-08 01:23:17.576042: train_loss -0.4517
2024-02-08 01:23:17.577397: val_loss -0.3803
2024-02-08 01:23:17.577884: Pseudo dice [0.8329, 0.8104, 0.7414, 0.8214, 0.8261]
2024-02-08 01:23:17.578337: Epoch time: 41.86 s
2024-02-08 01:23:17.578742: Yayy! New best EMA pseudo Dice: 0.8012
2024-02-08 01:23:18.891254: 
2024-02-08 01:23:18.892375: Epoch 74
2024-02-08 01:23:18.892830: Current learning rate: 0.00878
2024-02-08 01:24:01.476072: train_loss -0.4532
2024-02-08 01:24:01.477413: val_loss -0.3688
2024-02-08 01:24:01.477924: Pseudo dice [0.827, 0.8127, 0.7308, 0.8227, 0.819]
2024-02-08 01:24:01.478360: Epoch time: 42.59 s
2024-02-08 01:24:01.478787: Yayy! New best EMA pseudo Dice: 0.8013
2024-02-08 01:24:02.823466: 
2024-02-08 01:24:02.824697: Epoch 75
2024-02-08 01:24:02.825209: Current learning rate: 0.00876
2024-02-08 01:24:45.911058: train_loss -0.4607
2024-02-08 01:24:45.914461: val_loss -0.388
2024-02-08 01:24:45.914995: Pseudo dice [0.8264, 0.8127, 0.7409, 0.8346, 0.809]
2024-02-08 01:24:45.915594: Epoch time: 43.09 s
2024-02-08 01:24:45.916082: Yayy! New best EMA pseudo Dice: 0.8016
2024-02-08 01:24:47.300464: 
2024-02-08 01:24:47.301696: Epoch 76
2024-02-08 01:24:47.302871: Current learning rate: 0.00875
2024-02-08 01:25:30.698493: train_loss -0.4568
2024-02-08 01:25:30.699783: val_loss -0.3761
2024-02-08 01:25:30.700255: Pseudo dice [0.8255, 0.8185, 0.7362, 0.8285, 0.8091]
2024-02-08 01:25:30.700667: Epoch time: 43.4 s
2024-02-08 01:25:30.701067: Yayy! New best EMA pseudo Dice: 0.8018
2024-02-08 01:25:32.265602: 
2024-02-08 01:25:32.266551: Epoch 77
2024-02-08 01:25:32.267650: Current learning rate: 0.00873
2024-02-08 01:26:15.462260: train_loss -0.463
2024-02-08 01:26:15.463698: val_loss -0.3848
2024-02-08 01:26:15.464210: Pseudo dice [0.8279, 0.8135, 0.7425, 0.8281, 0.8161]
2024-02-08 01:26:15.464657: Epoch time: 43.2 s
2024-02-08 01:26:15.465066: Yayy! New best EMA pseudo Dice: 0.8022
2024-02-08 01:26:16.873181: 
2024-02-08 01:26:16.874265: Epoch 78
2024-02-08 01:26:16.875256: Current learning rate: 0.00871
2024-02-08 01:27:00.013658: train_loss -0.4611
2024-02-08 01:27:00.015346: val_loss -0.3813
2024-02-08 01:27:00.015822: Pseudo dice [0.8294, 0.8098, 0.7474, 0.8242, 0.7931]
2024-02-08 01:27:00.016293: Epoch time: 43.14 s
2024-02-08 01:27:01.110836: 
2024-02-08 01:27:01.112151: Epoch 79
2024-02-08 01:27:01.113470: Current learning rate: 0.0087
2024-02-08 01:27:44.340189: train_loss -0.4551
2024-02-08 01:27:44.341631: val_loss -0.3727
2024-02-08 01:27:44.342094: Pseudo dice [0.8269, 0.8127, 0.734, 0.8296, 0.808]
2024-02-08 01:27:44.342547: Epoch time: 43.23 s
2024-02-08 01:27:45.405639: 
2024-02-08 01:27:45.406616: Epoch 80
2024-02-08 01:27:45.407876: Current learning rate: 0.00868
2024-02-08 01:28:28.527564: train_loss -0.4592
2024-02-08 01:28:28.529402: val_loss -0.3781
2024-02-08 01:28:28.529988: Pseudo dice [0.829, 0.8116, 0.735, 0.8349, 0.8085]
2024-02-08 01:28:28.530490: Epoch time: 43.12 s
2024-02-08 01:28:28.530994: Yayy! New best EMA pseudo Dice: 0.8023
2024-02-08 01:28:30.049622: 
2024-02-08 01:28:30.051423: Epoch 81
2024-02-08 01:28:30.052234: Current learning rate: 0.00866
2024-02-08 01:29:13.391457: train_loss -0.457
2024-02-08 01:29:13.392844: val_loss -0.3882
2024-02-08 01:29:13.393336: Pseudo dice [0.8312, 0.8172, 0.7332, 0.8363, 0.8163]
2024-02-08 01:29:13.393793: Epoch time: 43.34 s
2024-02-08 01:29:13.394203: Yayy! New best EMA pseudo Dice: 0.8027
2024-02-08 01:29:14.771234: 
2024-02-08 01:29:14.772802: Epoch 82
2024-02-08 01:29:14.773305: Current learning rate: 0.00865
2024-02-08 01:29:58.236608: train_loss -0.4665
2024-02-08 01:29:58.238390: val_loss -0.3888
2024-02-08 01:29:58.238952: Pseudo dice [0.8345, 0.8129, 0.7381, 0.8366, 0.8169]
2024-02-08 01:29:58.239472: Epoch time: 43.47 s
2024-02-08 01:29:58.240005: Yayy! New best EMA pseudo Dice: 0.8032
2024-02-08 01:29:59.553074: 
2024-02-08 01:29:59.554346: Epoch 83
2024-02-08 01:29:59.555599: Current learning rate: 0.00863
2024-02-08 01:30:42.973771: train_loss -0.4701
2024-02-08 01:30:42.975135: val_loss -0.3977
2024-02-08 01:30:42.975635: Pseudo dice [0.833, 0.8178, 0.7462, 0.8294, 0.8141]
2024-02-08 01:30:42.976106: Epoch time: 43.42 s
2024-02-08 01:30:42.976546: Yayy! New best EMA pseudo Dice: 0.8037
2024-02-08 01:30:44.314229: 
2024-02-08 01:30:44.315713: Epoch 84
2024-02-08 01:30:44.316938: Current learning rate: 0.00861
2024-02-08 01:31:27.754618: train_loss -0.477
2024-02-08 01:31:27.756077: val_loss -0.3873
2024-02-08 01:31:27.756562: Pseudo dice [0.8247, 0.8193, 0.7463, 0.8301, 0.822]
2024-02-08 01:31:27.756991: Epoch time: 43.44 s
2024-02-08 01:31:27.757387: Yayy! New best EMA pseudo Dice: 0.8042
2024-02-08 01:31:29.121122: 
2024-02-08 01:31:29.122267: Epoch 85
2024-02-08 01:31:29.123230: Current learning rate: 0.0086
2024-02-08 01:32:12.468893: train_loss -0.4686
2024-02-08 01:32:12.474835: val_loss -0.3882
2024-02-08 01:32:12.480082: Pseudo dice [0.8275, 0.8171, 0.7442, 0.8313, 0.8231]
2024-02-08 01:32:12.487302: Epoch time: 43.35 s
2024-02-08 01:32:12.488107: Yayy! New best EMA pseudo Dice: 0.8046
2024-02-08 01:32:13.862572: 
2024-02-08 01:32:13.864584: Epoch 86
2024-02-08 01:32:13.865491: Current learning rate: 0.00858
2024-02-08 01:32:57.317501: train_loss -0.4772
2024-02-08 01:32:57.319549: val_loss -0.3791
2024-02-08 01:32:57.320024: Pseudo dice [0.8189, 0.8202, 0.7496, 0.8164, 0.8064]
2024-02-08 01:32:57.320513: Epoch time: 43.46 s
2024-02-08 01:32:58.654340: 
2024-02-08 01:32:58.655404: Epoch 87
2024-02-08 01:32:58.656352: Current learning rate: 0.00856
2024-02-08 01:33:42.275060: train_loss -0.4769
2024-02-08 01:33:42.276772: val_loss -0.3764
2024-02-08 01:33:42.277298: Pseudo dice [0.8253, 0.8168, 0.7421, 0.8313, 0.8128]
2024-02-08 01:33:42.278438: Epoch time: 43.62 s
2024-02-08 01:33:43.318429: 
2024-02-08 01:33:43.319745: Epoch 88
2024-02-08 01:33:43.320968: Current learning rate: 0.00855
2024-02-08 01:34:26.629696: train_loss -0.4749
2024-02-08 01:34:26.631817: val_loss -0.3763
2024-02-08 01:34:26.632577: Pseudo dice [0.826, 0.8134, 0.7489, 0.8276, 0.8043]
2024-02-08 01:34:26.633080: Epoch time: 43.31 s
2024-02-08 01:34:27.640762: 
2024-02-08 01:34:27.641911: Epoch 89
2024-02-08 01:34:27.643106: Current learning rate: 0.00853
2024-02-08 01:35:10.777480: train_loss -0.4835
2024-02-08 01:35:10.778840: val_loss -0.3762
2024-02-08 01:35:10.779368: Pseudo dice [0.8339, 0.8146, 0.7293, 0.8327, 0.8109]
2024-02-08 01:35:10.779801: Epoch time: 43.14 s
2024-02-08 01:35:11.769468: 
2024-02-08 01:35:11.770545: Epoch 90
2024-02-08 01:35:11.771801: Current learning rate: 0.00851
2024-02-08 01:35:54.833085: train_loss -0.4784
2024-02-08 01:35:54.834857: val_loss -0.3906
2024-02-08 01:35:54.835412: Pseudo dice [0.8304, 0.8236, 0.7442, 0.829, 0.8245]
2024-02-08 01:35:54.835895: Epoch time: 43.06 s
2024-02-08 01:35:54.836353: Yayy! New best EMA pseudo Dice: 0.805
2024-02-08 01:35:56.071539: 
2024-02-08 01:35:56.072643: Epoch 91
2024-02-08 01:35:56.073625: Current learning rate: 0.0085
2024-02-08 01:36:39.194020: train_loss -0.4802
2024-02-08 01:36:39.196459: val_loss -0.3692
2024-02-08 01:36:39.197205: Pseudo dice [0.8284, 0.8103, 0.7442, 0.8319, 0.8119]
2024-02-08 01:36:39.198139: Epoch time: 43.12 s
2024-02-08 01:36:39.198698: Yayy! New best EMA pseudo Dice: 0.8051
2024-02-08 01:36:40.718328: 
2024-02-08 01:36:40.719411: Epoch 92
2024-02-08 01:36:40.720458: Current learning rate: 0.00848
2024-02-08 01:37:23.900145: train_loss -0.4788
2024-02-08 01:37:23.901483: val_loss -0.3883
2024-02-08 01:37:23.902011: Pseudo dice [0.8254, 0.8139, 0.7485, 0.8378, 0.8113]
2024-02-08 01:37:23.902434: Epoch time: 43.18 s
2024-02-08 01:37:23.902874: Yayy! New best EMA pseudo Dice: 0.8053
2024-02-08 01:37:25.240586: 
2024-02-08 01:37:25.242690: Epoch 93
2024-02-08 01:37:25.244166: Current learning rate: 0.00846
2024-02-08 01:38:08.528943: train_loss -0.4828
2024-02-08 01:38:08.530957: val_loss -0.3746
2024-02-08 01:38:08.531518: Pseudo dice [0.8319, 0.8135, 0.7376, 0.8328, 0.801]
2024-02-08 01:38:08.531960: Epoch time: 43.29 s
2024-02-08 01:38:09.581202: 
2024-02-08 01:38:09.583171: Epoch 94
2024-02-08 01:38:09.584471: Current learning rate: 0.00845
2024-02-08 01:38:52.573803: train_loss -0.4761
2024-02-08 01:38:52.575254: val_loss -0.3819
2024-02-08 01:38:52.575740: Pseudo dice [0.825, 0.8041, 0.7438, 0.8263, 0.8083]
2024-02-08 01:38:52.576186: Epoch time: 42.99 s
2024-02-08 01:38:53.589042: 
2024-02-08 01:38:53.590034: Epoch 95
2024-02-08 01:38:53.591118: Current learning rate: 0.00843
2024-02-08 01:39:36.458183: train_loss -0.4787
2024-02-08 01:39:36.459472: val_loss -0.3915
2024-02-08 01:39:36.459894: Pseudo dice [0.8305, 0.82, 0.7427, 0.8334, 0.812]
2024-02-08 01:39:36.460344: Epoch time: 42.87 s
2024-02-08 01:39:37.515255: 
2024-02-08 01:39:37.516248: Epoch 96
2024-02-08 01:39:37.517211: Current learning rate: 0.00841
2024-02-08 01:40:19.594906: train_loss -0.4861
2024-02-08 01:40:19.596316: val_loss -0.3808
2024-02-08 01:40:19.596814: Pseudo dice [0.8283, 0.8129, 0.7396, 0.8331, 0.8116]
2024-02-08 01:40:19.597446: Epoch time: 42.08 s
2024-02-08 01:40:20.629219: 
2024-02-08 01:40:20.630208: Epoch 97
2024-02-08 01:40:20.631398: Current learning rate: 0.0084
2024-02-08 01:41:02.641504: train_loss -0.4872
2024-02-08 01:41:02.643497: val_loss -0.3766
2024-02-08 01:41:02.643968: Pseudo dice [0.828, 0.8175, 0.7327, 0.8275, 0.7987]
2024-02-08 01:41:02.644390: Epoch time: 42.01 s
2024-02-08 01:41:03.813451: 
2024-02-08 01:41:03.815932: Epoch 98
2024-02-08 01:41:03.817429: Current learning rate: 0.00838
2024-02-08 01:41:46.426330: train_loss -0.4839
2024-02-08 01:41:46.428660: val_loss -0.4006
2024-02-08 01:41:46.429144: Pseudo dice [0.8383, 0.8195, 0.7414, 0.8378, 0.819]
2024-02-08 01:41:46.429594: Epoch time: 42.61 s
2024-02-08 01:41:47.485628: 
2024-02-08 01:41:47.486836: Epoch 99
2024-02-08 01:41:47.487753: Current learning rate: 0.00836
2024-02-08 01:42:29.497236: train_loss -0.4889
2024-02-08 01:42:29.498745: val_loss -0.3899
2024-02-08 01:42:29.499243: Pseudo dice [0.8301, 0.8191, 0.7459, 0.8282, 0.8062]
2024-02-08 01:42:29.499751: Epoch time: 42.01 s
2024-02-08 01:42:29.731121: Yayy! New best EMA pseudo Dice: 0.8054
2024-02-08 01:42:31.000906: 
2024-02-08 01:42:31.001904: Epoch 100
2024-02-08 01:42:31.003692: Current learning rate: 0.00835
2024-02-08 01:43:12.945524: train_loss -0.4859
2024-02-08 01:43:12.946864: val_loss -0.3821
2024-02-08 01:43:12.947372: Pseudo dice [0.8293, 0.8182, 0.7425, 0.8341, 0.7995]
2024-02-08 01:43:12.947842: Epoch time: 41.95 s
2024-02-08 01:43:13.959483: 
2024-02-08 01:43:13.960470: Epoch 101
2024-02-08 01:43:13.961349: Current learning rate: 0.00833
2024-02-08 01:43:55.891150: train_loss -0.4976
2024-02-08 01:43:55.892572: val_loss -0.3943
2024-02-08 01:43:55.893064: Pseudo dice [0.8324, 0.8204, 0.7469, 0.8351, 0.806]
2024-02-08 01:43:55.893504: Epoch time: 41.93 s
2024-02-08 01:43:55.893998: Yayy! New best EMA pseudo Dice: 0.8056
2024-02-08 01:43:57.182083: 
2024-02-08 01:43:57.182975: Epoch 102
2024-02-08 01:43:57.183770: Current learning rate: 0.00831
2024-02-08 01:44:39.290198: train_loss -0.4944
2024-02-08 01:44:39.291898: val_loss -0.3845
2024-02-08 01:44:39.292410: Pseudo dice [0.8331, 0.8173, 0.7404, 0.831, 0.8086]
2024-02-08 01:44:39.292904: Epoch time: 42.11 s
2024-02-08 01:44:39.293503: Yayy! New best EMA pseudo Dice: 0.8056
2024-02-08 01:44:40.798603: 
2024-02-08 01:44:40.799561: Epoch 103
2024-02-08 01:44:40.800375: Current learning rate: 0.0083
2024-02-08 01:45:22.843604: train_loss -0.4915
2024-02-08 01:45:22.845171: val_loss -0.3746
2024-02-08 01:45:22.845702: Pseudo dice [0.8297, 0.8165, 0.7383, 0.8301, 0.8055]
2024-02-08 01:45:22.846277: Epoch time: 42.05 s
2024-02-08 01:45:23.859784: 
2024-02-08 01:45:23.860857: Epoch 104
2024-02-08 01:45:23.861891: Current learning rate: 0.00828
2024-02-08 01:46:06.401551: train_loss -0.4971
2024-02-08 01:46:06.402916: val_loss -0.3927
2024-02-08 01:46:06.403387: Pseudo dice [0.8339, 0.8198, 0.7485, 0.8363, 0.8082]
2024-02-08 01:46:06.403820: Epoch time: 42.54 s
2024-02-08 01:46:06.404212: Yayy! New best EMA pseudo Dice: 0.8059
2024-02-08 01:46:07.721733: 
2024-02-08 01:46:07.722977: Epoch 105
2024-02-08 01:46:07.724825: Current learning rate: 0.00826
2024-02-08 01:46:50.642571: train_loss -0.4989
2024-02-08 01:46:50.643992: val_loss -0.3923
2024-02-08 01:46:50.644496: Pseudo dice [0.8318, 0.819, 0.7335, 0.8256, 0.8062]
2024-02-08 01:46:50.645023: Epoch time: 42.92 s
2024-02-08 01:46:51.671272: 
2024-02-08 01:46:51.672892: Epoch 106
2024-02-08 01:46:51.673567: Current learning rate: 0.00825
2024-02-08 01:47:34.750269: train_loss -0.4988
2024-02-08 01:47:34.752856: val_loss -0.3892
2024-02-08 01:47:34.753484: Pseudo dice [0.8318, 0.8086, 0.7439, 0.8344, 0.8241]
2024-02-08 01:47:34.754039: Epoch time: 43.08 s
2024-02-08 01:47:34.754617: Yayy! New best EMA pseudo Dice: 0.8059
2024-02-08 01:47:36.090494: 
2024-02-08 01:47:36.091617: Epoch 107
2024-02-08 01:47:36.092876: Current learning rate: 0.00823
2024-02-08 01:48:19.416940: train_loss -0.4958
2024-02-08 01:48:19.418376: val_loss -0.3906
2024-02-08 01:48:19.420167: Pseudo dice [0.8232, 0.8158, 0.7456, 0.8344, 0.8198]
2024-02-08 01:48:19.420851: Epoch time: 43.33 s
2024-02-08 01:48:19.421274: Yayy! New best EMA pseudo Dice: 0.8061
2024-02-08 01:48:20.902335: 
2024-02-08 01:48:20.903503: Epoch 108
2024-02-08 01:48:20.904444: Current learning rate: 0.00821
2024-02-08 01:49:04.022856: train_loss -0.4947
2024-02-08 01:49:04.024353: val_loss -0.3915
2024-02-08 01:49:04.024815: Pseudo dice [0.8301, 0.818, 0.7476, 0.8304, 0.8069]
2024-02-08 01:49:04.025252: Epoch time: 43.12 s
2024-02-08 01:49:04.025654: Yayy! New best EMA pseudo Dice: 0.8061
2024-02-08 01:49:05.346601: 
2024-02-08 01:49:05.347615: Epoch 109
2024-02-08 01:49:05.348439: Current learning rate: 0.0082
2024-02-08 01:49:48.454628: train_loss -0.5044
2024-02-08 01:49:48.456176: val_loss -0.3851
2024-02-08 01:49:48.456842: Pseudo dice [0.8284, 0.8166, 0.7422, 0.8341, 0.8203]
2024-02-08 01:49:48.457279: Epoch time: 43.11 s
2024-02-08 01:49:48.457718: Yayy! New best EMA pseudo Dice: 0.8063
2024-02-08 01:49:49.831860: 
2024-02-08 01:49:49.833382: Epoch 110
2024-02-08 01:49:49.833951: Current learning rate: 0.00818
2024-02-08 01:50:32.865630: train_loss -0.5009
2024-02-08 01:50:33.007193: val_loss -0.3867
2024-02-08 01:50:33.007700: Pseudo dice [0.8325, 0.8094, 0.7436, 0.8307, 0.8249]
2024-02-08 01:50:33.008179: Epoch time: 43.04 s
2024-02-08 01:50:33.009427: Yayy! New best EMA pseudo Dice: 0.8065
2024-02-08 01:50:34.514619: 
2024-02-08 01:50:34.515888: Epoch 111
2024-02-08 01:50:34.517372: Current learning rate: 0.00816
2024-02-08 01:51:17.827990: train_loss -0.5056
2024-02-08 01:51:17.829504: val_loss -0.3715
2024-02-08 01:51:17.830047: Pseudo dice [0.8298, 0.8171, 0.7387, 0.8325, 0.8027]
2024-02-08 01:51:17.830543: Epoch time: 43.31 s
2024-02-08 01:51:18.879735: 
2024-02-08 01:51:18.880849: Epoch 112
2024-02-08 01:51:18.881965: Current learning rate: 0.00815
2024-02-08 01:52:01.879930: train_loss -0.503
2024-02-08 01:52:01.881824: val_loss -0.3756
2024-02-08 01:52:01.882336: Pseudo dice [0.8314, 0.8149, 0.7466, 0.831, 0.8079]
2024-02-08 01:52:01.882799: Epoch time: 43.0 s
2024-02-08 01:52:02.902226: 
2024-02-08 01:52:02.903373: Epoch 113
2024-02-08 01:52:02.904554: Current learning rate: 0.00813
2024-02-08 01:52:45.932717: train_loss -0.5021
2024-02-08 01:52:45.934528: val_loss -0.396
2024-02-08 01:52:45.935058: Pseudo dice [0.8332, 0.8157, 0.7422, 0.8344, 0.8041]
2024-02-08 01:52:45.935508: Epoch time: 43.03 s
2024-02-08 01:52:47.282084: 
2024-02-08 01:52:47.283203: Epoch 114
2024-02-08 01:52:47.284175: Current learning rate: 0.00811
2024-02-08 01:53:30.562860: train_loss -0.4946
2024-02-08 01:53:30.564490: val_loss -0.3847
2024-02-08 01:53:30.565017: Pseudo dice [0.8269, 0.8126, 0.7476, 0.8306, 0.8108]
2024-02-08 01:53:30.565430: Epoch time: 43.28 s
2024-02-08 01:53:31.591676: 
2024-02-08 01:53:31.593052: Epoch 115
2024-02-08 01:53:31.594162: Current learning rate: 0.0081
2024-02-08 01:54:14.470418: train_loss -0.5058
2024-02-08 01:54:14.471767: val_loss -0.3902
2024-02-08 01:54:14.472260: Pseudo dice [0.8321, 0.8166, 0.7385, 0.8303, 0.8232]
2024-02-08 01:54:14.472716: Epoch time: 42.88 s
2024-02-08 01:54:15.517681: 
2024-02-08 01:54:15.518861: Epoch 116
2024-02-08 01:54:15.520067: Current learning rate: 0.00808
2024-02-08 01:54:58.591607: train_loss -0.4995
2024-02-08 01:54:58.686615: val_loss -0.3722
2024-02-08 01:54:58.782696: Pseudo dice [0.8258, 0.8119, 0.7389, 0.822, 0.8136]
2024-02-08 01:54:58.783425: Epoch time: 43.07 s
2024-02-08 01:54:59.844806: 
2024-02-08 01:54:59.846034: Epoch 117
2024-02-08 01:54:59.847139: Current learning rate: 0.00806
2024-02-08 01:55:43.148523: train_loss -0.5079
2024-02-08 01:55:43.150079: val_loss -0.3928
2024-02-08 01:55:43.150554: Pseudo dice [0.8307, 0.8245, 0.7452, 0.8411, 0.8176]
2024-02-08 01:55:43.150973: Epoch time: 43.31 s
2024-02-08 01:55:43.151395: Yayy! New best EMA pseudo Dice: 0.8066
2024-02-08 01:55:44.532301: 
2024-02-08 01:55:44.533306: Epoch 118
2024-02-08 01:55:44.534370: Current learning rate: 0.00805
2024-02-08 01:56:27.799349: train_loss -0.5057
2024-02-08 01:56:27.800970: val_loss -0.3733
2024-02-08 01:56:27.801463: Pseudo dice [0.8292, 0.8123, 0.7408, 0.8263, 0.8069]
2024-02-08 01:56:27.801932: Epoch time: 43.27 s
2024-02-08 01:56:29.233303: 
2024-02-08 01:56:29.234329: Epoch 119
2024-02-08 01:56:29.235322: Current learning rate: 0.00803
2024-02-08 01:57:12.503962: train_loss -0.5083
2024-02-08 01:57:12.505409: val_loss -0.3845
2024-02-08 01:57:12.505923: Pseudo dice [0.8286, 0.8188, 0.746, 0.8386, 0.7988]
2024-02-08 01:57:12.506402: Epoch time: 43.27 s
2024-02-08 01:57:13.558952: 
2024-02-08 01:57:13.560076: Epoch 120
2024-02-08 01:57:13.561107: Current learning rate: 0.00801
2024-02-08 01:57:56.799349: train_loss -0.5067
2024-02-08 01:57:56.800810: val_loss -0.3833
2024-02-08 01:57:56.801353: Pseudo dice [0.8324, 0.819, 0.7372, 0.8278, 0.8171]
2024-02-08 01:57:56.801805: Epoch time: 43.24 s
2024-02-08 01:57:57.841937: 
2024-02-08 01:57:57.842957: Epoch 121
2024-02-08 01:57:57.843967: Current learning rate: 0.008
2024-02-08 01:58:40.844147: train_loss -0.5132
2024-02-08 01:58:40.845653: val_loss -0.3757
2024-02-08 01:58:40.846208: Pseudo dice [0.8278, 0.8116, 0.7413, 0.8319, 0.8141]
2024-02-08 01:58:40.846643: Epoch time: 43.0 s
2024-02-08 01:58:41.927036: 
2024-02-08 01:58:41.928135: Epoch 122
2024-02-08 01:58:41.929289: Current learning rate: 0.00798
2024-02-08 01:59:25.057875: train_loss -0.5069
2024-02-08 01:59:25.059360: val_loss -0.3774
2024-02-08 01:59:25.059847: Pseudo dice [0.8303, 0.8112, 0.7433, 0.8224, 0.8092]
2024-02-08 01:59:25.060328: Epoch time: 43.13 s
2024-02-08 01:59:26.154118: 
2024-02-08 01:59:26.155303: Epoch 123
2024-02-08 01:59:26.156515: Current learning rate: 0.00796
2024-02-08 02:00:09.371211: train_loss -0.5182
2024-02-08 02:00:09.372886: val_loss -0.3969
2024-02-08 02:00:09.373497: Pseudo dice [0.8327, 0.8236, 0.7462, 0.8308, 0.808]
2024-02-08 02:00:09.374052: Epoch time: 43.22 s
2024-02-08 02:00:10.443098: 
2024-02-08 02:00:10.444263: Epoch 124
2024-02-08 02:00:10.445182: Current learning rate: 0.00795
2024-02-08 02:00:53.667084: train_loss -0.514
2024-02-08 02:00:53.669101: val_loss -0.3925
2024-02-08 02:00:53.669590: Pseudo dice [0.8337, 0.8193, 0.7369, 0.8413, 0.8128]
2024-02-08 02:00:53.670095: Epoch time: 43.23 s
2024-02-08 02:00:54.871284: 
2024-02-08 02:00:54.872575: Epoch 125
2024-02-08 02:00:54.874444: Current learning rate: 0.00793
2024-02-08 02:01:38.286507: train_loss -0.5106
2024-02-08 02:01:38.288450: val_loss -0.3969
2024-02-08 02:01:38.288952: Pseudo dice [0.834, 0.817, 0.7484, 0.8423, 0.8153]
2024-02-08 02:01:38.289503: Epoch time: 43.42 s
2024-02-08 02:01:38.289969: Yayy! New best EMA pseudo Dice: 0.8069
2024-02-08 02:01:39.618673: 
2024-02-08 02:01:39.619867: Epoch 126
2024-02-08 02:01:39.621408: Current learning rate: 0.00791
2024-02-08 02:02:22.931743: train_loss -0.5187
2024-02-08 02:02:22.933040: val_loss -0.41
2024-02-08 02:02:22.933617: Pseudo dice [0.8345, 0.8186, 0.7525, 0.8441, 0.8194]
2024-02-08 02:02:22.934047: Epoch time: 43.31 s
2024-02-08 02:02:22.934458: Yayy! New best EMA pseudo Dice: 0.8076
2024-02-08 02:02:24.321121: 
2024-02-08 02:02:24.322521: Epoch 127
2024-02-08 02:02:24.323933: Current learning rate: 0.0079
2024-02-08 02:03:07.469697: train_loss -0.5209
2024-02-08 02:03:07.471414: val_loss -0.385
2024-02-08 02:03:07.471928: Pseudo dice [0.8338, 0.8164, 0.7465, 0.8344, 0.8137]
2024-02-08 02:03:07.472368: Epoch time: 43.15 s
2024-02-08 02:03:07.472785: Yayy! New best EMA pseudo Dice: 0.8077
2024-02-08 02:03:08.809911: 
2024-02-08 02:03:08.811499: Epoch 128
2024-02-08 02:03:08.812599: Current learning rate: 0.00788
2024-02-08 02:03:51.972839: train_loss -0.5101
2024-02-08 02:03:51.974233: val_loss -0.3825
2024-02-08 02:03:51.974916: Pseudo dice [0.8314, 0.822, 0.7453, 0.8333, 0.8118]
2024-02-08 02:03:51.975381: Epoch time: 43.16 s
2024-02-08 02:03:51.975797: Yayy! New best EMA pseudo Dice: 0.8078
2024-02-08 02:03:53.342376: 
2024-02-08 02:03:53.343506: Epoch 129
2024-02-08 02:03:53.344377: Current learning rate: 0.00786
2024-02-08 02:04:36.521898: train_loss -0.5183
2024-02-08 02:04:36.523627: val_loss -0.3804
2024-02-08 02:04:36.524156: Pseudo dice [0.8312, 0.819, 0.7353, 0.8346, 0.8085]
2024-02-08 02:04:36.524612: Epoch time: 43.18 s
2024-02-08 02:04:37.703712: 
2024-02-08 02:04:37.704951: Epoch 130
2024-02-08 02:04:37.705996: Current learning rate: 0.00785
2024-02-08 02:05:20.715668: train_loss -0.5163
2024-02-08 02:05:20.717284: val_loss -0.4017
2024-02-08 02:05:20.717826: Pseudo dice [0.8379, 0.8223, 0.75, 0.8439, 0.808]
2024-02-08 02:05:20.718321: Epoch time: 43.01 s
2024-02-08 02:05:20.718755: Yayy! New best EMA pseudo Dice: 0.8081
2024-02-08 02:05:22.074619: 
2024-02-08 02:05:22.075771: Epoch 131
2024-02-08 02:05:22.076696: Current learning rate: 0.00783
2024-02-08 02:06:05.116624: train_loss -0.5132
2024-02-08 02:06:05.118625: val_loss -0.3826
2024-02-08 02:06:05.119147: Pseudo dice [0.8309, 0.8157, 0.7367, 0.8313, 0.8127]
2024-02-08 02:06:05.119652: Epoch time: 43.04 s
2024-02-08 02:06:06.152221: 
2024-02-08 02:06:06.153675: Epoch 132
2024-02-08 02:06:06.154276: Current learning rate: 0.00781
2024-02-08 02:06:49.117739: train_loss -0.5179
2024-02-08 02:06:49.119384: val_loss -0.3894
2024-02-08 02:06:49.119870: Pseudo dice [0.8373, 0.8123, 0.739, 0.8366, 0.8151]
2024-02-08 02:06:49.120311: Epoch time: 42.97 s
2024-02-08 02:06:50.158476: 
2024-02-08 02:06:50.159554: Epoch 133
2024-02-08 02:06:50.160674: Current learning rate: 0.00779
2024-02-08 02:07:33.093256: train_loss -0.5211
2024-02-08 02:07:33.094628: val_loss -0.3883
2024-02-08 02:07:33.095109: Pseudo dice [0.836, 0.8152, 0.7402, 0.8334, 0.809]
2024-02-08 02:07:33.096035: Epoch time: 42.94 s
2024-02-08 02:07:34.136027: 
2024-02-08 02:07:34.137168: Epoch 134
2024-02-08 02:07:34.138025: Current learning rate: 0.00778
2024-02-08 02:08:17.281058: train_loss -0.5211
2024-02-08 02:08:17.282380: val_loss -0.3991
2024-02-08 02:08:17.282831: Pseudo dice [0.8329, 0.8144, 0.7399, 0.8314, 0.8223]
2024-02-08 02:08:17.283255: Epoch time: 43.15 s
2024-02-08 02:08:18.349195: 
2024-02-08 02:08:18.350739: Epoch 135
2024-02-08 02:08:18.351891: Current learning rate: 0.00776
2024-02-08 02:09:01.477695: train_loss -0.5162
2024-02-08 02:09:01.479426: val_loss -0.3864
2024-02-08 02:09:01.480021: Pseudo dice [0.833, 0.8146, 0.7443, 0.8266, 0.8149]
2024-02-08 02:09:01.480495: Epoch time: 43.13 s
2024-02-08 02:09:02.663030: 
2024-02-08 02:09:02.664121: Epoch 136
2024-02-08 02:09:02.665102: Current learning rate: 0.00774
2024-02-08 02:09:45.892749: train_loss -0.5244
2024-02-08 02:09:45.894227: val_loss -0.3876
2024-02-08 02:09:45.894741: Pseudo dice [0.8348, 0.8226, 0.7386, 0.8362, 0.8153]
2024-02-08 02:09:45.895253: Epoch time: 43.23 s
2024-02-08 02:09:46.952173: 
2024-02-08 02:09:46.953402: Epoch 137
2024-02-08 02:09:46.954886: Current learning rate: 0.00773
2024-02-08 02:10:30.285842: train_loss -0.5222
2024-02-08 02:10:30.287245: val_loss -0.3803
2024-02-08 02:10:30.287724: Pseudo dice [0.8319, 0.8134, 0.7452, 0.8296, 0.8182]
2024-02-08 02:10:30.288168: Epoch time: 43.34 s
2024-02-08 02:10:31.345631: 
2024-02-08 02:10:31.346958: Epoch 138
2024-02-08 02:10:31.348386: Current learning rate: 0.00771
2024-02-08 02:11:14.527126: train_loss -0.5278
2024-02-08 02:11:14.528506: val_loss -0.3967
2024-02-08 02:11:14.528994: Pseudo dice [0.8321, 0.8199, 0.754, 0.8448, 0.8092]
2024-02-08 02:11:14.529450: Epoch time: 43.18 s
2024-02-08 02:11:14.529925: Yayy! New best EMA pseudo Dice: 0.8083
2024-02-08 02:11:15.860267: 
2024-02-08 02:11:15.861339: Epoch 139
2024-02-08 02:11:15.862297: Current learning rate: 0.00769
2024-02-08 02:11:59.087483: train_loss -0.5324
2024-02-08 02:11:59.089786: val_loss -0.3998
2024-02-08 02:11:59.090305: Pseudo dice [0.835, 0.8222, 0.7519, 0.8375, 0.8115]
2024-02-08 02:11:59.090775: Epoch time: 43.23 s
2024-02-08 02:11:59.091195: Yayy! New best EMA pseudo Dice: 0.8086
2024-02-08 02:12:00.460583: 
2024-02-08 02:12:00.461628: Epoch 140
2024-02-08 02:12:00.462545: Current learning rate: 0.00768
2024-02-08 02:12:43.828119: train_loss -0.5301
2024-02-08 02:12:43.830186: val_loss -0.3763
2024-02-08 02:12:43.830753: Pseudo dice [0.8296, 0.8224, 0.7493, 0.8231, 0.8021]
2024-02-08 02:12:43.831310: Epoch time: 43.37 s
2024-02-08 02:12:45.011105: 
2024-02-08 02:12:45.012256: Epoch 141
2024-02-08 02:12:45.013541: Current learning rate: 0.00766
2024-02-08 02:13:28.141529: train_loss -0.5191
2024-02-08 02:13:28.143169: val_loss -0.4011
2024-02-08 02:13:28.143641: Pseudo dice [0.8386, 0.8194, 0.7446, 0.8438, 0.8192]
2024-02-08 02:13:28.144080: Epoch time: 43.13 s
2024-02-08 02:13:28.144515: Yayy! New best EMA pseudo Dice: 0.8087
2024-02-08 02:13:29.556552: 
2024-02-08 02:13:29.557882: Epoch 142
2024-02-08 02:13:29.558934: Current learning rate: 0.00764
2024-02-08 02:14:12.640095: train_loss -0.5207
2024-02-08 02:14:12.641796: val_loss -0.3893
2024-02-08 02:14:12.642288: Pseudo dice [0.833, 0.8212, 0.7429, 0.8323, 0.8082]
2024-02-08 02:14:12.642789: Epoch time: 43.09 s
2024-02-08 02:14:13.682375: 
2024-02-08 02:14:13.683413: Epoch 143
2024-02-08 02:14:13.684402: Current learning rate: 0.00763
2024-02-08 02:14:56.788737: train_loss -0.5292
2024-02-08 02:14:56.790250: val_loss -0.386
2024-02-08 02:14:56.790776: Pseudo dice [0.8326, 0.8168, 0.7435, 0.8298, 0.812]
2024-02-08 02:14:56.791219: Epoch time: 43.11 s
2024-02-08 02:14:57.826277: 
2024-02-08 02:14:57.827407: Epoch 144
2024-02-08 02:14:57.828531: Current learning rate: 0.00761
2024-02-08 02:15:40.869529: train_loss -0.5209
2024-02-08 02:15:40.871109: val_loss -0.3853
2024-02-08 02:15:40.871758: Pseudo dice [0.8306, 0.8183, 0.74, 0.8347, 0.806]
2024-02-08 02:15:40.872346: Epoch time: 43.04 s
2024-02-08 02:15:42.064673: 
2024-02-08 02:15:42.065694: Epoch 145
2024-02-08 02:15:42.066783: Current learning rate: 0.00759
2024-02-08 02:16:25.025262: train_loss -0.531
2024-02-08 02:16:25.027066: val_loss -0.3764
2024-02-08 02:16:25.027790: Pseudo dice [0.8344, 0.8181, 0.7412, 0.8359, 0.793]
2024-02-08 02:16:25.028300: Epoch time: 42.96 s
2024-02-08 02:16:26.198229: 
2024-02-08 02:16:26.199299: Epoch 146
2024-02-08 02:16:26.200856: Current learning rate: 0.00758
2024-02-08 02:17:09.363582: train_loss -0.5266
2024-02-08 02:17:09.365016: val_loss -0.3978
2024-02-08 02:17:09.365493: Pseudo dice [0.834, 0.8203, 0.7559, 0.8268, 0.824]
2024-02-08 02:17:09.365955: Epoch time: 43.17 s
2024-02-08 02:17:10.425347: 
2024-02-08 02:17:10.426385: Epoch 147
2024-02-08 02:17:10.427586: Current learning rate: 0.00756
2024-02-08 02:17:53.614181: train_loss -0.5216
2024-02-08 02:17:53.615880: val_loss -0.3857
2024-02-08 02:17:53.616370: Pseudo dice [0.8375, 0.8133, 0.7501, 0.8403, 0.7973]
2024-02-08 02:17:53.616859: Epoch time: 43.19 s
2024-02-08 02:17:54.650810: 
2024-02-08 02:17:54.651839: Epoch 148
2024-02-08 02:17:54.652850: Current learning rate: 0.00754
2024-02-08 02:18:37.924492: train_loss -0.5255
2024-02-08 02:18:37.925941: val_loss -0.4015
2024-02-08 02:18:37.926462: Pseudo dice [0.8361, 0.8239, 0.7524, 0.8503, 0.8181]
2024-02-08 02:18:37.926961: Epoch time: 43.27 s
2024-02-08 02:18:37.927402: Yayy! New best EMA pseudo Dice: 0.809
2024-02-08 02:18:39.283217: 
2024-02-08 02:18:39.284318: Epoch 149
2024-02-08 02:18:39.285202: Current learning rate: 0.00752
2024-02-08 02:19:22.821300: train_loss -0.5327
2024-02-08 02:19:22.822786: val_loss -0.3899
2024-02-08 02:19:22.823302: Pseudo dice [0.8379, 0.8161, 0.7477, 0.8364, 0.8254]
2024-02-08 02:19:22.823784: Epoch time: 43.54 s
2024-02-08 02:19:23.101489: Yayy! New best EMA pseudo Dice: 0.8094
2024-02-08 02:19:24.444307: 
2024-02-08 02:19:24.445300: Epoch 150
2024-02-08 02:19:24.446542: Current learning rate: 0.00751
2024-02-08 02:20:07.816599: train_loss -0.5336
2024-02-08 02:20:07.818368: val_loss -0.3847
2024-02-08 02:20:07.818910: Pseudo dice [0.8366, 0.8183, 0.7401, 0.8351, 0.8179]
2024-02-08 02:20:07.819365: Epoch time: 43.37 s
2024-02-08 02:20:07.819808: Yayy! New best EMA pseudo Dice: 0.8094
2024-02-08 02:20:09.200141: 
2024-02-08 02:20:09.201491: Epoch 151
2024-02-08 02:20:09.203114: Current learning rate: 0.00749
2024-02-08 02:20:52.410855: train_loss -0.5332
2024-02-08 02:20:52.412401: val_loss -0.3948
2024-02-08 02:20:52.413011: Pseudo dice [0.8322, 0.8171, 0.7443, 0.8346, 0.8182]
2024-02-08 02:20:52.413464: Epoch time: 43.21 s
2024-02-08 02:20:53.642740: 
2024-02-08 02:20:53.643888: Epoch 152
2024-02-08 02:20:53.644957: Current learning rate: 0.00747
2024-02-08 02:21:37.053123: train_loss -0.5299
2024-02-08 02:21:37.055182: val_loss -0.3959
2024-02-08 02:21:37.055714: Pseudo dice [0.8361, 0.8221, 0.748, 0.8341, 0.8091]
2024-02-08 02:21:37.056201: Epoch time: 43.41 s
2024-02-08 02:21:37.056604: Yayy! New best EMA pseudo Dice: 0.8094
2024-02-08 02:21:38.433797: 
2024-02-08 02:21:38.435157: Epoch 153
2024-02-08 02:21:38.436546: Current learning rate: 0.00746
2024-02-08 02:22:21.715760: train_loss -0.5295
2024-02-08 02:22:21.717362: val_loss -0.3869
2024-02-08 02:22:21.717847: Pseudo dice [0.8356, 0.8168, 0.7445, 0.8317, 0.8146]
2024-02-08 02:22:21.718341: Epoch time: 43.28 s
2024-02-08 02:22:22.934520: 
2024-02-08 02:22:22.935526: Epoch 154
2024-02-08 02:22:22.936597: Current learning rate: 0.00744
2024-02-08 02:23:06.179310: train_loss -0.5318
2024-02-08 02:23:06.181423: val_loss -0.3908
2024-02-08 02:23:06.181950: Pseudo dice [0.83, 0.8193, 0.7523, 0.832, 0.8112]
2024-02-08 02:23:06.182465: Epoch time: 43.25 s
2024-02-08 02:23:07.252898: 
2024-02-08 02:23:07.254045: Epoch 155
2024-02-08 02:23:07.255184: Current learning rate: 0.00742
2024-02-08 02:23:50.553858: train_loss -0.5352
2024-02-08 02:23:50.555280: val_loss -0.4073
2024-02-08 02:23:50.555767: Pseudo dice [0.8326, 0.8317, 0.7584, 0.836, 0.8243]
2024-02-08 02:23:50.556328: Epoch time: 43.3 s
2024-02-08 02:23:50.556761: Yayy! New best EMA pseudo Dice: 0.81
2024-02-08 02:23:51.891001: 
2024-02-08 02:23:51.892208: Epoch 156
2024-02-08 02:23:51.893263: Current learning rate: 0.00741
2024-02-08 02:24:35.203520: train_loss -0.5259
2024-02-08 02:24:35.205671: val_loss -0.3921
2024-02-08 02:24:35.206205: Pseudo dice [0.8371, 0.8203, 0.7382, 0.8381, 0.81]
2024-02-08 02:24:35.206705: Epoch time: 43.31 s
2024-02-08 02:24:36.291971: 
2024-02-08 02:24:36.293239: Epoch 157
2024-02-08 02:24:36.294668: Current learning rate: 0.00739
2024-02-08 02:25:19.491168: train_loss -0.5324
2024-02-08 02:25:19.492789: val_loss -0.3909
2024-02-08 02:25:19.493294: Pseudo dice [0.8313, 0.8248, 0.7467, 0.8402, 0.814]
2024-02-08 02:25:19.493941: Epoch time: 43.2 s
2024-02-08 02:25:19.494371: Yayy! New best EMA pseudo Dice: 0.8101
2024-02-08 02:25:20.870891: 
2024-02-08 02:25:20.872123: Epoch 158
2024-02-08 02:25:20.873069: Current learning rate: 0.00737
2024-02-08 02:26:04.160716: train_loss -0.54
2024-02-08 02:26:04.162428: val_loss -0.3944
2024-02-08 02:26:04.162996: Pseudo dice [0.833, 0.8214, 0.748, 0.8335, 0.8281]
2024-02-08 02:26:04.163477: Epoch time: 43.29 s
2024-02-08 02:26:04.163893: Yayy! New best EMA pseudo Dice: 0.8103
2024-02-08 02:26:05.550686: 
2024-02-08 02:26:05.552418: Epoch 159
2024-02-08 02:26:05.554000: Current learning rate: 0.00736
2024-02-08 02:26:48.785206: train_loss -0.5372
2024-02-08 02:26:48.786696: val_loss -0.3712
2024-02-08 02:26:48.787195: Pseudo dice [0.8273, 0.8169, 0.7359, 0.8228, 0.8094]
2024-02-08 02:26:48.787649: Epoch time: 43.24 s
2024-02-08 02:26:49.863807: 
2024-02-08 02:26:49.865348: Epoch 160
2024-02-08 02:26:49.866359: Current learning rate: 0.00734
2024-02-08 02:27:33.181744: train_loss -0.5356
2024-02-08 02:27:33.183938: val_loss -0.3599
2024-02-08 02:27:33.184658: Pseudo dice [0.8295, 0.8102, 0.7288, 0.829, 0.8161]
2024-02-08 02:27:33.185209: Epoch time: 43.32 s
2024-02-08 02:27:34.312470: 
2024-02-08 02:27:34.313538: Epoch 161
2024-02-08 02:27:34.315188: Current learning rate: 0.00732
2024-02-08 02:28:17.780081: train_loss -0.5329
2024-02-08 02:28:17.781417: val_loss -0.3735
2024-02-08 02:28:17.781911: Pseudo dice [0.8327, 0.8178, 0.7434, 0.8386, 0.8033]
2024-02-08 02:28:17.782376: Epoch time: 43.47 s
2024-02-08 02:28:18.849123: 
2024-02-08 02:28:18.850412: Epoch 162
2024-02-08 02:28:18.851895: Current learning rate: 0.00731
2024-02-08 02:29:02.187775: train_loss -0.5419
2024-02-08 02:29:02.189051: val_loss -0.3833
2024-02-08 02:29:02.189512: Pseudo dice [0.8353, 0.8167, 0.7459, 0.8381, 0.8084]
2024-02-08 02:29:02.189978: Epoch time: 43.34 s
2024-02-08 02:29:03.359473: 
2024-02-08 02:29:03.360551: Epoch 163
2024-02-08 02:29:03.361603: Current learning rate: 0.00729
2024-02-08 02:29:46.967376: train_loss -0.5375
2024-02-08 02:29:46.969105: val_loss -0.3906
2024-02-08 02:29:46.969636: Pseudo dice [0.8312, 0.8202, 0.7378, 0.8245, 0.8089]
2024-02-08 02:29:46.970113: Epoch time: 43.61 s
2024-02-08 02:29:48.055827: 
2024-02-08 02:29:48.057040: Epoch 164
2024-02-08 02:29:48.058115: Current learning rate: 0.00727
2024-02-08 02:30:31.464844: train_loss -0.5402
2024-02-08 02:30:31.466304: val_loss -0.3898
2024-02-08 02:30:31.466850: Pseudo dice [0.8338, 0.823, 0.7462, 0.837, 0.8214]
2024-02-08 02:30:31.467317: Epoch time: 43.41 s
2024-02-08 02:30:32.513807: 
2024-02-08 02:30:32.515108: Epoch 165
2024-02-08 02:30:32.516221: Current learning rate: 0.00725
2024-02-08 02:31:15.965415: train_loss -0.5376
2024-02-08 02:31:15.967208: val_loss -0.3898
2024-02-08 02:31:15.967766: Pseudo dice [0.837, 0.82, 0.7439, 0.8278, 0.8145]
2024-02-08 02:31:15.968467: Epoch time: 43.45 s
2024-02-08 02:31:17.004026: 
2024-02-08 02:31:17.005058: Epoch 166
2024-02-08 02:31:17.006485: Current learning rate: 0.00724
2024-02-08 02:32:00.324100: train_loss -0.5371
2024-02-08 02:32:00.325499: val_loss -0.3913
2024-02-08 02:32:00.326007: Pseudo dice [0.835, 0.8202, 0.7478, 0.8459, 0.8123]
2024-02-08 02:32:00.326541: Epoch time: 43.32 s
2024-02-08 02:32:01.379253: 
2024-02-08 02:32:01.380735: Epoch 167
2024-02-08 02:32:01.382079: Current learning rate: 0.00722
2024-02-08 02:32:44.647372: train_loss -0.5376
2024-02-08 02:32:44.648853: val_loss -0.3829
2024-02-08 02:32:44.649330: Pseudo dice [0.8371, 0.8198, 0.7381, 0.835, 0.8133]
2024-02-08 02:32:44.649780: Epoch time: 43.27 s
2024-02-08 02:32:45.720879: 
2024-02-08 02:32:45.721933: Epoch 168
2024-02-08 02:32:45.722822: Current learning rate: 0.0072
2024-02-08 02:33:28.798115: train_loss -0.5365
2024-02-08 02:33:28.799580: val_loss -0.377
2024-02-08 02:33:28.800105: Pseudo dice [0.8291, 0.8217, 0.7425, 0.8264, 0.7961]
2024-02-08 02:33:28.800528: Epoch time: 43.08 s
2024-02-08 02:33:29.873105: 
2024-02-08 02:33:29.874676: Epoch 169
2024-02-08 02:33:29.877586: Current learning rate: 0.00719
2024-02-08 02:34:13.271305: train_loss -0.5438
2024-02-08 02:34:13.283576: val_loss -0.3825
2024-02-08 02:34:13.284000: Pseudo dice [0.8363, 0.8162, 0.7396, 0.8364, 0.8098]
2024-02-08 02:34:13.284928: Epoch time: 43.4 s
2024-02-08 02:34:14.402402: 
2024-02-08 02:34:14.403671: Epoch 170
2024-02-08 02:34:14.404935: Current learning rate: 0.00717
2024-02-08 02:34:57.469108: train_loss -0.5358
2024-02-08 02:34:57.470532: val_loss -0.3781
2024-02-08 02:34:57.471057: Pseudo dice [0.8324, 0.8139, 0.733, 0.8275, 0.8165]
2024-02-08 02:34:57.471519: Epoch time: 43.07 s
2024-02-08 02:34:58.531572: 
2024-02-08 02:34:58.533376: Epoch 171
2024-02-08 02:34:58.535146: Current learning rate: 0.00715
2024-02-08 02:35:41.945233: train_loss -0.5328
2024-02-08 02:35:41.946662: val_loss -0.3871
2024-02-08 02:35:41.947182: Pseudo dice [0.8365, 0.8177, 0.7495, 0.835, 0.8135]
2024-02-08 02:35:41.947628: Epoch time: 43.42 s
2024-02-08 02:35:43.008657: 
2024-02-08 02:35:43.009818: Epoch 172
2024-02-08 02:35:43.027398: Current learning rate: 0.00714
2024-02-08 02:36:26.199912: train_loss -0.5459
2024-02-08 02:36:26.201639: val_loss -0.3929
2024-02-08 02:36:26.202101: Pseudo dice [0.8353, 0.8218, 0.748, 0.8385, 0.8141]
2024-02-08 02:36:26.202555: Epoch time: 43.19 s
2024-02-08 02:36:27.296082: 
2024-02-08 02:36:27.297101: Epoch 173
2024-02-08 02:36:27.297951: Current learning rate: 0.00712
2024-02-08 02:37:10.517051: train_loss -0.5467
2024-02-08 02:37:10.518562: val_loss -0.3873
2024-02-08 02:37:10.519036: Pseudo dice [0.834, 0.8217, 0.7447, 0.8312, 0.8108]
2024-02-08 02:37:10.519483: Epoch time: 43.22 s
2024-02-08 02:37:11.600874: 
2024-02-08 02:37:11.601933: Epoch 174
2024-02-08 02:37:11.603117: Current learning rate: 0.0071
2024-02-08 02:37:54.755832: train_loss -0.5371
2024-02-08 02:37:54.757578: val_loss -0.3944
2024-02-08 02:37:54.758109: Pseudo dice [0.8353, 0.8214, 0.7441, 0.8408, 0.8059]
2024-02-08 02:37:54.758586: Epoch time: 43.16 s
2024-02-08 02:37:55.868364: 
2024-02-08 02:37:55.869494: Epoch 175
2024-02-08 02:37:55.870386: Current learning rate: 0.00708
2024-02-08 02:38:39.408937: train_loss -0.5422
2024-02-08 02:38:39.410756: val_loss -0.3891
2024-02-08 02:38:39.411317: Pseudo dice [0.8376, 0.8175, 0.7537, 0.8412, 0.8002]
2024-02-08 02:38:39.411860: Epoch time: 43.54 s
2024-02-08 02:38:40.476952: 
2024-02-08 02:38:40.478797: Epoch 176
2024-02-08 02:38:40.479971: Current learning rate: 0.00707
2024-02-08 02:39:23.969741: train_loss -0.5471
2024-02-08 02:39:23.972429: val_loss -0.3912
2024-02-08 02:39:23.972959: Pseudo dice [0.8342, 0.8235, 0.7434, 0.8283, 0.8103]
2024-02-08 02:39:23.973437: Epoch time: 43.49 s
2024-02-08 02:39:25.039519: 
2024-02-08 02:39:25.040535: Epoch 177
2024-02-08 02:39:25.041433: Current learning rate: 0.00705
2024-02-08 02:40:08.170685: train_loss -0.5468
2024-02-08 02:40:08.172467: val_loss -0.395
2024-02-08 02:40:08.173002: Pseudo dice [0.8346, 0.8269, 0.7527, 0.8365, 0.8226]
2024-02-08 02:40:08.173515: Epoch time: 43.13 s
2024-02-08 02:40:09.236121: 
2024-02-08 02:40:09.237245: Epoch 178
2024-02-08 02:40:09.238432: Current learning rate: 0.00703
2024-02-08 02:40:52.361636: train_loss -0.5366
2024-02-08 02:40:52.363459: val_loss -0.3844
2024-02-08 02:40:52.364069: Pseudo dice [0.8291, 0.8175, 0.7445, 0.8294, 0.8069]
2024-02-08 02:40:52.364570: Epoch time: 43.13 s
2024-02-08 02:40:53.427948: 
2024-02-08 02:40:53.429125: Epoch 179
2024-02-08 02:40:53.430133: Current learning rate: 0.00702
2024-02-08 02:41:36.633106: train_loss -0.549
2024-02-08 02:41:36.645696: val_loss -0.3938
2024-02-08 02:41:36.646407: Pseudo dice [0.8339, 0.8192, 0.7397, 0.8391, 0.8167]
2024-02-08 02:41:36.647047: Epoch time: 43.21 s
2024-02-08 02:41:37.716356: 
2024-02-08 02:41:37.717524: Epoch 180
2024-02-08 02:41:37.718835: Current learning rate: 0.007
2024-02-08 02:42:20.849341: train_loss -0.5501
2024-02-08 02:42:20.850941: val_loss -0.3774
2024-02-08 02:42:20.851519: Pseudo dice [0.8325, 0.8174, 0.744, 0.8338, 0.8106]
2024-02-08 02:42:20.852152: Epoch time: 43.13 s
2024-02-08 02:42:22.206340: 
2024-02-08 02:42:22.208073: Epoch 181
2024-02-08 02:42:22.209370: Current learning rate: 0.00698
2024-02-08 02:43:05.366503: train_loss -0.5516
2024-02-08 02:43:05.368251: val_loss -0.3735
2024-02-08 02:43:05.368777: Pseudo dice [0.8347, 0.8079, 0.7431, 0.8262, 0.8049]
2024-02-08 02:43:05.369246: Epoch time: 43.16 s
2024-02-08 02:43:06.422419: 
2024-02-08 02:43:06.423773: Epoch 182
2024-02-08 02:43:06.425817: Current learning rate: 0.00697
2024-02-08 02:43:49.591164: train_loss -0.5457
2024-02-08 02:43:49.601935: val_loss -0.3834
2024-02-08 02:43:49.602468: Pseudo dice [0.8343, 0.8203, 0.7457, 0.8409, 0.8111]
2024-02-08 02:43:49.602995: Epoch time: 43.17 s
2024-02-08 02:43:50.670137: 
2024-02-08 02:43:50.671410: Epoch 183
2024-02-08 02:43:50.672658: Current learning rate: 0.00695
2024-02-08 02:44:33.863757: train_loss -0.5464
2024-02-08 02:44:33.865115: val_loss -0.3926
2024-02-08 02:44:33.865581: Pseudo dice [0.8368, 0.8227, 0.7397, 0.8391, 0.8227]
2024-02-08 02:44:33.866035: Epoch time: 43.19 s
2024-02-08 02:44:34.925184: 
2024-02-08 02:44:34.926627: Epoch 184
2024-02-08 02:44:34.927632: Current learning rate: 0.00693
2024-02-08 02:45:18.248652: train_loss -0.5405
2024-02-08 02:45:18.250145: val_loss -0.4034
2024-02-08 02:45:18.250681: Pseudo dice [0.8364, 0.8217, 0.7502, 0.8467, 0.8128]
2024-02-08 02:45:18.251132: Epoch time: 43.32 s
2024-02-08 02:45:19.322645: 
2024-02-08 02:45:19.323825: Epoch 185
2024-02-08 02:45:19.325059: Current learning rate: 0.00691
2024-02-08 02:46:02.703486: train_loss -0.5463
2024-02-08 02:46:02.704831: val_loss -0.3858
2024-02-08 02:46:02.705293: Pseudo dice [0.8343, 0.8151, 0.7412, 0.8338, 0.8156]
2024-02-08 02:46:02.705722: Epoch time: 43.38 s
2024-02-08 02:46:03.793984: 
2024-02-08 02:46:03.795292: Epoch 186
2024-02-08 02:46:03.796500: Current learning rate: 0.0069
2024-02-08 02:46:46.988567: train_loss -0.5469
2024-02-08 02:46:46.989994: val_loss -0.3815
2024-02-08 02:46:46.990503: Pseudo dice [0.8418, 0.8138, 0.7437, 0.8385, 0.8203]
2024-02-08 02:46:46.990918: Epoch time: 43.2 s
2024-02-08 02:46:48.217236: 
2024-02-08 02:46:48.218417: Epoch 187
2024-02-08 02:46:48.219880: Current learning rate: 0.00688
2024-02-08 02:47:31.381575: train_loss -0.5567
2024-02-08 02:47:31.383326: val_loss -0.3914
2024-02-08 02:47:31.383914: Pseudo dice [0.8384, 0.8161, 0.7379, 0.8331, 0.8218]
2024-02-08 02:47:31.384425: Epoch time: 43.17 s
2024-02-08 02:47:32.440072: 
2024-02-08 02:47:32.441153: Epoch 188
2024-02-08 02:47:32.442336: Current learning rate: 0.00686
2024-02-08 02:48:15.722850: train_loss -0.5471
2024-02-08 02:48:15.724311: val_loss -0.3856
2024-02-08 02:48:15.724818: Pseudo dice [0.835, 0.8203, 0.7438, 0.8449, 0.8029]
2024-02-08 02:48:15.725266: Epoch time: 43.28 s
2024-02-08 02:48:16.776933: 
2024-02-08 02:48:16.778229: Epoch 189
2024-02-08 02:48:16.779542: Current learning rate: 0.00685
2024-02-08 02:48:59.939976: train_loss -0.5523
2024-02-08 02:48:59.941960: val_loss -0.3885
2024-02-08 02:48:59.942666: Pseudo dice [0.8344, 0.8139, 0.7438, 0.8357, 0.8205]
2024-02-08 02:48:59.943241: Epoch time: 43.16 s
2024-02-08 02:49:01.062520: 
2024-02-08 02:49:01.063966: Epoch 190
2024-02-08 02:49:01.064613: Current learning rate: 0.00683
2024-02-08 02:49:44.242494: train_loss -0.5473
2024-02-08 02:49:44.244153: val_loss -0.4024
2024-02-08 02:49:44.244628: Pseudo dice [0.8394, 0.8208, 0.7487, 0.8419, 0.8129]
2024-02-08 02:49:44.245066: Epoch time: 43.18 s
2024-02-08 02:49:45.377653: 
2024-02-08 02:49:45.378884: Epoch 191
2024-02-08 02:49:45.379922: Current learning rate: 0.00681
2024-02-08 02:50:28.490291: train_loss -0.5533
2024-02-08 02:50:28.491839: val_loss -0.3613
2024-02-08 02:50:28.492292: Pseudo dice [0.8302, 0.8142, 0.7343, 0.8298, 0.8048]
2024-02-08 02:50:28.493425: Epoch time: 43.11 s
2024-02-08 02:50:29.789440: 
2024-02-08 02:50:29.790658: Epoch 192
2024-02-08 02:50:29.791887: Current learning rate: 0.00679
2024-02-08 02:51:12.908772: train_loss -0.5537
2024-02-08 02:51:12.910691: val_loss -0.3882
2024-02-08 02:51:12.911309: Pseudo dice [0.8375, 0.8199, 0.7476, 0.8391, 0.8095]
2024-02-08 02:51:12.911882: Epoch time: 43.12 s
2024-02-08 02:51:13.975012: 
2024-02-08 02:51:13.976101: Epoch 193
2024-02-08 02:51:13.977075: Current learning rate: 0.00678
2024-02-08 02:51:57.092628: train_loss -0.558
2024-02-08 02:51:57.093984: val_loss -0.3784
2024-02-08 02:51:57.094461: Pseudo dice [0.834, 0.813, 0.7396, 0.8463, 0.8008]
2024-02-08 02:51:57.094909: Epoch time: 43.12 s
2024-02-08 02:51:58.157763: 
2024-02-08 02:51:58.158858: Epoch 194
2024-02-08 02:51:58.160007: Current learning rate: 0.00676
2024-02-08 02:52:41.266217: train_loss -0.553
2024-02-08 02:52:41.268296: val_loss -0.3903
2024-02-08 02:52:41.268840: Pseudo dice [0.8381, 0.8163, 0.7466, 0.8413, 0.8114]
2024-02-08 02:52:41.269345: Epoch time: 43.11 s
2024-02-08 02:52:42.331003: 
2024-02-08 02:52:42.332133: Epoch 195
2024-02-08 02:52:42.333578: Current learning rate: 0.00674
2024-02-08 02:53:25.464323: train_loss -0.5562
2024-02-08 02:53:25.465719: val_loss -0.3981
2024-02-08 02:53:25.466219: Pseudo dice [0.8361, 0.8244, 0.7536, 0.8464, 0.8155]
2024-02-08 02:53:25.466675: Epoch time: 43.13 s
2024-02-08 02:53:26.547423: 
2024-02-08 02:53:26.548574: Epoch 196
2024-02-08 02:53:26.549561: Current learning rate: 0.00673
2024-02-08 02:54:09.806037: train_loss -0.5512
2024-02-08 02:54:09.807527: val_loss -0.4034
2024-02-08 02:54:09.808424: Pseudo dice [0.8348, 0.8241, 0.7453, 0.8454, 0.8088]
2024-02-08 02:54:09.808880: Epoch time: 43.26 s
2024-02-08 02:54:11.031198: 
2024-02-08 02:54:11.032718: Epoch 197
2024-02-08 02:54:11.033422: Current learning rate: 0.00671
2024-02-08 02:54:54.207651: train_loss -0.5539
2024-02-08 02:54:54.209208: val_loss -0.386
2024-02-08 02:54:54.209684: Pseudo dice [0.8362, 0.8132, 0.7462, 0.8342, 0.8119]
2024-02-08 02:54:54.210341: Epoch time: 43.18 s
2024-02-08 02:54:55.279423: 
2024-02-08 02:54:55.280417: Epoch 198
2024-02-08 02:54:55.281435: Current learning rate: 0.00669
2024-02-08 02:55:38.440105: train_loss -0.5562
2024-02-08 02:55:38.442095: val_loss -0.3906
2024-02-08 02:55:38.442597: Pseudo dice [0.8353, 0.8242, 0.7459, 0.8268, 0.8104]
2024-02-08 02:55:38.443068: Epoch time: 43.16 s
2024-02-08 02:55:39.530929: 
2024-02-08 02:55:39.532552: Epoch 199
2024-02-08 02:55:39.533072: Current learning rate: 0.00667
2024-02-08 02:56:22.729405: train_loss -0.5574
2024-02-08 02:56:22.730912: val_loss -0.359
2024-02-08 02:56:22.731425: Pseudo dice [0.8316, 0.8109, 0.7345, 0.8304, 0.7971]
2024-02-08 02:56:22.731907: Epoch time: 43.2 s
2024-02-08 02:56:24.098247: 
2024-02-08 02:56:24.099590: Epoch 200
2024-02-08 02:56:24.100992: Current learning rate: 0.00666
2024-02-08 02:57:07.235793: train_loss -0.5555
2024-02-08 02:57:07.237244: val_loss -0.3783
2024-02-08 02:57:07.237722: Pseudo dice [0.8316, 0.8187, 0.7389, 0.8301, 0.8225]
2024-02-08 02:57:07.238191: Epoch time: 43.14 s
2024-02-08 02:57:08.335380: 
2024-02-08 02:57:08.336432: Epoch 201
2024-02-08 02:57:08.337691: Current learning rate: 0.00664
2024-02-08 02:57:51.449597: train_loss -0.5561
2024-02-08 02:57:51.451252: val_loss -0.3882
2024-02-08 02:57:51.451769: Pseudo dice [0.8355, 0.8201, 0.7399, 0.839, 0.8111]
2024-02-08 02:57:51.452261: Epoch time: 43.12 s
2024-02-08 02:57:52.669240: 
2024-02-08 02:57:52.670495: Epoch 202
2024-02-08 02:57:52.671596: Current learning rate: 0.00662
2024-02-08 02:58:35.984031: train_loss -0.5575
2024-02-08 02:58:35.985473: val_loss -0.3723
2024-02-08 02:58:35.985967: Pseudo dice [0.8344, 0.8128, 0.7448, 0.8362, 0.8086]
2024-02-08 02:58:35.986408: Epoch time: 43.32 s
2024-02-08 02:58:37.056541: 
2024-02-08 02:58:37.057611: Epoch 203
2024-02-08 02:58:37.058610: Current learning rate: 0.00661
2024-02-08 02:59:20.387779: train_loss -0.5594
2024-02-08 02:59:20.389169: val_loss -0.3802
2024-02-08 02:59:20.389642: Pseudo dice [0.8372, 0.8163, 0.7441, 0.8379, 0.8082]
2024-02-08 02:59:20.390078: Epoch time: 43.33 s
2024-02-08 02:59:21.465345: 
2024-02-08 02:59:21.466507: Epoch 204
2024-02-08 02:59:21.467763: Current learning rate: 0.00659
2024-02-08 03:00:04.693932: train_loss -0.5616
2024-02-08 03:00:04.695914: val_loss -0.3827
2024-02-08 03:00:04.696552: Pseudo dice [0.8312, 0.8185, 0.7437, 0.8338, 0.8121]
2024-02-08 03:00:04.697040: Epoch time: 43.23 s
2024-02-08 03:00:05.768845: 
2024-02-08 03:00:05.770163: Epoch 205
2024-02-08 03:00:05.771794: Current learning rate: 0.00657
2024-02-08 03:00:48.901199: train_loss -0.5574
2024-02-08 03:00:48.902665: val_loss -0.3825
2024-02-08 03:00:48.903153: Pseudo dice [0.8353, 0.8215, 0.7416, 0.8366, 0.7994]
2024-02-08 03:00:48.903635: Epoch time: 43.13 s
2024-02-08 03:00:49.999692: 
2024-02-08 03:00:50.000896: Epoch 206
2024-02-08 03:00:50.002516: Current learning rate: 0.00656
2024-02-08 03:01:33.047097: train_loss -0.5607
2024-02-08 03:01:33.048590: val_loss -0.3779
2024-02-08 03:01:33.049098: Pseudo dice [0.8348, 0.8174, 0.7301, 0.8308, 0.8038]
2024-02-08 03:01:33.049612: Epoch time: 43.05 s
2024-02-08 03:01:34.050724: 
2024-02-08 03:01:34.051839: Epoch 207
2024-02-08 03:01:34.052881: Current learning rate: 0.00654
2024-02-08 03:02:17.109781: train_loss -0.5631
2024-02-08 03:02:17.111229: val_loss -0.3899
2024-02-08 03:02:17.111762: Pseudo dice [0.8343, 0.8218, 0.7447, 0.8333, 0.8208]
2024-02-08 03:02:17.112236: Epoch time: 43.06 s
2024-02-08 03:02:18.137343: 
2024-02-08 03:02:18.138525: Epoch 208
2024-02-08 03:02:18.139690: Current learning rate: 0.00652
2024-02-08 03:03:01.245083: train_loss -0.5602
2024-02-08 03:03:01.246766: val_loss -0.3989
2024-02-08 03:03:01.247222: Pseudo dice [0.8366, 0.8236, 0.7476, 0.8352, 0.8135]
2024-02-08 03:03:01.247662: Epoch time: 43.11 s
2024-02-08 03:03:02.266701: 
2024-02-08 03:03:02.267821: Epoch 209
2024-02-08 03:03:02.269245: Current learning rate: 0.0065
2024-02-08 03:03:45.526348: train_loss -0.5544
2024-02-08 03:03:45.530174: val_loss -0.3711
2024-02-08 03:03:45.530683: Pseudo dice [0.8344, 0.8145, 0.745, 0.834, 0.8116]
2024-02-08 03:03:45.531224: Epoch time: 43.26 s
2024-02-08 03:03:46.638040: 
2024-02-08 03:03:46.639549: Epoch 210
2024-02-08 03:03:46.640993: Current learning rate: 0.00649
2024-02-08 03:04:29.903548: train_loss -0.5606
2024-02-08 03:04:29.905676: val_loss -0.381
2024-02-08 03:04:29.906155: Pseudo dice [0.8314, 0.8197, 0.746, 0.8293, 0.8071]
2024-02-08 03:04:29.906604: Epoch time: 43.27 s
2024-02-08 03:04:30.909894: 
2024-02-08 03:04:30.912011: Epoch 211
2024-02-08 03:04:30.912582: Current learning rate: 0.00647
2024-02-08 03:05:14.238461: train_loss -0.5586
2024-02-08 03:05:14.239815: val_loss -0.3768
2024-02-08 03:05:14.240289: Pseudo dice [0.8373, 0.8146, 0.7424, 0.8313, 0.814]
2024-02-08 03:05:14.240705: Epoch time: 43.33 s
2024-02-08 03:05:15.267325: 
2024-02-08 03:05:15.268646: Epoch 212
2024-02-08 03:05:15.270238: Current learning rate: 0.00645
2024-02-08 03:05:58.469448: train_loss -0.5612
2024-02-08 03:05:58.471145: val_loss -0.3837
2024-02-08 03:05:58.471675: Pseudo dice [0.8378, 0.8187, 0.7468, 0.8331, 0.8176]
2024-02-08 03:05:58.472156: Epoch time: 43.2 s
2024-02-08 03:05:59.599513: 
2024-02-08 03:05:59.600791: Epoch 213
2024-02-08 03:05:59.602167: Current learning rate: 0.00643
2024-02-08 03:06:42.811379: train_loss -0.5578
2024-02-08 03:06:42.812800: val_loss -0.3863
2024-02-08 03:06:42.813299: Pseudo dice [0.8334, 0.8188, 0.7402, 0.8434, 0.7957]
2024-02-08 03:06:42.813875: Epoch time: 43.21 s
2024-02-08 03:06:43.840714: 
2024-02-08 03:06:43.841791: Epoch 214
2024-02-08 03:06:43.842864: Current learning rate: 0.00642
2024-02-08 03:07:27.167308: train_loss -0.5595
2024-02-08 03:07:27.168834: val_loss -0.3891
2024-02-08 03:07:27.169311: Pseudo dice [0.8376, 0.8176, 0.7487, 0.8353, 0.8076]
2024-02-08 03:07:27.169770: Epoch time: 43.33 s
2024-02-08 03:07:28.220100: 
2024-02-08 03:07:28.221308: Epoch 215
2024-02-08 03:07:28.222450: Current learning rate: 0.0064
2024-02-08 03:08:11.446194: train_loss -0.5584
2024-02-08 03:08:11.447635: val_loss -0.3935
2024-02-08 03:08:11.448128: Pseudo dice [0.8363, 0.8224, 0.7423, 0.8357, 0.8003]
2024-02-08 03:08:11.448577: Epoch time: 43.23 s
2024-02-08 03:08:12.447289: 
2024-02-08 03:08:12.448287: Epoch 216
2024-02-08 03:08:12.449283: Current learning rate: 0.00638
2024-02-08 03:08:55.479081: train_loss -0.5562
2024-02-08 03:08:55.480790: val_loss -0.3901
2024-02-08 03:08:55.481289: Pseudo dice [0.8391, 0.821, 0.75, 0.8384, 0.8196]
2024-02-08 03:08:55.481749: Epoch time: 43.03 s
2024-02-08 03:08:56.482034: 
2024-02-08 03:08:56.483298: Epoch 217
2024-02-08 03:08:56.484364: Current learning rate: 0.00637
2024-02-08 03:09:39.689656: train_loss -0.5594
2024-02-08 03:09:39.692083: val_loss -0.3659
2024-02-08 03:09:39.692617: Pseudo dice [0.8296, 0.8158, 0.7399, 0.8334, 0.8103]
2024-02-08 03:09:39.693120: Epoch time: 43.21 s
2024-02-08 03:09:40.820711: 
2024-02-08 03:09:40.821938: Epoch 218
2024-02-08 03:09:40.823134: Current learning rate: 0.00635
2024-02-08 03:10:24.035650: train_loss -0.5638
2024-02-08 03:10:24.037285: val_loss -0.3913
2024-02-08 03:10:24.037758: Pseudo dice [0.837, 0.8169, 0.7482, 0.8412, 0.8156]
2024-02-08 03:10:24.038203: Epoch time: 43.22 s
2024-02-08 03:10:25.030766: 
2024-02-08 03:10:25.031616: Epoch 219
2024-02-08 03:10:25.032434: Current learning rate: 0.00633
2024-02-08 03:11:08.428629: train_loss -0.5623
2024-02-08 03:11:08.430660: val_loss -0.362
2024-02-08 03:11:08.431166: Pseudo dice [0.8268, 0.8117, 0.7374, 0.8361, 0.8049]
2024-02-08 03:11:08.431659: Epoch time: 43.4 s
2024-02-08 03:11:09.420449: 
2024-02-08 03:11:09.421334: Epoch 220
2024-02-08 03:11:09.421945: Current learning rate: 0.00631
2024-02-08 03:11:52.468146: train_loss -0.5678
2024-02-08 03:11:52.469635: val_loss -0.3768
2024-02-08 03:11:52.470171: Pseudo dice [0.8345, 0.8144, 0.7452, 0.8391, 0.8146]
2024-02-08 03:11:52.470641: Epoch time: 43.05 s
2024-02-08 03:11:53.474204: 
2024-02-08 03:11:53.475435: Epoch 221
2024-02-08 03:11:53.476679: Current learning rate: 0.0063
2024-02-08 03:12:36.616464: train_loss -0.5515
2024-02-08 03:12:36.618237: val_loss -0.3691
2024-02-08 03:12:36.618792: Pseudo dice [0.8288, 0.8153, 0.7436, 0.8315, 0.8057]
2024-02-08 03:12:36.619307: Epoch time: 43.14 s
2024-02-08 03:12:37.663201: 
2024-02-08 03:12:37.664441: Epoch 222
2024-02-08 03:12:37.665474: Current learning rate: 0.00628
2024-02-08 03:13:20.790555: train_loss -0.5661
2024-02-08 03:13:20.792274: val_loss -0.3872
2024-02-08 03:13:20.792802: Pseudo dice [0.8362, 0.8176, 0.7426, 0.8452, 0.8145]
2024-02-08 03:13:20.793245: Epoch time: 43.13 s
2024-02-08 03:13:21.805182: 
2024-02-08 03:13:21.806183: Epoch 223
2024-02-08 03:13:21.807280: Current learning rate: 0.00626
2024-02-08 03:14:05.106348: train_loss -0.5599
2024-02-08 03:14:05.107682: val_loss -0.3834
2024-02-08 03:14:05.108147: Pseudo dice [0.8322, 0.8176, 0.7372, 0.8275, 0.8128]
2024-02-08 03:14:05.108635: Epoch time: 43.3 s
2024-02-08 03:14:06.248299: 
2024-02-08 03:14:06.249935: Epoch 224
2024-02-08 03:14:06.251739: Current learning rate: 0.00625
2024-02-08 03:14:49.560946: train_loss -0.5662
2024-02-08 03:14:49.562665: val_loss -0.3744
2024-02-08 03:14:49.563177: Pseudo dice [0.8308, 0.8236, 0.7482, 0.8332, 0.8138]
2024-02-08 03:14:49.563673: Epoch time: 43.31 s
2024-02-08 03:14:50.602958: 
2024-02-08 03:14:50.604588: Epoch 225
2024-02-08 03:14:50.605744: Current learning rate: 0.00623
2024-02-08 03:15:34.082253: train_loss -0.5651
2024-02-08 03:15:34.083760: val_loss -0.3947
2024-02-08 03:15:34.084220: Pseudo dice [0.8374, 0.8213, 0.7496, 0.8456, 0.8206]
2024-02-08 03:15:34.084682: Epoch time: 43.48 s
2024-02-08 03:15:35.119942: 
2024-02-08 03:15:35.121449: Epoch 226
2024-02-08 03:15:35.122660: Current learning rate: 0.00621
2024-02-08 03:16:18.532964: train_loss -0.5641
2024-02-08 03:16:18.534703: val_loss -0.3974
2024-02-08 03:16:18.535235: Pseudo dice [0.8357, 0.8232, 0.7482, 0.841, 0.8109]
2024-02-08 03:16:18.535745: Epoch time: 43.41 s
2024-02-08 03:16:19.536301: 
2024-02-08 03:16:19.537466: Epoch 227
2024-02-08 03:16:19.538553: Current learning rate: 0.00619
2024-02-08 03:17:02.926812: train_loss -0.5616
2024-02-08 03:17:02.929025: val_loss -0.3846
2024-02-08 03:17:02.929589: Pseudo dice [0.8376, 0.8177, 0.7416, 0.8364, 0.8037]
2024-02-08 03:17:02.930121: Epoch time: 43.39 s
2024-02-08 03:17:03.958719: 
2024-02-08 03:17:03.960576: Epoch 228
2024-02-08 03:17:03.961193: Current learning rate: 0.00618
2024-02-08 03:17:47.372975: train_loss -0.5635
2024-02-08 03:17:47.374462: val_loss -0.3925
2024-02-08 03:17:47.374923: Pseudo dice [0.8381, 0.8214, 0.7428, 0.8405, 0.8142]
2024-02-08 03:17:47.375372: Epoch time: 43.42 s
2024-02-08 03:17:48.522607: 
2024-02-08 03:17:48.523722: Epoch 229
2024-02-08 03:17:48.524663: Current learning rate: 0.00616
2024-02-08 03:18:31.869597: train_loss -0.5672
2024-02-08 03:18:31.871010: val_loss -0.3671
2024-02-08 03:18:31.871482: Pseudo dice [0.8335, 0.8106, 0.7375, 0.8308, 0.8187]
2024-02-08 03:18:31.871919: Epoch time: 43.35 s
2024-02-08 03:18:32.891649: 
2024-02-08 03:18:32.892884: Epoch 230
2024-02-08 03:18:32.894182: Current learning rate: 0.00614
2024-02-08 03:19:16.338523: train_loss -0.5645
2024-02-08 03:19:16.340360: val_loss -0.379
2024-02-08 03:19:16.340899: Pseudo dice [0.8327, 0.8161, 0.7451, 0.8368, 0.8091]
2024-02-08 03:19:16.341374: Epoch time: 43.45 s
2024-02-08 03:19:17.347381: 
2024-02-08 03:19:17.348484: Epoch 231
2024-02-08 03:19:17.349870: Current learning rate: 0.00612
2024-02-08 03:20:00.707110: train_loss -0.5635
2024-02-08 03:20:00.709386: val_loss -0.3922
2024-02-08 03:20:00.710157: Pseudo dice [0.8404, 0.8199, 0.7454, 0.8315, 0.8177]
2024-02-08 03:20:00.710717: Epoch time: 43.36 s
2024-02-08 03:20:01.726178: 
2024-02-08 03:20:01.727253: Epoch 232
2024-02-08 03:20:01.728464: Current learning rate: 0.00611
2024-02-08 03:20:44.970938: train_loss -0.5663
2024-02-08 03:20:44.973241: val_loss -0.3876
2024-02-08 03:20:44.973821: Pseudo dice [0.8388, 0.8212, 0.7514, 0.8377, 0.8102]
2024-02-08 03:20:44.974370: Epoch time: 43.25 s
2024-02-08 03:20:46.029431: 
2024-02-08 03:20:46.030493: Epoch 233
2024-02-08 03:20:46.031492: Current learning rate: 0.00609
2024-02-08 03:21:29.097814: train_loss -0.5653
2024-02-08 03:21:29.099205: val_loss -0.3833
2024-02-08 03:21:29.099663: Pseudo dice [0.8353, 0.8184, 0.7485, 0.8409, 0.8123]
2024-02-08 03:21:29.100119: Epoch time: 43.07 s
2024-02-08 03:21:30.232421: 
2024-02-08 03:21:30.233652: Epoch 234
2024-02-08 03:21:30.235189: Current learning rate: 0.00607
2024-02-08 03:22:13.086328: train_loss -0.5686
2024-02-08 03:22:13.087785: val_loss -0.3901
2024-02-08 03:22:13.088254: Pseudo dice [0.8395, 0.8168, 0.7466, 0.842, 0.8223]
2024-02-08 03:22:13.089092: Epoch time: 42.85 s
2024-02-08 03:22:14.102432: 
2024-02-08 03:22:14.103518: Epoch 235
2024-02-08 03:22:14.104532: Current learning rate: 0.00606
2024-02-08 03:22:57.160010: train_loss -0.568
2024-02-08 03:22:57.161278: val_loss -0.3758
2024-02-08 03:22:57.161718: Pseudo dice [0.8354, 0.8143, 0.7368, 0.8331, 0.8167]
2024-02-08 03:22:57.162144: Epoch time: 43.06 s
2024-02-08 03:22:58.309293: 
2024-02-08 03:22:58.310445: Epoch 236
2024-02-08 03:22:58.311419: Current learning rate: 0.00604
2024-02-08 03:23:41.313621: train_loss -0.5728
2024-02-08 03:23:41.315029: val_loss -0.378
2024-02-08 03:23:41.315490: Pseudo dice [0.831, 0.8179, 0.7469, 0.8368, 0.8058]
2024-02-08 03:23:41.315940: Epoch time: 43.01 s
2024-02-08 03:23:42.359135: 
2024-02-08 03:23:42.360304: Epoch 237
2024-02-08 03:23:42.361632: Current learning rate: 0.00602
2024-02-08 03:24:25.394891: train_loss -0.5761
2024-02-08 03:24:25.396574: val_loss -0.3743
2024-02-08 03:24:25.397109: Pseudo dice [0.8322, 0.8168, 0.7403, 0.8345, 0.8095]
2024-02-08 03:24:25.397614: Epoch time: 43.04 s
2024-02-08 03:24:26.416578: 
2024-02-08 03:24:26.418089: Epoch 238
2024-02-08 03:24:26.419781: Current learning rate: 0.006
2024-02-08 03:25:09.513094: train_loss -0.5747
2024-02-08 03:25:09.515127: val_loss -0.3858
2024-02-08 03:25:09.515768: Pseudo dice [0.8369, 0.8212, 0.7493, 0.8316, 0.8133]
2024-02-08 03:25:09.516201: Epoch time: 43.1 s
2024-02-08 03:25:10.522793: 
2024-02-08 03:25:10.523992: Epoch 239
2024-02-08 03:25:10.525549: Current learning rate: 0.00599
2024-02-08 03:25:53.731699: train_loss -0.5738
2024-02-08 03:25:53.733233: val_loss -0.3927
2024-02-08 03:25:53.733724: Pseudo dice [0.835, 0.8225, 0.7442, 0.8442, 0.8104]
2024-02-08 03:25:53.734165: Epoch time: 43.21 s
2024-02-08 03:25:54.880976: 
2024-02-08 03:25:54.882216: Epoch 240
2024-02-08 03:25:54.883648: Current learning rate: 0.00597
2024-02-08 03:26:38.262917: train_loss -0.5732
2024-02-08 03:26:38.265273: val_loss -0.3878
2024-02-08 03:26:38.265873: Pseudo dice [0.8399, 0.8156, 0.7415, 0.8342, 0.8063]
2024-02-08 03:26:38.266836: Epoch time: 43.38 s
2024-02-08 03:26:39.300115: 
2024-02-08 03:26:39.301290: Epoch 241
2024-02-08 03:26:39.302527: Current learning rate: 0.00595
2024-02-08 03:27:22.364310: train_loss -0.5741
2024-02-08 03:27:22.365772: val_loss -0.3968
2024-02-08 03:27:22.366256: Pseudo dice [0.8398, 0.825, 0.7512, 0.8446, 0.8079]
2024-02-08 03:27:22.366792: Epoch time: 43.07 s
2024-02-08 03:27:23.413742: 
2024-02-08 03:27:23.415394: Epoch 242
2024-02-08 03:27:23.416779: Current learning rate: 0.00593
2024-02-08 03:28:06.481022: train_loss -0.5676
2024-02-08 03:28:06.483430: val_loss -0.3793
2024-02-08 03:28:06.483989: Pseudo dice [0.8332, 0.8229, 0.7438, 0.8375, 0.8081]
2024-02-08 03:28:06.484502: Epoch time: 43.07 s
2024-02-08 03:28:07.514578: 
2024-02-08 03:28:07.516188: Epoch 243
2024-02-08 03:28:07.517642: Current learning rate: 0.00592
2024-02-08 03:28:50.609981: train_loss -0.5659
2024-02-08 03:28:50.611627: val_loss -0.4018
2024-02-08 03:28:50.612122: Pseudo dice [0.8415, 0.8245, 0.7497, 0.8409, 0.8173]
2024-02-08 03:28:50.612587: Epoch time: 43.1 s
2024-02-08 03:28:51.661726: 
2024-02-08 03:28:51.663133: Epoch 244
2024-02-08 03:28:51.664238: Current learning rate: 0.0059
2024-02-08 03:29:34.741489: train_loss -0.572
2024-02-08 03:29:34.743118: val_loss -0.393
2024-02-08 03:29:34.743704: Pseudo dice [0.8338, 0.8253, 0.7475, 0.8339, 0.8151]
2024-02-08 03:29:34.744361: Epoch time: 43.08 s
2024-02-08 03:29:35.882587: 
2024-02-08 03:29:35.894806: Epoch 245
2024-02-08 03:29:35.895921: Current learning rate: 0.00588
2024-02-08 03:30:18.929968: train_loss -0.5767
2024-02-08 03:30:18.931370: val_loss -0.3863
2024-02-08 03:30:18.932038: Pseudo dice [0.8393, 0.8244, 0.7466, 0.8383, 0.8137]
2024-02-08 03:30:18.932501: Epoch time: 43.05 s
2024-02-08 03:30:18.932938: Yayy! New best EMA pseudo Dice: 0.8105
2024-02-08 03:30:20.205353: 
2024-02-08 03:30:20.206736: Epoch 246
2024-02-08 03:30:20.208024: Current learning rate: 0.00586
2024-02-08 03:31:03.330445: train_loss -0.5721
2024-02-08 03:31:03.332363: val_loss -0.3818
2024-02-08 03:31:03.332931: Pseudo dice [0.8323, 0.8204, 0.7433, 0.838, 0.8053]
2024-02-08 03:31:03.333424: Epoch time: 43.13 s
2024-02-08 03:31:04.356341: 
2024-02-08 03:31:04.357519: Epoch 247
2024-02-08 03:31:04.358508: Current learning rate: 0.00585
2024-02-08 03:31:47.595863: train_loss -0.5733
2024-02-08 03:31:47.597319: val_loss -0.3795
2024-02-08 03:31:47.597779: Pseudo dice [0.8363, 0.8173, 0.7441, 0.8415, 0.8085]
2024-02-08 03:31:47.598287: Epoch time: 43.24 s
2024-02-08 03:31:48.652302: 
2024-02-08 03:31:48.653472: Epoch 248
2024-02-08 03:31:48.654829: Current learning rate: 0.00583
2024-02-08 03:32:31.878640: train_loss -0.5723
2024-02-08 03:32:31.880289: val_loss -0.3974
2024-02-08 03:32:31.880773: Pseudo dice [0.8397, 0.822, 0.7454, 0.8457, 0.8149]
2024-02-08 03:32:31.881192: Epoch time: 43.23 s
2024-02-08 03:32:31.881644: Yayy! New best EMA pseudo Dice: 0.8105
2024-02-08 03:32:33.233431: 
2024-02-08 03:32:33.234612: Epoch 249
2024-02-08 03:32:33.235707: Current learning rate: 0.00581
2024-02-08 03:33:16.440248: train_loss -0.5723
2024-02-08 03:33:16.441900: val_loss -0.3893
2024-02-08 03:33:16.442418: Pseudo dice [0.8374, 0.8212, 0.7392, 0.838, 0.8186]
2024-02-08 03:33:16.442885: Epoch time: 43.21 s
2024-02-08 03:33:16.895356: Yayy! New best EMA pseudo Dice: 0.8105
2024-02-08 03:33:18.247453: 
2024-02-08 03:33:18.249196: Epoch 250
2024-02-08 03:33:18.250723: Current learning rate: 0.0058
2024-02-08 03:34:01.391907: train_loss -0.5698
2024-02-08 03:34:01.393519: val_loss -0.3868
2024-02-08 03:34:01.394030: Pseudo dice [0.8372, 0.8214, 0.7393, 0.8395, 0.8116]
2024-02-08 03:34:01.394506: Epoch time: 43.15 s
2024-02-08 03:34:02.428301: 
2024-02-08 03:34:02.429809: Epoch 251
2024-02-08 03:34:02.430699: Current learning rate: 0.00578
2024-02-08 03:34:45.380733: train_loss -0.577
2024-02-08 03:34:45.382315: val_loss -0.38
2024-02-08 03:34:45.382862: Pseudo dice [0.8385, 0.8157, 0.7463, 0.8393, 0.8049]
2024-02-08 03:34:45.383303: Epoch time: 42.95 s
2024-02-08 03:34:46.392061: 
2024-02-08 03:34:46.393305: Epoch 252
2024-02-08 03:34:46.394425: Current learning rate: 0.00576
2024-02-08 03:35:29.559961: train_loss -0.5773
2024-02-08 03:35:29.561807: val_loss -0.4069
2024-02-08 03:35:29.562446: Pseudo dice [0.8386, 0.8245, 0.7461, 0.8439, 0.8136]
2024-02-08 03:35:29.562973: Epoch time: 43.17 s
2024-02-08 03:35:29.563415: Yayy! New best EMA pseudo Dice: 0.8106
2024-02-08 03:35:30.880958: 
2024-02-08 03:35:30.882027: Epoch 253
2024-02-08 03:35:30.882903: Current learning rate: 0.00574
2024-02-08 03:36:14.224070: train_loss -0.5753
2024-02-08 03:36:14.225656: val_loss -0.3731
2024-02-08 03:36:14.226182: Pseudo dice [0.8333, 0.8173, 0.7411, 0.8357, 0.7953]
2024-02-08 03:36:14.226665: Epoch time: 43.34 s
2024-02-08 03:36:15.286690: 
2024-02-08 03:36:15.287992: Epoch 254
2024-02-08 03:36:15.289089: Current learning rate: 0.00573
2024-02-08 03:36:58.701854: train_loss -0.5757
2024-02-08 03:36:58.703222: val_loss -0.3792
2024-02-08 03:36:58.703799: Pseudo dice [0.8366, 0.8194, 0.7461, 0.8407, 0.8106]
2024-02-08 03:36:58.704260: Epoch time: 43.42 s
2024-02-08 03:36:59.909878: 
2024-02-08 03:36:59.912115: Epoch 255
2024-02-08 03:36:59.913176: Current learning rate: 0.00571
2024-02-08 03:37:43.291059: train_loss -0.5729
2024-02-08 03:37:43.292759: val_loss -0.364
2024-02-08 03:37:43.293289: Pseudo dice [0.8293, 0.8155, 0.7414, 0.8308, 0.7942]
2024-02-08 03:37:43.293796: Epoch time: 43.38 s
2024-02-08 03:37:44.328502: 
2024-02-08 03:37:44.330416: Epoch 256
2024-02-08 03:37:44.332120: Current learning rate: 0.00569
2024-02-08 03:38:27.651569: train_loss -0.5768
2024-02-08 03:38:27.652978: val_loss -0.3803
2024-02-08 03:38:27.653457: Pseudo dice [0.8313, 0.8233, 0.7418, 0.8305, 0.8158]
2024-02-08 03:38:27.653901: Epoch time: 43.33 s
2024-02-08 03:38:28.674176: 
2024-02-08 03:38:28.675387: Epoch 257
2024-02-08 03:38:28.676635: Current learning rate: 0.00567
2024-02-08 03:39:12.049325: train_loss -0.5736
2024-02-08 03:39:12.050850: val_loss -0.4008
2024-02-08 03:39:12.051388: Pseudo dice [0.8366, 0.8262, 0.7466, 0.8405, 0.8262]
2024-02-08 03:39:12.051850: Epoch time: 43.38 s
2024-02-08 03:39:13.108452: 
2024-02-08 03:39:13.109792: Epoch 258
2024-02-08 03:39:13.110830: Current learning rate: 0.00566
2024-02-08 03:39:56.376268: train_loss -0.5767
2024-02-08 03:39:56.377645: val_loss -0.3854
2024-02-08 03:39:56.378117: Pseudo dice [0.837, 0.8211, 0.7333, 0.8353, 0.8094]
2024-02-08 03:39:56.378580: Epoch time: 43.27 s
2024-02-08 03:39:57.422190: 
2024-02-08 03:39:57.423315: Epoch 259
2024-02-08 03:39:57.424218: Current learning rate: 0.00564
2024-02-08 03:40:40.498940: train_loss -0.5724
2024-02-08 03:40:40.500767: val_loss -0.3767
2024-02-08 03:40:40.501309: Pseudo dice [0.838, 0.8171, 0.741, 0.8387, 0.8226]
2024-02-08 03:40:40.501761: Epoch time: 43.08 s
2024-02-08 03:40:41.724944: 
2024-02-08 03:40:41.726748: Epoch 260
2024-02-08 03:40:41.728714: Current learning rate: 0.00562
2024-02-08 03:41:25.043408: train_loss -0.5707
2024-02-08 03:41:25.044901: val_loss -0.3709
2024-02-08 03:41:25.045377: Pseudo dice [0.8337, 0.8205, 0.7362, 0.8367, 0.8028]
2024-02-08 03:41:25.045815: Epoch time: 43.32 s
2024-02-08 03:41:26.122652: 
2024-02-08 03:41:26.123803: Epoch 261
2024-02-08 03:41:26.125045: Current learning rate: 0.0056
2024-02-08 03:42:09.302340: train_loss -0.5724
2024-02-08 03:42:09.304086: val_loss -0.395
2024-02-08 03:42:09.304759: Pseudo dice [0.8401, 0.8221, 0.7467, 0.8464, 0.8133]
2024-02-08 03:42:09.305277: Epoch time: 43.18 s
2024-02-08 03:42:10.314428: 
2024-02-08 03:42:10.315656: Epoch 262
2024-02-08 03:42:10.316650: Current learning rate: 0.00559
2024-02-08 03:42:53.499292: train_loss -0.5796
2024-02-08 03:42:53.501492: val_loss -0.3851
2024-02-08 03:42:53.502062: Pseudo dice [0.8368, 0.817, 0.7458, 0.838, 0.8158]
2024-02-08 03:42:53.502580: Epoch time: 43.19 s
2024-02-08 03:42:54.521410: 
2024-02-08 03:42:54.522476: Epoch 263
2024-02-08 03:42:54.523537: Current learning rate: 0.00557
2024-02-08 03:43:38.061505: train_loss -0.5786
2024-02-08 03:43:38.063070: val_loss -0.3859
2024-02-08 03:43:38.063595: Pseudo dice [0.8314, 0.8286, 0.7519, 0.8347, 0.8086]
2024-02-08 03:43:38.064245: Epoch time: 43.54 s
2024-02-08 03:43:39.108545: 
2024-02-08 03:43:39.109772: Epoch 264
2024-02-08 03:43:39.110745: Current learning rate: 0.00555
2024-02-08 03:44:22.231669: train_loss -0.5835
2024-02-08 03:44:22.233101: val_loss -0.3855
2024-02-08 03:44:22.233612: Pseudo dice [0.8358, 0.8202, 0.739, 0.839, 0.8186]
2024-02-08 03:44:22.234026: Epoch time: 43.12 s
2024-02-08 03:44:23.311337: 
2024-02-08 03:44:23.312383: Epoch 265
2024-02-08 03:44:23.316623: Current learning rate: 0.00553
2024-02-08 03:45:06.690465: train_loss -0.5691
2024-02-08 03:45:06.691982: val_loss -0.394
2024-02-08 03:45:06.692497: Pseudo dice [0.8377, 0.8228, 0.7504, 0.8368, 0.8129]
2024-02-08 03:45:06.692942: Epoch time: 43.38 s
2024-02-08 03:45:07.911261: 
2024-02-08 03:45:07.912642: Epoch 266
2024-02-08 03:45:07.914283: Current learning rate: 0.00552
2024-02-08 03:45:51.547078: train_loss -0.5751
2024-02-08 03:45:51.548598: val_loss -0.382
2024-02-08 03:45:51.549093: Pseudo dice [0.8407, 0.8214, 0.7449, 0.843, 0.8046]
2024-02-08 03:45:51.549552: Epoch time: 43.64 s
2024-02-08 03:45:52.588310: 
2024-02-08 03:45:52.590369: Epoch 267
2024-02-08 03:45:52.591100: Current learning rate: 0.0055
2024-02-08 03:46:36.066267: train_loss -0.5759
2024-02-08 03:46:36.067971: val_loss -0.3793
2024-02-08 03:46:36.068523: Pseudo dice [0.8353, 0.8233, 0.7378, 0.8392, 0.8148]
2024-02-08 03:46:36.069011: Epoch time: 43.48 s
2024-02-08 03:46:37.106064: 
2024-02-08 03:46:37.107063: Epoch 268
2024-02-08 03:46:37.108207: Current learning rate: 0.00548
2024-02-08 03:47:20.480109: train_loss -0.5879
2024-02-08 03:47:20.481548: val_loss -0.385
2024-02-08 03:47:20.482006: Pseudo dice [0.8371, 0.822, 0.7523, 0.8396, 0.815]
2024-02-08 03:47:20.482907: Epoch time: 43.38 s
2024-02-08 03:47:21.544955: 
2024-02-08 03:47:21.546073: Epoch 269
2024-02-08 03:47:21.547372: Current learning rate: 0.00546
2024-02-08 03:48:04.693268: train_loss -0.5821
2024-02-08 03:48:04.695013: val_loss -0.3768
2024-02-08 03:48:04.695575: Pseudo dice [0.8342, 0.8224, 0.7474, 0.8405, 0.8115]
2024-02-08 03:48:04.696024: Epoch time: 43.15 s
2024-02-08 03:48:04.696450: Yayy! New best EMA pseudo Dice: 0.8107
2024-02-08 03:48:06.023088: 
2024-02-08 03:48:06.024080: Epoch 270
2024-02-08 03:48:06.024970: Current learning rate: 0.00545
2024-02-08 03:48:49.092203: train_loss -0.5821
2024-02-08 03:48:49.093704: val_loss -0.371
2024-02-08 03:48:49.094344: Pseudo dice [0.8329, 0.8181, 0.7458, 0.8348, 0.8022]
2024-02-08 03:48:49.094791: Epoch time: 43.07 s
2024-02-08 03:48:50.375179: 
2024-02-08 03:48:50.376368: Epoch 271
2024-02-08 03:48:50.377215: Current learning rate: 0.00543
2024-02-08 03:49:33.432401: train_loss -0.5775
2024-02-08 03:49:33.434074: val_loss -0.3722
2024-02-08 03:49:33.434579: Pseudo dice [0.8336, 0.8181, 0.7463, 0.8317, 0.8116]
2024-02-08 03:49:33.435008: Epoch time: 43.06 s
2024-02-08 03:49:34.478173: 
2024-02-08 03:49:34.479414: Epoch 272
2024-02-08 03:49:34.480722: Current learning rate: 0.00541
2024-02-08 03:50:17.729241: train_loss -0.5724
2024-02-08 03:50:17.731081: val_loss -0.388
2024-02-08 03:50:17.731601: Pseudo dice [0.8351, 0.8211, 0.7515, 0.8361, 0.8174]
2024-02-08 03:50:17.732100: Epoch time: 43.25 s
2024-02-08 03:50:18.750245: 
2024-02-08 03:50:18.751327: Epoch 273
2024-02-08 03:50:18.752557: Current learning rate: 0.00539
2024-02-08 03:51:01.805065: train_loss -0.5749
2024-02-08 03:51:01.806656: val_loss -0.3792
2024-02-08 03:51:01.807157: Pseudo dice [0.8365, 0.8173, 0.7395, 0.8392, 0.8061]
2024-02-08 03:51:01.807832: Epoch time: 43.06 s
2024-02-08 03:51:02.849556: 
2024-02-08 03:51:02.850716: Epoch 274
2024-02-08 03:51:02.851703: Current learning rate: 0.00538
2024-02-08 03:51:46.054823: train_loss -0.5832
2024-02-08 03:51:46.056223: val_loss -0.3753
2024-02-08 03:51:46.056708: Pseudo dice [0.8351, 0.8189, 0.7402, 0.8355, 0.8096]
2024-02-08 03:51:46.057163: Epoch time: 43.21 s
2024-02-08 03:51:47.099909: 
2024-02-08 03:51:47.101428: Epoch 275
2024-02-08 03:51:47.103110: Current learning rate: 0.00536
2024-02-08 03:52:30.260651: train_loss -0.5801
2024-02-08 03:52:30.262106: val_loss -0.369
2024-02-08 03:52:30.262584: Pseudo dice [0.832, 0.8242, 0.7351, 0.8292, 0.8091]
2024-02-08 03:52:30.263057: Epoch time: 43.16 s
2024-02-08 03:52:31.307291: 
2024-02-08 03:52:31.308668: Epoch 276
2024-02-08 03:52:31.309838: Current learning rate: 0.00534
2024-02-08 03:53:14.643800: train_loss -0.5781
2024-02-08 03:53:14.645253: val_loss -0.3792
2024-02-08 03:53:14.645779: Pseudo dice [0.8369, 0.8242, 0.7417, 0.8359, 0.8115]
2024-02-08 03:53:14.646260: Epoch time: 43.34 s
2024-02-08 03:53:15.931858: 
2024-02-08 03:53:15.933254: Epoch 277
2024-02-08 03:53:15.933842: Current learning rate: 0.00532
2024-02-08 03:53:59.213828: train_loss -0.5864
2024-02-08 03:53:59.215582: val_loss -0.3867
2024-02-08 03:53:59.216121: Pseudo dice [0.8386, 0.8197, 0.7503, 0.8327, 0.8131]
2024-02-08 03:53:59.216643: Epoch time: 43.28 s
2024-02-08 03:54:00.246778: 
2024-02-08 03:54:00.247706: Epoch 278
2024-02-08 03:54:00.248667: Current learning rate: 0.00531
2024-02-08 03:54:43.259775: train_loss -0.5788
2024-02-08 03:54:43.261712: val_loss -0.3891
2024-02-08 03:54:43.262234: Pseudo dice [0.8382, 0.8211, 0.7496, 0.8441, 0.814]
2024-02-08 03:54:43.262712: Epoch time: 43.01 s
2024-02-08 03:54:44.295006: 
2024-02-08 03:54:44.296014: Epoch 279
2024-02-08 03:54:44.296986: Current learning rate: 0.00529
2024-02-08 03:55:27.465391: train_loss -0.5843
2024-02-08 03:55:27.467002: val_loss -0.3799
2024-02-08 03:55:27.467477: Pseudo dice [0.8378, 0.8232, 0.7462, 0.8464, 0.8077]
2024-02-08 03:55:27.467906: Epoch time: 43.17 s
2024-02-08 03:55:28.489347: 
2024-02-08 03:55:28.490632: Epoch 280
2024-02-08 03:55:28.491630: Current learning rate: 0.00527
2024-02-08 03:56:11.549316: train_loss -0.5783
2024-02-08 03:56:11.550825: val_loss -0.3824
2024-02-08 03:56:11.551313: Pseudo dice [0.8395, 0.8216, 0.75, 0.8494, 0.8099]
2024-02-08 03:56:11.551807: Epoch time: 43.06 s
2024-02-08 03:56:12.592519: 
2024-02-08 03:56:12.594072: Epoch 281
2024-02-08 03:56:12.595703: Current learning rate: 0.00525
2024-02-08 03:56:55.715280: train_loss -0.578
2024-02-08 03:56:55.716974: val_loss -0.3841
2024-02-08 03:56:55.717453: Pseudo dice [0.8398, 0.8247, 0.7461, 0.8362, 0.8149]
2024-02-08 03:56:55.717885: Epoch time: 43.12 s
2024-02-08 03:56:55.718297: Yayy! New best EMA pseudo Dice: 0.8108
2024-02-08 03:56:57.350839: 
2024-02-08 03:56:57.352229: Epoch 282
2024-02-08 03:56:57.352872: Current learning rate: 0.00524
2024-02-08 03:57:40.469965: train_loss -0.5818
2024-02-08 03:57:40.471582: val_loss -0.3731
2024-02-08 03:57:40.472103: Pseudo dice [0.8365, 0.8098, 0.7419, 0.8338, 0.808]
2024-02-08 03:57:40.472552: Epoch time: 43.12 s
2024-02-08 03:57:41.538363: 
2024-02-08 03:57:41.539699: Epoch 283
2024-02-08 03:57:41.541099: Current learning rate: 0.00522
2024-02-08 03:58:24.609574: train_loss -0.5855
2024-02-08 03:58:24.611318: val_loss -0.3975
2024-02-08 03:58:24.611858: Pseudo dice [0.8411, 0.8207, 0.7503, 0.8387, 0.8129]
2024-02-08 03:58:24.612355: Epoch time: 43.07 s
2024-02-08 03:58:25.619941: 
2024-02-08 03:58:25.620970: Epoch 284
2024-02-08 03:58:25.622295: Current learning rate: 0.0052
2024-02-08 03:59:08.915526: train_loss -0.5843
2024-02-08 03:59:08.917244: val_loss -0.3912
2024-02-08 03:59:08.917757: Pseudo dice [0.8316, 0.8208, 0.7383, 0.8322, 0.8073]
2024-02-08 03:59:08.918230: Epoch time: 43.3 s
2024-02-08 03:59:09.936166: 
2024-02-08 03:59:09.937229: Epoch 285
2024-02-08 03:59:09.938268: Current learning rate: 0.00518
2024-02-08 03:59:52.962205: train_loss -0.5827
2024-02-08 03:59:52.963800: val_loss -0.3739
2024-02-08 03:59:52.964327: Pseudo dice [0.8355, 0.8174, 0.7487, 0.8365, 0.808]
2024-02-08 03:59:52.964812: Epoch time: 43.03 s
2024-02-08 03:59:54.021253: 
2024-02-08 03:59:54.022739: Epoch 286
2024-02-08 03:59:54.023879: Current learning rate: 0.00517
2024-02-08 04:00:37.117743: train_loss -0.585
2024-02-08 04:00:37.119375: val_loss -0.3856
2024-02-08 04:00:37.119920: Pseudo dice [0.8392, 0.8168, 0.7429, 0.8388, 0.8173]
2024-02-08 04:00:37.120436: Epoch time: 43.1 s
2024-02-08 04:00:38.198955: 
2024-02-08 04:00:38.200347: Epoch 287
2024-02-08 04:00:38.200845: Current learning rate: 0.00515
2024-02-08 04:01:21.140144: train_loss -0.5885
2024-02-08 04:01:21.141964: val_loss -0.4021
2024-02-08 04:01:21.142506: Pseudo dice [0.8418, 0.826, 0.7522, 0.8511, 0.8182]
2024-02-08 04:01:21.143011: Epoch time: 42.94 s
2024-02-08 04:01:21.143443: Yayy! New best EMA pseudo Dice: 0.8109
2024-02-08 04:01:22.710072: 
2024-02-08 04:01:22.712150: Epoch 288
2024-02-08 04:01:22.712740: Current learning rate: 0.00513
2024-02-08 04:02:05.954975: train_loss -0.585
2024-02-08 04:02:05.956480: val_loss -0.3939
2024-02-08 04:02:05.956984: Pseudo dice [0.8367, 0.8301, 0.7451, 0.8452, 0.8127]
2024-02-08 04:02:05.957475: Epoch time: 43.25 s
2024-02-08 04:02:05.957891: Yayy! New best EMA pseudo Dice: 0.8112
2024-02-08 04:02:07.319433: 
2024-02-08 04:02:07.320462: Epoch 289
2024-02-08 04:02:07.321432: Current learning rate: 0.00511
2024-02-08 04:02:50.562621: train_loss -0.5837
2024-02-08 04:02:50.564298: val_loss -0.3854
2024-02-08 04:02:50.564827: Pseudo dice [0.8385, 0.8225, 0.7484, 0.8407, 0.8121]
2024-02-08 04:02:50.565291: Epoch time: 43.24 s
2024-02-08 04:02:50.565708: Yayy! New best EMA pseudo Dice: 0.8113
2024-02-08 04:02:51.982036: 
2024-02-08 04:02:51.983545: Epoch 290
2024-02-08 04:02:51.984819: Current learning rate: 0.0051
2024-02-08 04:03:35.052203: train_loss -0.5842
2024-02-08 04:03:35.054095: val_loss -0.3981
2024-02-08 04:03:35.054929: Pseudo dice [0.8399, 0.827, 0.7546, 0.8572, 0.8158]
2024-02-08 04:03:35.055441: Epoch time: 43.07 s
2024-02-08 04:03:35.055952: Yayy! New best EMA pseudo Dice: 0.8121
2024-02-08 04:03:36.435723: 
2024-02-08 04:03:36.437446: Epoch 291
2024-02-08 04:03:36.439024: Current learning rate: 0.00508
2024-02-08 04:04:19.520671: train_loss -0.5834
2024-02-08 04:04:19.522118: val_loss -0.3887
2024-02-08 04:04:19.522602: Pseudo dice [0.8394, 0.8189, 0.7437, 0.8413, 0.8219]
2024-02-08 04:04:19.523072: Epoch time: 43.09 s
2024-02-08 04:04:19.523483: Yayy! New best EMA pseudo Dice: 0.8122
2024-02-08 04:04:21.208329: 
2024-02-08 04:04:21.209874: Epoch 292
2024-02-08 04:04:21.210485: Current learning rate: 0.00506
2024-02-08 04:05:04.575450: train_loss -0.5859
2024-02-08 04:05:04.576960: val_loss -0.3897
2024-02-08 04:05:04.577459: Pseudo dice [0.8398, 0.8214, 0.7412, 0.8513, 0.8153]
2024-02-08 04:05:04.577924: Epoch time: 43.37 s
2024-02-08 04:05:04.578389: Yayy! New best EMA pseudo Dice: 0.8123
2024-02-08 04:05:06.049704: 
2024-02-08 04:05:06.051433: Epoch 293
2024-02-08 04:05:06.052049: Current learning rate: 0.00504
2024-02-08 04:05:49.638199: train_loss -0.5789
2024-02-08 04:05:49.640538: val_loss -0.366
2024-02-08 04:05:49.641321: Pseudo dice [0.8308, 0.8137, 0.7388, 0.8358, 0.8128]
2024-02-08 04:05:49.641779: Epoch time: 43.59 s
2024-02-08 04:05:50.713032: 
2024-02-08 04:05:50.714692: Epoch 294
2024-02-08 04:05:50.716340: Current learning rate: 0.00502
2024-02-08 04:06:34.020340: train_loss -0.5881
2024-02-08 04:06:34.021892: val_loss -0.3951
2024-02-08 04:06:34.022426: Pseudo dice [0.841, 0.8245, 0.7498, 0.8473, 0.8229]
2024-02-08 04:06:34.022988: Epoch time: 43.31 s
2024-02-08 04:06:35.168994: 
2024-02-08 04:06:35.170478: Epoch 295
2024-02-08 04:06:35.171904: Current learning rate: 0.00501
2024-02-08 04:07:18.463710: train_loss -0.5805
2024-02-08 04:07:18.465140: val_loss -0.3849
2024-02-08 04:07:18.465595: Pseudo dice [0.838, 0.8163, 0.7466, 0.8319, 0.8111]
2024-02-08 04:07:18.466023: Epoch time: 43.3 s
2024-02-08 04:07:19.517197: 
2024-02-08 04:07:19.518315: Epoch 296
2024-02-08 04:07:19.519503: Current learning rate: 0.00499
2024-02-08 04:08:02.455644: train_loss -0.5837
2024-02-08 04:08:02.457054: val_loss -0.372
2024-02-08 04:08:02.457592: Pseudo dice [0.837, 0.8112, 0.7468, 0.8375, 0.8102]
2024-02-08 04:08:02.458164: Epoch time: 42.94 s
2024-02-08 04:08:03.745557: 
2024-02-08 04:08:03.746446: Epoch 297
2024-02-08 04:08:03.747266: Current learning rate: 0.00497
2024-02-08 04:08:46.956723: train_loss -0.5918
2024-02-08 04:08:46.958517: val_loss -0.3819
2024-02-08 04:08:46.959063: Pseudo dice [0.8362, 0.8165, 0.747, 0.8456, 0.7921]
2024-02-08 04:08:46.959561: Epoch time: 43.21 s
2024-02-08 04:08:48.067126: 
2024-02-08 04:08:48.068258: Epoch 298
2024-02-08 04:08:48.069237: Current learning rate: 0.00495
2024-02-08 04:09:31.063516: train_loss -0.5872
2024-02-08 04:09:31.064937: val_loss -0.4004
2024-02-08 04:09:31.065516: Pseudo dice [0.8403, 0.8264, 0.7553, 0.8504, 0.8167]
2024-02-08 04:09:31.065980: Epoch time: 43.0 s
2024-02-08 04:09:32.154677: 
2024-02-08 04:09:32.155581: Epoch 299
2024-02-08 04:09:32.156635: Current learning rate: 0.00494
2024-02-08 04:10:15.385675: train_loss -0.5798
2024-02-08 04:10:15.387150: val_loss -0.3959
2024-02-08 04:10:15.387626: Pseudo dice [0.8415, 0.8243, 0.7471, 0.847, 0.8182]
2024-02-08 04:10:15.388060: Epoch time: 43.23 s
2024-02-08 04:10:16.720813: 
2024-02-08 04:10:16.729993: Epoch 300
2024-02-08 04:10:16.731025: Current learning rate: 0.00492
2024-02-08 04:10:59.778948: train_loss -0.5828
2024-02-08 04:10:59.781023: val_loss -0.3886
2024-02-08 04:10:59.781572: Pseudo dice [0.84, 0.8254, 0.7479, 0.8434, 0.8096]
2024-02-08 04:10:59.782074: Epoch time: 43.06 s
2024-02-08 04:11:00.866977: 
2024-02-08 04:11:00.868178: Epoch 301
2024-02-08 04:11:00.869284: Current learning rate: 0.0049
2024-02-08 04:11:44.067998: train_loss -0.5879
2024-02-08 04:11:44.070229: val_loss -0.3752
2024-02-08 04:11:44.070865: Pseudo dice [0.8365, 0.8175, 0.7424, 0.8346, 0.8191]
2024-02-08 04:11:44.071434: Epoch time: 43.2 s
2024-02-08 04:11:45.196470: 
2024-02-08 04:11:45.197577: Epoch 302
2024-02-08 04:11:45.198838: Current learning rate: 0.00488
2024-02-08 04:12:28.298088: train_loss -0.5862
2024-02-08 04:12:28.299556: val_loss -0.3802
2024-02-08 04:12:28.300055: Pseudo dice [0.838, 0.8196, 0.7465, 0.8402, 0.8091]
2024-02-08 04:12:28.300509: Epoch time: 43.1 s
2024-02-08 04:12:29.584020: 
2024-02-08 04:12:29.585740: Epoch 303
2024-02-08 04:12:29.587464: Current learning rate: 0.00487
2024-02-08 04:13:12.786278: train_loss -0.5889
2024-02-08 04:13:12.788053: val_loss -0.3788
2024-02-08 04:13:12.788643: Pseudo dice [0.835, 0.8166, 0.7452, 0.8386, 0.8068]
2024-02-08 04:13:12.789136: Epoch time: 43.2 s
2024-02-08 04:13:13.836390: 
2024-02-08 04:13:13.838146: Epoch 304
2024-02-08 04:13:13.839677: Current learning rate: 0.00485
2024-02-08 04:13:56.822672: train_loss -0.5953
2024-02-08 04:13:56.838726: val_loss -0.3715
2024-02-08 04:13:56.839237: Pseudo dice [0.8395, 0.8162, 0.7452, 0.8412, 0.8048]
2024-02-08 04:13:56.839738: Epoch time: 42.99 s
2024-02-08 04:13:57.899846: 
2024-02-08 04:13:57.900928: Epoch 305
2024-02-08 04:13:57.901969: Current learning rate: 0.00483
2024-02-08 04:14:40.914061: train_loss -0.586
2024-02-08 04:14:40.915422: val_loss -0.3698
2024-02-08 04:14:40.915895: Pseudo dice [0.8358, 0.8199, 0.7443, 0.8327, 0.8103]
2024-02-08 04:14:40.916316: Epoch time: 43.02 s
2024-02-08 04:14:41.967854: 
2024-02-08 04:14:41.969010: Epoch 306
2024-02-08 04:14:41.970048: Current learning rate: 0.00481
2024-02-08 04:15:25.181535: train_loss -0.5813
2024-02-08 04:15:25.183252: val_loss -0.3854
2024-02-08 04:15:25.184004: Pseudo dice [0.8355, 0.8195, 0.7498, 0.8387, 0.8112]
2024-02-08 04:15:25.184504: Epoch time: 43.21 s
2024-02-08 04:15:26.239301: 
2024-02-08 04:15:26.240470: Epoch 307
2024-02-08 04:15:26.241764: Current learning rate: 0.00479
2024-02-08 04:16:09.373845: train_loss -0.5842
2024-02-08 04:16:09.375302: val_loss -0.3832
2024-02-08 04:16:09.375782: Pseudo dice [0.8362, 0.8233, 0.7446, 0.8374, 0.806]
2024-02-08 04:16:09.376221: Epoch time: 43.14 s
2024-02-08 04:16:10.560750: 
2024-02-08 04:16:10.561670: Epoch 308
2024-02-08 04:16:10.562603: Current learning rate: 0.00478
2024-02-08 04:16:53.891900: train_loss -0.5811
2024-02-08 04:16:53.893275: val_loss -0.3864
2024-02-08 04:16:53.893743: Pseudo dice [0.8379, 0.8143, 0.7464, 0.8334, 0.8156]
2024-02-08 04:16:53.894182: Epoch time: 43.33 s
2024-02-08 04:16:54.935286: 
2024-02-08 04:16:54.936582: Epoch 309
2024-02-08 04:16:54.937744: Current learning rate: 0.00476
2024-02-08 04:17:38.136741: train_loss -0.5863
2024-02-08 04:17:38.138087: val_loss -0.3806
2024-02-08 04:17:38.138790: Pseudo dice [0.8381, 0.8299, 0.7425, 0.8312, 0.8074]
2024-02-08 04:17:38.139246: Epoch time: 43.2 s
2024-02-08 04:17:39.193889: 
2024-02-08 04:17:39.194991: Epoch 310
2024-02-08 04:17:39.196116: Current learning rate: 0.00474
2024-02-08 04:18:22.319228: train_loss -0.5856
2024-02-08 04:18:22.320669: val_loss -0.3808
2024-02-08 04:18:22.321146: Pseudo dice [0.8389, 0.8162, 0.7465, 0.8334, 0.8102]
2024-02-08 04:18:22.321550: Epoch time: 43.13 s
2024-02-08 04:18:23.390211: 
2024-02-08 04:18:23.391798: Epoch 311
2024-02-08 04:18:23.393385: Current learning rate: 0.00472
2024-02-08 04:19:06.649698: train_loss -0.5887
2024-02-08 04:19:06.651302: val_loss -0.3806
2024-02-08 04:19:06.651824: Pseudo dice [0.8374, 0.8162, 0.7445, 0.8378, 0.8121]
2024-02-08 04:19:06.652370: Epoch time: 43.26 s
2024-02-08 04:19:07.709146: 
2024-02-08 04:19:07.710217: Epoch 312
2024-02-08 04:19:07.711205: Current learning rate: 0.00471
2024-02-08 04:19:50.756287: train_loss -0.5905
2024-02-08 04:19:50.758772: val_loss -0.3611
2024-02-08 04:19:50.759408: Pseudo dice [0.8329, 0.8192, 0.7391, 0.8317, 0.7999]
2024-02-08 04:19:50.760070: Epoch time: 43.05 s
2024-02-08 04:19:51.926329: 
2024-02-08 04:19:51.927590: Epoch 313
2024-02-08 04:19:51.928721: Current learning rate: 0.00469
2024-02-08 04:20:35.033254: train_loss -0.5816
2024-02-08 04:20:35.035013: val_loss -0.3716
2024-02-08 04:20:35.035534: Pseudo dice [0.8309, 0.8222, 0.7407, 0.8351, 0.7992]
2024-02-08 04:20:35.036016: Epoch time: 43.11 s
2024-02-08 04:20:36.071527: 
2024-02-08 04:20:36.072632: Epoch 314
2024-02-08 04:20:36.073897: Current learning rate: 0.00467
2024-02-08 04:21:19.293301: train_loss -0.5836
2024-02-08 04:21:19.294875: val_loss -0.3772
2024-02-08 04:21:19.295346: Pseudo dice [0.8349, 0.8171, 0.7454, 0.8421, 0.8106]
2024-02-08 04:21:19.295862: Epoch time: 43.22 s
2024-02-08 04:21:20.327734: 
2024-02-08 04:21:20.329818: Epoch 315
2024-02-08 04:21:20.331033: Current learning rate: 0.00465
2024-02-08 04:22:03.702725: train_loss -0.5922
2024-02-08 04:22:03.704541: val_loss -0.3769
2024-02-08 04:22:03.705080: Pseudo dice [0.8331, 0.8228, 0.7412, 0.832, 0.805]
2024-02-08 04:22:03.705603: Epoch time: 43.38 s
2024-02-08 04:22:04.749289: 
2024-02-08 04:22:04.750564: Epoch 316
2024-02-08 04:22:04.751724: Current learning rate: 0.00463
2024-02-08 04:22:47.942293: train_loss -0.5906
2024-02-08 04:22:47.943944: val_loss -0.395
2024-02-08 04:22:47.944433: Pseudo dice [0.8429, 0.8211, 0.7484, 0.8478, 0.8113]
2024-02-08 04:22:47.944921: Epoch time: 43.19 s
2024-02-08 04:22:48.990404: 
2024-02-08 04:22:48.991617: Epoch 317
2024-02-08 04:22:48.992865: Current learning rate: 0.00462
2024-02-08 04:23:32.015860: train_loss -0.5928
2024-02-08 04:23:32.017895: val_loss -0.3949
2024-02-08 04:23:32.018429: Pseudo dice [0.8401, 0.826, 0.7483, 0.8496, 0.8139]
2024-02-08 04:23:32.018960: Epoch time: 43.03 s
2024-02-08 04:23:33.174116: 
2024-02-08 04:23:33.175703: Epoch 318
2024-02-08 04:23:33.176337: Current learning rate: 0.0046
2024-02-08 04:24:16.393991: train_loss -0.5905
2024-02-08 04:24:16.395808: val_loss -0.3819
2024-02-08 04:24:16.396368: Pseudo dice [0.8377, 0.8271, 0.7485, 0.8518, 0.8057]
2024-02-08 04:24:16.396853: Epoch time: 43.22 s
2024-02-08 04:24:17.445559: 
2024-02-08 04:24:17.446923: Epoch 319
2024-02-08 04:24:17.447942: Current learning rate: 0.00458
2024-02-08 04:25:00.654975: train_loss -0.592
2024-02-08 04:25:00.656683: val_loss -0.374
2024-02-08 04:25:00.657357: Pseudo dice [0.8344, 0.8213, 0.7454, 0.8406, 0.8076]
2024-02-08 04:25:00.657799: Epoch time: 43.21 s
2024-02-08 04:25:01.694392: 
2024-02-08 04:25:01.695504: Epoch 320
2024-02-08 04:25:01.696748: Current learning rate: 0.00456
2024-02-08 04:25:44.815935: train_loss -0.6001
2024-02-08 04:25:44.817430: val_loss -0.3779
2024-02-08 04:25:44.817941: Pseudo dice [0.8323, 0.8183, 0.7451, 0.8425, 0.8095]
2024-02-08 04:25:44.818406: Epoch time: 43.12 s
2024-02-08 04:25:45.885698: 
2024-02-08 04:25:45.887468: Epoch 321
2024-02-08 04:25:45.889320: Current learning rate: 0.00454
2024-02-08 04:26:28.975199: train_loss -0.5945
2024-02-08 04:26:28.977161: val_loss -0.3788
2024-02-08 04:26:28.977646: Pseudo dice [0.8382, 0.8184, 0.748, 0.8327, 0.8185]
2024-02-08 04:26:28.978095: Epoch time: 43.09 s
2024-02-08 04:26:30.019150: 
2024-02-08 04:26:30.020263: Epoch 322
2024-02-08 04:26:30.021513: Current learning rate: 0.00453
2024-02-08 04:27:13.186744: train_loss -0.5941
2024-02-08 04:27:13.188753: val_loss -0.365
2024-02-08 04:27:13.189521: Pseudo dice [0.8367, 0.818, 0.7312, 0.8376, 0.8058]
2024-02-08 04:27:13.190048: Epoch time: 43.17 s
2024-02-08 04:27:14.390966: 
2024-02-08 04:27:14.392066: Epoch 323
2024-02-08 04:27:14.393232: Current learning rate: 0.00451
2024-02-08 04:27:57.439196: train_loss -0.594
2024-02-08 04:27:57.441218: val_loss -0.3722
2024-02-08 04:27:57.441746: Pseudo dice [0.8321, 0.822, 0.7409, 0.8298, 0.8158]
2024-02-08 04:27:57.442248: Epoch time: 43.05 s
2024-02-08 04:27:58.469869: 
2024-02-08 04:27:58.471069: Epoch 324
2024-02-08 04:27:58.472471: Current learning rate: 0.00449
2024-02-08 04:28:41.520230: train_loss -0.5914
2024-02-08 04:28:41.521570: val_loss -0.3705
2024-02-08 04:28:41.522241: Pseudo dice [0.8394, 0.8242, 0.7449, 0.836, 0.7974]
2024-02-08 04:28:41.522668: Epoch time: 43.05 s
2024-02-08 04:28:42.603148: 
2024-02-08 04:28:42.604355: Epoch 325
2024-02-08 04:28:42.605719: Current learning rate: 0.00447
2024-02-08 04:29:25.690629: train_loss -0.5976
2024-02-08 04:29:25.692379: val_loss -0.374
2024-02-08 04:29:25.692902: Pseudo dice [0.8393, 0.8126, 0.7456, 0.8461, 0.8148]
2024-02-08 04:29:25.693424: Epoch time: 43.09 s
2024-02-08 04:29:26.733617: 
2024-02-08 04:29:26.734633: Epoch 326
2024-02-08 04:29:26.735844: Current learning rate: 0.00446
2024-02-08 04:30:09.854631: train_loss -0.5988
2024-02-08 04:30:09.856489: val_loss -0.3834
2024-02-08 04:30:09.857069: Pseudo dice [0.8427, 0.8169, 0.7401, 0.8421, 0.8071]
2024-02-08 04:30:09.857558: Epoch time: 43.12 s
2024-02-08 04:30:10.890379: 
2024-02-08 04:30:10.891840: Epoch 327
2024-02-08 04:30:10.892427: Current learning rate: 0.00444
2024-02-08 04:30:54.083333: train_loss -0.5919
2024-02-08 04:30:54.085039: val_loss -0.371
2024-02-08 04:30:54.085554: Pseudo dice [0.836, 0.8141, 0.7443, 0.8415, 0.8116]
2024-02-08 04:30:54.086064: Epoch time: 43.19 s
2024-02-08 04:30:55.128009: 
2024-02-08 04:30:55.129048: Epoch 328
2024-02-08 04:30:55.130145: Current learning rate: 0.00442
2024-02-08 04:31:38.106492: train_loss -0.5977
2024-02-08 04:31:38.107952: val_loss -0.3628
2024-02-08 04:31:38.108444: Pseudo dice [0.83, 0.8195, 0.7413, 0.8317, 0.8041]
2024-02-08 04:31:38.108901: Epoch time: 42.98 s
2024-02-08 04:31:39.297374: 
2024-02-08 04:31:39.298759: Epoch 329
2024-02-08 04:31:39.299345: Current learning rate: 0.0044
2024-02-08 04:32:22.473232: train_loss -0.5955
2024-02-08 04:32:22.474695: val_loss -0.3638
2024-02-08 04:32:22.475171: Pseudo dice [0.8349, 0.8153, 0.7384, 0.8423, 0.8047]
2024-02-08 04:32:22.475609: Epoch time: 43.18 s
2024-02-08 04:32:23.502503: 
2024-02-08 04:32:23.503700: Epoch 330
2024-02-08 04:32:23.504776: Current learning rate: 0.00438
2024-02-08 04:33:06.657145: train_loss -0.5945
2024-02-08 04:33:06.658971: val_loss -0.3681
2024-02-08 04:33:06.659472: Pseudo dice [0.8372, 0.8223, 0.7392, 0.8457, 0.8074]
2024-02-08 04:33:06.660031: Epoch time: 43.16 s
2024-02-08 04:33:07.681854: 
2024-02-08 04:33:07.683113: Epoch 331
2024-02-08 04:33:07.684388: Current learning rate: 0.00437
2024-02-08 04:33:50.737069: train_loss -0.5973
2024-02-08 04:33:50.738561: val_loss -0.3841
2024-02-08 04:33:50.739093: Pseudo dice [0.8405, 0.8279, 0.7475, 0.8532, 0.8086]
2024-02-08 04:33:50.739559: Epoch time: 43.06 s
2024-02-08 04:33:51.775722: 
2024-02-08 04:33:51.778197: Epoch 332
2024-02-08 04:33:51.779484: Current learning rate: 0.00435
2024-02-08 04:34:34.984984: train_loss -0.5927
2024-02-08 04:34:34.986407: val_loss -0.3817
2024-02-08 04:34:34.986881: Pseudo dice [0.8356, 0.8223, 0.7431, 0.8403, 0.816]
2024-02-08 04:34:34.987328: Epoch time: 43.21 s
2024-02-08 04:34:36.039615: 
2024-02-08 04:34:36.040806: Epoch 333
2024-02-08 04:34:36.042083: Current learning rate: 0.00433
2024-02-08 04:35:19.085698: train_loss -0.5975
2024-02-08 04:35:19.088420: val_loss -0.385
2024-02-08 04:35:19.089030: Pseudo dice [0.8385, 0.8219, 0.7491, 0.8482, 0.8093]
2024-02-08 04:35:19.089536: Epoch time: 43.05 s
2024-02-08 04:35:20.260864: 
2024-02-08 04:35:20.262179: Epoch 334
2024-02-08 04:35:20.263223: Current learning rate: 0.00431
2024-02-08 04:36:03.501421: train_loss -0.5981
2024-02-08 04:36:03.503113: val_loss -0.3528
2024-02-08 04:36:03.503642: Pseudo dice [0.8306, 0.8117, 0.7398, 0.8361, 0.8099]
2024-02-08 04:36:03.504127: Epoch time: 43.24 s
2024-02-08 04:36:04.545902: 
2024-02-08 04:36:04.546937: Epoch 335
2024-02-08 04:36:04.548024: Current learning rate: 0.00429
2024-02-08 04:36:47.572456: train_loss -0.5951
2024-02-08 04:36:47.573815: val_loss -0.3633
2024-02-08 04:36:47.574265: Pseudo dice [0.8331, 0.8205, 0.7439, 0.8469, 0.8042]
2024-02-08 04:36:47.574719: Epoch time: 43.03 s
2024-02-08 04:36:48.632700: 
2024-02-08 04:36:48.634006: Epoch 336
2024-02-08 04:36:48.635316: Current learning rate: 0.00428
2024-02-08 04:37:31.776536: train_loss -0.5946
2024-02-08 04:37:31.778420: val_loss -0.38
2024-02-08 04:37:31.779001: Pseudo dice [0.8399, 0.8134, 0.7529, 0.841, 0.8129]
2024-02-08 04:37:31.779502: Epoch time: 43.14 s
2024-02-08 04:37:33.828318: 
2024-02-08 04:37:33.829710: Epoch 337
2024-02-08 04:37:33.831225: Current learning rate: 0.00426
2024-02-08 04:38:17.216578: train_loss -0.5904
2024-02-08 04:38:17.218125: val_loss -0.3577
2024-02-08 04:38:17.218606: Pseudo dice [0.8331, 0.8229, 0.7413, 0.8354, 0.8064]
2024-02-08 04:38:17.219029: Epoch time: 43.39 s
2024-02-08 04:38:18.291010: 
2024-02-08 04:38:18.292062: Epoch 338
2024-02-08 04:38:18.293197: Current learning rate: 0.00424
2024-02-08 04:39:01.404932: train_loss -0.5967
2024-02-08 04:39:01.406981: val_loss -0.3883
2024-02-08 04:39:01.407612: Pseudo dice [0.8395, 0.8198, 0.742, 0.8443, 0.808]
2024-02-08 04:39:01.408119: Epoch time: 43.12 s
2024-02-08 04:39:02.466105: 
2024-02-08 04:39:02.467437: Epoch 339
2024-02-08 04:39:02.469062: Current learning rate: 0.00422
2024-02-08 04:39:45.523915: train_loss -0.5997
2024-02-08 04:39:45.525510: val_loss -0.3836
2024-02-08 04:39:45.525999: Pseudo dice [0.8395, 0.8236, 0.7485, 0.8518, 0.8077]
2024-02-08 04:39:45.526417: Epoch time: 43.06 s
2024-02-08 04:39:46.719813: 
2024-02-08 04:39:46.720947: Epoch 340
2024-02-08 04:39:46.722194: Current learning rate: 0.0042
2024-02-08 04:40:29.713424: train_loss -0.6046
2024-02-08 04:40:29.714951: val_loss -0.3864
2024-02-08 04:40:29.715420: Pseudo dice [0.8402, 0.8255, 0.7517, 0.8516, 0.7997]
2024-02-08 04:40:29.716758: Epoch time: 42.99 s
2024-02-08 04:40:30.775682: 
2024-02-08 04:40:30.777073: Epoch 341
2024-02-08 04:40:30.778429: Current learning rate: 0.00419
2024-02-08 04:41:13.893344: train_loss -0.601
2024-02-08 04:41:13.894754: val_loss -0.3836
2024-02-08 04:41:13.895232: Pseudo dice [0.8412, 0.8188, 0.7468, 0.8388, 0.8127]
2024-02-08 04:41:13.895679: Epoch time: 43.12 s
2024-02-08 04:41:15.026579: 
2024-02-08 04:41:15.028208: Epoch 342
2024-02-08 04:41:15.029983: Current learning rate: 0.00417
2024-02-08 04:41:58.157007: train_loss -0.5955
2024-02-08 04:41:58.158688: val_loss -0.3795
2024-02-08 04:41:58.159201: Pseudo dice [0.8334, 0.8194, 0.7435, 0.8404, 0.8045]
2024-02-08 04:41:58.159812: Epoch time: 43.13 s
2024-02-08 04:41:59.221427: 
2024-02-08 04:41:59.222532: Epoch 343
2024-02-08 04:41:59.223789: Current learning rate: 0.00415
2024-02-08 04:42:42.298902: train_loss -0.5962
2024-02-08 04:42:42.300330: val_loss -0.3712
2024-02-08 04:42:42.300835: Pseudo dice [0.8383, 0.8165, 0.7423, 0.8372, 0.8093]
2024-02-08 04:42:42.301246: Epoch time: 43.08 s
2024-02-08 04:42:43.352394: 
2024-02-08 04:42:43.353435: Epoch 344
2024-02-08 04:42:43.354620: Current learning rate: 0.00413
2024-02-08 04:43:26.473590: train_loss -0.5885
2024-02-08 04:43:26.475164: val_loss -0.3758
2024-02-08 04:43:26.475681: Pseudo dice [0.8372, 0.8177, 0.7469, 0.838, 0.8149]
2024-02-08 04:43:26.476351: Epoch time: 43.12 s
2024-02-08 04:43:27.677298: 
2024-02-08 04:43:27.678407: Epoch 345
2024-02-08 04:43:27.679496: Current learning rate: 0.00411
2024-02-08 04:44:10.694415: train_loss -0.6002
2024-02-08 04:44:10.695897: val_loss -0.3746
2024-02-08 04:44:10.696418: Pseudo dice [0.8385, 0.8237, 0.7413, 0.8386, 0.8098]
2024-02-08 04:44:10.696864: Epoch time: 43.02 s
2024-02-08 04:44:11.749500: 
2024-02-08 04:44:11.751339: Epoch 346
2024-02-08 04:44:11.752687: Current learning rate: 0.0041
2024-02-08 04:44:55.052367: train_loss -0.6022
2024-02-08 04:44:55.053809: val_loss -0.3701
2024-02-08 04:44:55.054276: Pseudo dice [0.8322, 0.8232, 0.7427, 0.8396, 0.8138]
2024-02-08 04:44:55.054711: Epoch time: 43.3 s
2024-02-08 04:44:56.120771: 
2024-02-08 04:44:56.121855: Epoch 347
2024-02-08 04:44:56.122896: Current learning rate: 0.00408
2024-02-08 04:45:39.219275: train_loss -0.6013
2024-02-08 04:45:39.221208: val_loss -0.3738
2024-02-08 04:45:39.221743: Pseudo dice [0.8367, 0.8221, 0.7445, 0.8451, 0.8099]
2024-02-08 04:45:39.222272: Epoch time: 43.1 s
2024-02-08 04:45:40.488430: 
2024-02-08 04:45:40.489516: Epoch 348
2024-02-08 04:45:40.490429: Current learning rate: 0.00406
2024-02-08 04:46:23.700257: train_loss -0.5946
2024-02-08 04:46:23.701695: val_loss -0.3747
2024-02-08 04:46:23.702184: Pseudo dice [0.8364, 0.8241, 0.7411, 0.8361, 0.801]
2024-02-08 04:46:23.702626: Epoch time: 43.21 s
2024-02-08 04:46:24.770080: 
2024-02-08 04:46:24.771272: Epoch 349
2024-02-08 04:46:24.776099: Current learning rate: 0.00404
2024-02-08 04:47:07.990301: train_loss -0.5978
2024-02-08 04:47:07.992498: val_loss -0.3795
2024-02-08 04:47:07.993007: Pseudo dice [0.8401, 0.8174, 0.7454, 0.8393, 0.8032]
2024-02-08 04:47:07.993467: Epoch time: 43.22 s
2024-02-08 04:47:09.482446: 
2024-02-08 04:47:09.483605: Epoch 350
2024-02-08 04:47:09.484581: Current learning rate: 0.00402
2024-02-08 04:47:52.867657: train_loss -0.5993
2024-02-08 04:47:52.868987: val_loss -0.3627
2024-02-08 04:47:52.869455: Pseudo dice [0.8328, 0.818, 0.7451, 0.8346, 0.8063]
2024-02-08 04:47:52.869892: Epoch time: 43.39 s
2024-02-08 04:47:53.921789: 
2024-02-08 04:47:53.922884: Epoch 351
2024-02-08 04:47:53.924084: Current learning rate: 0.00401
2024-02-08 04:48:37.042208: train_loss -0.6002
2024-02-08 04:48:37.044091: val_loss -0.3847
2024-02-08 04:48:37.044595: Pseudo dice [0.8398, 0.8221, 0.743, 0.8445, 0.8199]
2024-02-08 04:48:37.045129: Epoch time: 43.12 s
2024-02-08 04:48:38.090390: 
2024-02-08 04:48:38.091528: Epoch 352
2024-02-08 04:48:38.093050: Current learning rate: 0.00399
2024-02-08 04:49:21.048154: train_loss -0.6038
2024-02-08 04:49:21.049833: val_loss -0.3832
2024-02-08 04:49:21.050329: Pseudo dice [0.8393, 0.8241, 0.7457, 0.84, 0.819]
2024-02-08 04:49:21.050809: Epoch time: 42.96 s
2024-02-08 04:49:22.145288: 
2024-02-08 04:49:22.146539: Epoch 353
2024-02-08 04:49:22.147834: Current learning rate: 0.00397
2024-02-08 04:50:05.475627: train_loss -0.6015
2024-02-08 04:50:05.477819: val_loss -0.397
2024-02-08 04:50:05.478328: Pseudo dice [0.8413, 0.8261, 0.7515, 0.8477, 0.8096]
2024-02-08 04:50:05.479019: Epoch time: 43.33 s
2024-02-08 04:50:06.528781: 
2024-02-08 04:50:06.530006: Epoch 354
2024-02-08 04:50:06.531214: Current learning rate: 0.00395
2024-02-08 04:50:49.535749: train_loss -0.6023
2024-02-08 04:50:49.537796: val_loss -0.3717
2024-02-08 04:50:49.538269: Pseudo dice [0.8379, 0.8191, 0.7355, 0.8448, 0.8222]
2024-02-08 04:50:49.539680: Epoch time: 43.01 s
2024-02-08 04:50:50.730529: 
2024-02-08 04:50:50.731779: Epoch 355
2024-02-08 04:50:50.732901: Current learning rate: 0.00393
2024-02-08 04:51:33.861881: train_loss -0.606
2024-02-08 04:51:33.863297: val_loss -0.3727
2024-02-08 04:51:33.863787: Pseudo dice [0.8352, 0.8204, 0.7435, 0.8405, 0.8167]
2024-02-08 04:51:33.864232: Epoch time: 43.13 s
2024-02-08 04:51:34.920532: 
2024-02-08 04:51:34.921818: Epoch 356
2024-02-08 04:51:34.922814: Current learning rate: 0.00391
2024-02-08 04:52:17.942946: train_loss -0.6048
2024-02-08 04:52:17.944458: val_loss -0.3682
2024-02-08 04:52:17.944969: Pseudo dice [0.8356, 0.8239, 0.7423, 0.8402, 0.8047]
2024-02-08 04:52:17.945438: Epoch time: 43.02 s
2024-02-08 04:52:19.021079: 
2024-02-08 04:52:19.022465: Epoch 357
2024-02-08 04:52:19.024757: Current learning rate: 0.0039
2024-02-08 04:53:02.304215: train_loss -0.608
2024-02-08 04:53:02.305647: val_loss -0.3764
2024-02-08 04:53:02.306138: Pseudo dice [0.8394, 0.823, 0.7495, 0.8403, 0.8141]
2024-02-08 04:53:02.306600: Epoch time: 43.28 s
2024-02-08 04:53:03.407963: 
2024-02-08 04:53:03.409401: Epoch 358
2024-02-08 04:53:03.410718: Current learning rate: 0.00388
2024-02-08 04:53:46.539057: train_loss -0.5999
2024-02-08 04:53:46.541034: val_loss -0.355
2024-02-08 04:53:46.541652: Pseudo dice [0.8309, 0.8161, 0.7376, 0.8407, 0.7968]
2024-02-08 04:53:46.542164: Epoch time: 43.13 s
2024-02-08 04:53:47.584282: 
2024-02-08 04:53:47.585355: Epoch 359
2024-02-08 04:53:47.586405: Current learning rate: 0.00386
2024-02-08 04:54:30.752064: train_loss -0.6022
2024-02-08 04:54:30.753571: val_loss -0.3815
2024-02-08 04:54:30.754059: Pseudo dice [0.8357, 0.8224, 0.7484, 0.8376, 0.8089]
2024-02-08 04:54:30.754535: Epoch time: 43.17 s
2024-02-08 04:54:31.955420: 
2024-02-08 04:54:31.957560: Epoch 360
2024-02-08 04:54:31.959709: Current learning rate: 0.00384
2024-02-08 04:55:15.048341: train_loss -0.6014
2024-02-08 04:55:15.049981: val_loss -0.3876
2024-02-08 04:55:15.050592: Pseudo dice [0.8401, 0.8205, 0.7495, 0.8463, 0.8061]
2024-02-08 04:55:15.051087: Epoch time: 43.09 s
2024-02-08 04:55:16.104893: 
2024-02-08 04:55:16.106015: Epoch 361
2024-02-08 04:55:16.107568: Current learning rate: 0.00382
2024-02-08 04:55:59.191808: train_loss -0.6038
2024-02-08 04:55:59.193223: val_loss -0.384
2024-02-08 04:55:59.193675: Pseudo dice [0.8429, 0.8224, 0.7563, 0.8433, 0.8087]
2024-02-08 04:55:59.194293: Epoch time: 43.09 s
2024-02-08 04:56:00.250374: 
2024-02-08 04:56:00.251845: Epoch 362
2024-02-08 04:56:00.252892: Current learning rate: 0.00381
2024-02-08 04:56:43.508745: train_loss -0.6014
2024-02-08 04:56:43.510221: val_loss -0.3863
2024-02-08 04:56:43.510697: Pseudo dice [0.8423, 0.825, 0.7473, 0.845, 0.8066]
2024-02-08 04:56:43.511157: Epoch time: 43.26 s
2024-02-08 04:56:44.573259: 
2024-02-08 04:56:44.574419: Epoch 363
2024-02-08 04:56:44.575411: Current learning rate: 0.00379
2024-02-08 04:57:27.818057: train_loss -0.6073
2024-02-08 04:57:27.820003: val_loss -0.3908
2024-02-08 04:57:27.820502: Pseudo dice [0.8419, 0.8244, 0.7515, 0.8444, 0.8137]
2024-02-08 04:57:27.820954: Epoch time: 43.25 s
2024-02-08 04:57:28.880733: 
2024-02-08 04:57:28.882744: Epoch 364
2024-02-08 04:57:28.884096: Current learning rate: 0.00377
2024-02-08 04:58:12.094106: train_loss -0.6089
2024-02-08 04:58:12.095550: val_loss -0.3875
2024-02-08 04:58:12.096040: Pseudo dice [0.8375, 0.8236, 0.7505, 0.8433, 0.8151]
2024-02-08 04:58:12.096500: Epoch time: 43.21 s
2024-02-08 04:58:13.296141: 
2024-02-08 04:58:13.297361: Epoch 365
2024-02-08 04:58:13.298840: Current learning rate: 0.00375
2024-02-08 04:58:56.428429: train_loss -0.6107
2024-02-08 04:58:56.429953: val_loss -0.3853
2024-02-08 04:58:56.430467: Pseudo dice [0.8384, 0.8176, 0.7503, 0.8462, 0.8145]
2024-02-08 04:58:56.430969: Epoch time: 43.13 s
2024-02-08 04:58:57.479327: 
2024-02-08 04:58:57.480466: Epoch 366
2024-02-08 04:58:57.481514: Current learning rate: 0.00373
2024-02-08 04:59:40.630461: train_loss -0.5949
2024-02-08 04:59:40.631997: val_loss -0.3932
2024-02-08 04:59:40.632523: Pseudo dice [0.8423, 0.8243, 0.7537, 0.8416, 0.8145]
2024-02-08 04:59:40.632979: Epoch time: 43.15 s
2024-02-08 04:59:40.633428: Yayy! New best EMA pseudo Dice: 0.8124
2024-02-08 04:59:42.036803: 
2024-02-08 04:59:42.038105: Epoch 367
2024-02-08 04:59:42.039287: Current learning rate: 0.00371
2024-02-08 05:00:25.546130: train_loss -0.5981
2024-02-08 05:00:25.547627: val_loss -0.388
2024-02-08 05:00:25.548253: Pseudo dice [0.8358, 0.8269, 0.755, 0.8526, 0.8043]
2024-02-08 05:00:25.548667: Epoch time: 43.51 s
2024-02-08 05:00:25.549118: Yayy! New best EMA pseudo Dice: 0.8127
2024-02-08 05:00:26.941330: 
2024-02-08 05:00:26.942479: Epoch 368
2024-02-08 05:00:26.943505: Current learning rate: 0.0037
2024-02-08 05:01:10.360196: train_loss -0.6021
2024-02-08 05:01:10.362443: val_loss -0.3897
2024-02-08 05:01:10.363317: Pseudo dice [0.839, 0.8195, 0.7434, 0.8421, 0.8157]
2024-02-08 05:01:10.363881: Epoch time: 43.42 s
2024-02-08 05:01:11.667885: 
2024-02-08 05:01:11.668942: Epoch 369
2024-02-08 05:01:11.669818: Current learning rate: 0.00368
2024-02-08 05:01:54.797055: train_loss -0.6012
2024-02-08 05:01:54.798576: val_loss -0.3751
2024-02-08 05:01:54.799136: Pseudo dice [0.8409, 0.8213, 0.7505, 0.844, 0.8082]
2024-02-08 05:01:54.799594: Epoch time: 43.13 s
2024-02-08 05:01:55.865537: 
2024-02-08 05:01:55.866822: Epoch 370
2024-02-08 05:01:55.867782: Current learning rate: 0.00366
2024-02-08 05:02:38.872809: train_loss -0.6084
2024-02-08 05:02:38.874794: val_loss -0.3803
2024-02-08 05:02:38.875322: Pseudo dice [0.8381, 0.8279, 0.7484, 0.842, 0.8087]
2024-02-08 05:02:38.875817: Epoch time: 43.01 s
2024-02-08 05:02:38.876281: Yayy! New best EMA pseudo Dice: 0.8127
2024-02-08 05:02:40.224367: 
2024-02-08 05:02:40.225965: Epoch 371
2024-02-08 05:02:40.227213: Current learning rate: 0.00364
2024-02-08 05:03:23.303274: train_loss -0.6054
2024-02-08 05:03:23.304979: val_loss -0.3685
2024-02-08 05:03:23.305866: Pseudo dice [0.8374, 0.8167, 0.7464, 0.8381, 0.8122]
2024-02-08 05:03:23.306458: Epoch time: 43.08 s
2024-02-08 05:03:24.366608: 
2024-02-08 05:03:24.367733: Epoch 372
2024-02-08 05:03:24.369016: Current learning rate: 0.00362
2024-02-08 05:04:07.383099: train_loss -0.6116
2024-02-08 05:04:07.384677: val_loss -0.3728
2024-02-08 05:04:07.385172: Pseudo dice [0.8359, 0.8194, 0.7409, 0.8364, 0.8066]
2024-02-08 05:04:07.385631: Epoch time: 43.02 s
2024-02-08 05:04:08.448915: 
2024-02-08 05:04:08.450295: Epoch 373
2024-02-08 05:04:08.451901: Current learning rate: 0.0036
2024-02-08 05:04:51.762862: train_loss -0.6076
2024-02-08 05:04:51.764450: val_loss -0.3639
2024-02-08 05:04:51.764935: Pseudo dice [0.8363, 0.8144, 0.7399, 0.8303, 0.8116]
2024-02-08 05:04:51.765378: Epoch time: 43.32 s
2024-02-08 05:04:52.948862: 
2024-02-08 05:04:52.950557: Epoch 374
2024-02-08 05:04:52.951267: Current learning rate: 0.00359
2024-02-08 05:05:36.155822: train_loss -0.6099
2024-02-08 05:05:36.157405: val_loss -0.3908
2024-02-08 05:05:36.158065: Pseudo dice [0.8418, 0.8262, 0.7504, 0.845, 0.8181]
2024-02-08 05:05:36.158571: Epoch time: 43.21 s
2024-02-08 05:05:37.201057: 
2024-02-08 05:05:37.202168: Epoch 375
2024-02-08 05:05:37.203435: Current learning rate: 0.00357
2024-02-08 05:06:20.530333: train_loss -0.609
2024-02-08 05:06:20.532265: val_loss -0.3627
2024-02-08 05:06:20.532828: Pseudo dice [0.8348, 0.8252, 0.7419, 0.8392, 0.8059]
2024-02-08 05:06:20.533325: Epoch time: 43.33 s
2024-02-08 05:06:21.611639: 
2024-02-08 05:06:21.612889: Epoch 376
2024-02-08 05:06:21.613861: Current learning rate: 0.00355
2024-02-08 05:07:04.646564: train_loss -0.6125
2024-02-08 05:07:04.647947: val_loss -0.3786
2024-02-08 05:07:04.648432: Pseudo dice [0.8403, 0.8188, 0.7519, 0.8476, 0.8096]
2024-02-08 05:07:04.648879: Epoch time: 43.04 s
2024-02-08 05:07:05.747032: 
2024-02-08 05:07:05.748056: Epoch 377
2024-02-08 05:07:05.748989: Current learning rate: 0.00353
2024-02-08 05:07:48.725498: train_loss -0.6074
2024-02-08 05:07:48.727904: val_loss -0.3749
2024-02-08 05:07:48.728473: Pseudo dice [0.8381, 0.8191, 0.7488, 0.8413, 0.8145]
2024-02-08 05:07:48.728992: Epoch time: 42.98 s
2024-02-08 05:07:49.818407: 
2024-02-08 05:07:49.819666: Epoch 378
2024-02-08 05:07:49.820986: Current learning rate: 0.00351
2024-02-08 05:08:32.902962: train_loss -0.6116
2024-02-08 05:08:32.904813: val_loss -0.381
2024-02-08 05:08:32.905314: Pseudo dice [0.8396, 0.8254, 0.7458, 0.8391, 0.8079]
2024-02-08 05:08:32.905989: Epoch time: 43.09 s
2024-02-08 05:08:33.962444: 
2024-02-08 05:08:33.963524: Epoch 379
2024-02-08 05:08:33.964461: Current learning rate: 0.00349
2024-02-08 05:09:17.000979: train_loss -0.6051
2024-02-08 05:09:17.002430: val_loss -0.3734
2024-02-08 05:09:17.003958: Pseudo dice [0.8404, 0.8141, 0.7476, 0.8364, 0.8118]
2024-02-08 05:09:17.004371: Epoch time: 43.04 s
2024-02-08 05:09:18.213720: 
2024-02-08 05:09:18.215187: Epoch 380
2024-02-08 05:09:18.216293: Current learning rate: 0.00348
2024-02-08 05:10:01.387204: train_loss -0.6107
2024-02-08 05:10:01.388643: val_loss -0.3689
2024-02-08 05:10:01.389122: Pseudo dice [0.8375, 0.8192, 0.7449, 0.8395, 0.8039]
2024-02-08 05:10:01.389559: Epoch time: 43.17 s
2024-02-08 05:10:02.438215: 
2024-02-08 05:10:02.439327: Epoch 381
2024-02-08 05:10:02.440427: Current learning rate: 0.00346
2024-02-08 05:10:45.547072: train_loss -0.6121
2024-02-08 05:10:45.548480: val_loss -0.3908
2024-02-08 05:10:45.549011: Pseudo dice [0.8394, 0.8337, 0.7442, 0.8477, 0.8166]
2024-02-08 05:10:45.549444: Epoch time: 43.11 s
2024-02-08 05:10:46.626260: 
2024-02-08 05:10:46.627389: Epoch 382
2024-02-08 05:10:46.628467: Current learning rate: 0.00344
2024-02-08 05:11:29.598744: train_loss -0.6047
2024-02-08 05:11:29.600116: val_loss -0.3584
2024-02-08 05:11:29.600560: Pseudo dice [0.8319, 0.8157, 0.7439, 0.8341, 0.8105]
2024-02-08 05:11:29.601003: Epoch time: 42.97 s
2024-02-08 05:11:30.677973: 
2024-02-08 05:11:30.679127: Epoch 383
2024-02-08 05:11:30.680111: Current learning rate: 0.00342
2024-02-08 05:12:13.616971: train_loss -0.6096
2024-02-08 05:12:13.618463: val_loss -0.3705
2024-02-08 05:12:13.618944: Pseudo dice [0.8394, 0.821, 0.7492, 0.8481, 0.814]
2024-02-08 05:12:13.619370: Epoch time: 42.94 s
2024-02-08 05:12:14.695326: 
2024-02-08 05:12:14.696450: Epoch 384
2024-02-08 05:12:14.697479: Current learning rate: 0.0034
2024-02-08 05:12:57.767017: train_loss -0.6118
2024-02-08 05:12:57.769449: val_loss -0.3732
2024-02-08 05:12:57.770181: Pseudo dice [0.8348, 0.8236, 0.7457, 0.8391, 0.8125]
2024-02-08 05:12:57.770829: Epoch time: 43.07 s
2024-02-08 05:12:59.185188: 
2024-02-08 05:12:59.186443: Epoch 385
2024-02-08 05:12:59.187556: Current learning rate: 0.00338
2024-02-08 05:13:42.480258: train_loss -0.6111
2024-02-08 05:13:42.481853: val_loss -0.3585
2024-02-08 05:13:42.482543: Pseudo dice [0.8349, 0.8216, 0.7408, 0.8393, 0.7993]
2024-02-08 05:13:42.483260: Epoch time: 43.3 s
2024-02-08 05:13:43.583462: 
2024-02-08 05:13:43.584581: Epoch 386
2024-02-08 05:13:43.585996: Current learning rate: 0.00337
2024-02-08 05:14:26.788925: train_loss -0.606
2024-02-08 05:14:26.790432: val_loss -0.3872
2024-02-08 05:14:26.790921: Pseudo dice [0.8374, 0.8264, 0.7498, 0.8413, 0.8104]
2024-02-08 05:14:26.791350: Epoch time: 43.21 s
2024-02-08 05:14:27.902893: 
2024-02-08 05:14:27.904254: Epoch 387
2024-02-08 05:14:27.905263: Current learning rate: 0.00335
2024-02-08 05:15:10.938518: train_loss -0.6073
2024-02-08 05:15:10.939975: val_loss -0.3737
2024-02-08 05:15:10.940443: Pseudo dice [0.8364, 0.8221, 0.7447, 0.8411, 0.8096]
2024-02-08 05:15:10.940875: Epoch time: 43.04 s
2024-02-08 05:15:12.030114: 
2024-02-08 05:15:12.031772: Epoch 388
2024-02-08 05:15:12.033212: Current learning rate: 0.00333
2024-02-08 05:15:55.186472: train_loss -0.6131
2024-02-08 05:15:55.188005: val_loss -0.3911
2024-02-08 05:15:55.188526: Pseudo dice [0.8441, 0.8218, 0.7514, 0.8508, 0.8112]
2024-02-08 05:15:55.188982: Epoch time: 43.16 s
2024-02-08 05:15:56.283819: 
2024-02-08 05:15:56.284947: Epoch 389
2024-02-08 05:15:56.286299: Current learning rate: 0.00331
2024-02-08 05:16:39.547133: train_loss -0.6128
2024-02-08 05:16:39.548522: val_loss -0.363
2024-02-08 05:16:39.548944: Pseudo dice [0.8331, 0.8237, 0.7342, 0.8417, 0.8097]
2024-02-08 05:16:39.549386: Epoch time: 43.26 s
2024-02-08 05:16:40.850211: 
2024-02-08 05:16:40.851265: Epoch 390
2024-02-08 05:16:40.852233: Current learning rate: 0.00329
2024-02-08 05:17:24.100960: train_loss -0.6144
2024-02-08 05:17:24.102472: val_loss -0.3655
2024-02-08 05:17:24.102980: Pseudo dice [0.8308, 0.8219, 0.7475, 0.8376, 0.8072]
2024-02-08 05:17:24.103422: Epoch time: 43.25 s
2024-02-08 05:17:25.228712: 
2024-02-08 05:17:25.229936: Epoch 391
2024-02-08 05:17:25.231106: Current learning rate: 0.00327
2024-02-08 05:18:08.412646: train_loss -0.6132
2024-02-08 05:18:08.414085: val_loss -0.3794
2024-02-08 05:18:08.414575: Pseudo dice [0.8368, 0.8237, 0.7419, 0.8429, 0.8071]
2024-02-08 05:18:08.415157: Epoch time: 43.19 s
2024-02-08 05:18:09.494823: 
2024-02-08 05:18:09.495859: Epoch 392
2024-02-08 05:18:09.497090: Current learning rate: 0.00325
2024-02-08 05:18:52.446001: train_loss -0.6094
2024-02-08 05:18:52.447502: val_loss -0.3834
2024-02-08 05:18:52.447994: Pseudo dice [0.8415, 0.8209, 0.7455, 0.8364, 0.8201]
2024-02-08 05:18:52.448471: Epoch time: 42.95 s
2024-02-08 05:18:53.539594: 
2024-02-08 05:18:53.541016: Epoch 393
2024-02-08 05:18:53.542352: Current learning rate: 0.00324
2024-02-08 05:19:36.916029: train_loss -0.6164
2024-02-08 05:19:36.917454: val_loss -0.3849
2024-02-08 05:19:36.917914: Pseudo dice [0.8394, 0.8181, 0.7482, 0.8469, 0.8236]
2024-02-08 05:19:36.918382: Epoch time: 43.38 s
2024-02-08 05:19:38.027463: 
2024-02-08 05:19:38.028620: Epoch 394
2024-02-08 05:19:38.029795: Current learning rate: 0.00322
2024-02-08 05:20:21.225937: train_loss -0.611
2024-02-08 05:20:21.227856: val_loss -0.3938
2024-02-08 05:20:21.228397: Pseudo dice [0.8419, 0.8255, 0.7527, 0.848, 0.8098]
2024-02-08 05:20:21.228871: Epoch time: 43.2 s
2024-02-08 05:20:22.345954: 
2024-02-08 05:20:22.347033: Epoch 395
2024-02-08 05:20:22.347979: Current learning rate: 0.0032
2024-02-08 05:21:05.501971: train_loss -0.6111
2024-02-08 05:21:05.503423: val_loss -0.374
2024-02-08 05:21:05.503940: Pseudo dice [0.8373, 0.822, 0.7423, 0.845, 0.806]
2024-02-08 05:21:05.504352: Epoch time: 43.16 s
2024-02-08 05:21:06.606568: 
2024-02-08 05:21:06.607516: Epoch 396
2024-02-08 05:21:06.608323: Current learning rate: 0.00318
2024-02-08 05:21:49.730235: train_loss -0.6091
2024-02-08 05:21:49.732003: val_loss -0.3791
2024-02-08 05:21:49.732574: Pseudo dice [0.8371, 0.8235, 0.7416, 0.8414, 0.8051]
2024-02-08 05:21:49.733032: Epoch time: 43.12 s
2024-02-08 05:21:50.919603: 
2024-02-08 05:21:50.920948: Epoch 397
2024-02-08 05:21:50.922190: Current learning rate: 0.00316
2024-02-08 05:22:34.051385: train_loss -0.6132
2024-02-08 05:22:34.052875: val_loss -0.3695
2024-02-08 05:22:34.053417: Pseudo dice [0.8309, 0.8187, 0.7483, 0.8396, 0.8085]
2024-02-08 05:22:34.053867: Epoch time: 43.13 s
2024-02-08 05:22:35.162380: 
2024-02-08 05:22:35.164925: Epoch 398
2024-02-08 05:22:35.166654: Current learning rate: 0.00314
2024-02-08 05:23:18.231016: train_loss -0.6194
2024-02-08 05:23:18.232768: val_loss -0.3816
2024-02-08 05:23:18.233297: Pseudo dice [0.8378, 0.8201, 0.7503, 0.8388, 0.812]
2024-02-08 05:23:18.233787: Epoch time: 43.07 s
2024-02-08 05:23:19.354739: 
2024-02-08 05:23:19.356057: Epoch 399
2024-02-08 05:23:19.357581: Current learning rate: 0.00312
2024-02-08 05:24:02.600301: train_loss -0.6112
2024-02-08 05:24:02.601857: val_loss -0.3624
2024-02-08 05:24:02.602590: Pseudo dice [0.8349, 0.821, 0.7376, 0.8373, 0.81]
2024-02-08 05:24:02.603042: Epoch time: 43.25 s
2024-02-08 05:24:04.338937: 
2024-02-08 05:24:04.339883: Epoch 400
2024-02-08 05:24:04.340422: Current learning rate: 0.00311
2024-02-08 05:24:47.749354: train_loss -0.617
2024-02-08 05:24:47.751216: val_loss -0.3825
2024-02-08 05:24:47.751766: Pseudo dice [0.8394, 0.8186, 0.7443, 0.8375, 0.8002]
2024-02-08 05:24:47.752228: Epoch time: 43.41 s
2024-02-08 05:24:48.905196: 
2024-02-08 05:24:48.906276: Epoch 401
2024-02-08 05:24:48.907510: Current learning rate: 0.00309
2024-02-08 05:25:31.887185: train_loss -0.6146
2024-02-08 05:25:31.888849: val_loss -0.3833
2024-02-08 05:25:31.889315: Pseudo dice [0.8429, 0.8238, 0.7517, 0.8478, 0.8223]
2024-02-08 05:25:31.890244: Epoch time: 42.98 s
2024-02-08 05:25:33.017164: 
2024-02-08 05:25:33.018147: Epoch 402
2024-02-08 05:25:33.019242: Current learning rate: 0.00307
2024-02-08 05:26:16.050539: train_loss -0.6125
2024-02-08 05:26:16.052479: val_loss -0.3618
2024-02-08 05:26:16.053003: Pseudo dice [0.835, 0.8169, 0.7365, 0.8326, 0.8123]
2024-02-08 05:26:16.053508: Epoch time: 43.03 s
2024-02-08 05:26:17.133616: 
2024-02-08 05:26:17.134710: Epoch 403
2024-02-08 05:26:17.136114: Current learning rate: 0.00305
2024-02-08 05:27:00.276063: train_loss -0.6097
2024-02-08 05:27:00.277469: val_loss -0.3887
2024-02-08 05:27:00.278051: Pseudo dice [0.8389, 0.8206, 0.7487, 0.8376, 0.8029]
2024-02-08 05:27:00.278721: Epoch time: 43.14 s
2024-02-08 05:27:01.415596: 
2024-02-08 05:27:01.416681: Epoch 404
2024-02-08 05:27:01.417877: Current learning rate: 0.00303
2024-02-08 05:27:44.623011: train_loss -0.6169
2024-02-08 05:27:44.624584: val_loss -0.3853
2024-02-08 05:27:44.625080: Pseudo dice [0.8385, 0.821, 0.7467, 0.8483, 0.8142]
2024-02-08 05:27:44.625552: Epoch time: 43.21 s
2024-02-08 05:27:45.702798: 
2024-02-08 05:27:45.703842: Epoch 405
2024-02-08 05:27:45.704999: Current learning rate: 0.00301
2024-02-08 05:28:29.037154: train_loss -0.6153
2024-02-08 05:28:29.039197: val_loss -0.3649
2024-02-08 05:28:29.039783: Pseudo dice [0.8353, 0.8233, 0.742, 0.8377, 0.8145]
2024-02-08 05:28:29.040280: Epoch time: 43.34 s
2024-02-08 05:28:30.158578: 
2024-02-08 05:28:30.159662: Epoch 406
2024-02-08 05:28:30.160692: Current learning rate: 0.00299
2024-02-08 05:29:13.282310: train_loss -0.6113
2024-02-08 05:29:13.284601: val_loss -0.3709
2024-02-08 05:29:13.285178: Pseudo dice [0.8382, 0.8192, 0.7475, 0.8372, 0.8169]
2024-02-08 05:29:13.285754: Epoch time: 43.13 s
2024-02-08 05:29:14.389201: 
2024-02-08 05:29:14.390305: Epoch 407
2024-02-08 05:29:14.391292: Current learning rate: 0.00297
2024-02-08 05:29:57.751053: train_loss -0.6176
2024-02-08 05:29:57.752563: val_loss -0.3773
2024-02-08 05:29:57.753057: Pseudo dice [0.8413, 0.8159, 0.7562, 0.8481, 0.8094]
2024-02-08 05:29:57.753550: Epoch time: 43.36 s
2024-02-08 05:29:58.849350: 
2024-02-08 05:29:58.850343: Epoch 408
2024-02-08 05:29:58.851358: Current learning rate: 0.00296
2024-02-08 05:30:41.180337: train_loss -0.6182
2024-02-08 05:30:41.181788: val_loss -0.387
2024-02-08 05:30:41.182286: Pseudo dice [0.8403, 0.8265, 0.7446, 0.8459, 0.8099]
2024-02-08 05:30:41.182892: Epoch time: 42.33 s
2024-02-08 05:30:42.286106: 
2024-02-08 05:30:42.287426: Epoch 409
2024-02-08 05:30:42.288587: Current learning rate: 0.00294
2024-02-08 05:31:25.596090: train_loss -0.6163
2024-02-08 05:31:25.597845: val_loss -0.3659
2024-02-08 05:31:25.598372: Pseudo dice [0.8373, 0.8134, 0.7468, 0.8366, 0.8019]
2024-02-08 05:31:25.598929: Epoch time: 43.31 s
2024-02-08 05:31:26.987748: 
2024-02-08 05:31:26.988960: Epoch 410
2024-02-08 05:31:26.989961: Current learning rate: 0.00292
2024-02-08 05:32:10.339518: train_loss -0.6202
2024-02-08 05:32:10.340915: val_loss -0.3731
2024-02-08 05:32:10.341377: Pseudo dice [0.8395, 0.8163, 0.743, 0.8474, 0.811]
2024-02-08 05:32:10.341831: Epoch time: 43.35 s
2024-02-08 05:32:11.395859: 
2024-02-08 05:32:11.397399: Epoch 411
2024-02-08 05:32:11.398006: Current learning rate: 0.0029
2024-02-08 05:32:54.717797: train_loss -0.6179
2024-02-08 05:32:54.719441: val_loss -0.3737
2024-02-08 05:32:54.720514: Pseudo dice [0.8413, 0.8156, 0.7454, 0.8411, 0.8011]
2024-02-08 05:32:54.720956: Epoch time: 43.32 s
2024-02-08 05:32:55.774977: 
2024-02-08 05:32:55.777657: Epoch 412
2024-02-08 05:32:55.779146: Current learning rate: 0.00288
2024-02-08 05:33:39.169561: train_loss -0.6119
2024-02-08 05:33:39.170935: val_loss -0.3635
2024-02-08 05:33:39.171442: Pseudo dice [0.8374, 0.8128, 0.7451, 0.8326, 0.8082]
2024-02-08 05:33:39.171896: Epoch time: 43.4 s
2024-02-08 05:33:40.193608: 
2024-02-08 05:33:40.194701: Epoch 413
2024-02-08 05:33:40.195786: Current learning rate: 0.00286
2024-02-08 05:34:23.447299: train_loss -0.615
2024-02-08 05:34:23.448696: val_loss -0.3933
2024-02-08 05:34:23.449193: Pseudo dice [0.8434, 0.8245, 0.7521, 0.8444, 0.82]
2024-02-08 05:34:23.449849: Epoch time: 43.25 s
2024-02-08 05:34:24.518984: 
2024-02-08 05:34:24.519990: Epoch 414
2024-02-08 05:34:24.521273: Current learning rate: 0.00284
2024-02-08 05:35:07.865202: train_loss -0.6147
2024-02-08 05:35:07.867362: val_loss -0.3659
2024-02-08 05:35:07.868106: Pseudo dice [0.8321, 0.819, 0.7468, 0.8348, 0.8061]
2024-02-08 05:35:07.868584: Epoch time: 43.35 s
2024-02-08 05:35:08.979610: 
2024-02-08 05:35:08.985867: Epoch 415
2024-02-08 05:35:08.987037: Current learning rate: 0.00282
2024-02-08 05:35:52.378680: train_loss -0.6174
2024-02-08 05:35:52.380210: val_loss -0.3871
2024-02-08 05:35:52.380765: Pseudo dice [0.8439, 0.8182, 0.7516, 0.849, 0.8223]
2024-02-08 05:35:52.381207: Epoch time: 43.4 s
2024-02-08 05:35:53.565265: 
2024-02-08 05:35:53.566250: Epoch 416
2024-02-08 05:35:53.567435: Current learning rate: 0.00281
2024-02-08 05:36:36.783762: train_loss -0.6181
2024-02-08 05:36:36.785215: val_loss -0.3758
2024-02-08 05:36:36.785735: Pseudo dice [0.8369, 0.8285, 0.7466, 0.8453, 0.8194]
2024-02-08 05:36:36.786186: Epoch time: 43.22 s
2024-02-08 05:36:37.870752: 
2024-02-08 05:36:37.871856: Epoch 417
2024-02-08 05:36:37.872991: Current learning rate: 0.00279
2024-02-08 05:37:21.211292: train_loss -0.6144
2024-02-08 05:37:21.212828: val_loss -0.3623
2024-02-08 05:37:21.213339: Pseudo dice [0.8326, 0.8161, 0.7437, 0.838, 0.8031]
2024-02-08 05:37:21.213824: Epoch time: 43.34 s
2024-02-08 05:37:22.251429: 
2024-02-08 05:37:22.252569: Epoch 418
2024-02-08 05:37:22.253672: Current learning rate: 0.00277
2024-02-08 05:38:05.573807: train_loss -0.6167
2024-02-08 05:38:05.575774: val_loss -0.364
2024-02-08 05:38:05.576323: Pseudo dice [0.8367, 0.8206, 0.7395, 0.8416, 0.8113]
2024-02-08 05:38:05.577084: Epoch time: 43.32 s
2024-02-08 05:38:06.623962: 
2024-02-08 05:38:06.625417: Epoch 419
2024-02-08 05:38:06.626046: Current learning rate: 0.00275
2024-02-08 05:38:49.950452: train_loss -0.6197
2024-02-08 05:38:49.951813: val_loss -0.3525
2024-02-08 05:38:49.952314: Pseudo dice [0.8322, 0.8196, 0.743, 0.8358, 0.8038]
2024-02-08 05:38:49.952773: Epoch time: 43.33 s
2024-02-08 05:38:51.015318: 
2024-02-08 05:38:51.016874: Epoch 420
2024-02-08 05:38:51.018350: Current learning rate: 0.00273
2024-02-08 05:39:34.359377: train_loss -0.6201
2024-02-08 05:39:34.360783: val_loss -0.3784
2024-02-08 05:39:34.361264: Pseudo dice [0.8402, 0.8219, 0.7491, 0.8432, 0.818]
2024-02-08 05:39:34.361699: Epoch time: 43.35 s
2024-02-08 05:39:35.411424: 
2024-02-08 05:39:35.412519: Epoch 421
2024-02-08 05:39:35.413610: Current learning rate: 0.00271
2024-02-08 05:40:18.635502: train_loss -0.6193
2024-02-08 05:40:18.637175: val_loss -0.3847
2024-02-08 05:40:18.637700: Pseudo dice [0.8391, 0.8242, 0.7507, 0.8332, 0.8067]
2024-02-08 05:40:18.638166: Epoch time: 43.23 s
2024-02-08 05:40:19.857289: 
2024-02-08 05:40:19.858277: Epoch 422
2024-02-08 05:40:19.859233: Current learning rate: 0.00269
2024-02-08 05:41:02.954636: train_loss -0.6155
2024-02-08 05:41:02.956006: val_loss -0.3767
2024-02-08 05:41:02.956457: Pseudo dice [0.8396, 0.8219, 0.7526, 0.8387, 0.8117]
2024-02-08 05:41:02.956865: Epoch time: 43.1 s
2024-02-08 05:41:03.972831: 
2024-02-08 05:41:03.973837: Epoch 423
2024-02-08 05:41:03.989915: Current learning rate: 0.00267
2024-02-08 05:41:47.314574: train_loss -0.6159
2024-02-08 05:41:47.316020: val_loss -0.3786
2024-02-08 05:41:47.316608: Pseudo dice [0.8425, 0.8226, 0.7502, 0.8463, 0.8097]
2024-02-08 05:41:47.317168: Epoch time: 43.34 s
2024-02-08 05:41:48.334361: 
2024-02-08 05:41:48.335531: Epoch 424
2024-02-08 05:41:48.336558: Current learning rate: 0.00265
2024-02-08 05:42:31.542649: train_loss -0.6193
2024-02-08 05:42:31.544027: val_loss -0.3654
2024-02-08 05:42:31.544478: Pseudo dice [0.8378, 0.8185, 0.7467, 0.8404, 0.8155]
2024-02-08 05:42:31.546206: Epoch time: 43.21 s
2024-02-08 05:42:32.643566: 
2024-02-08 05:42:32.689688: Epoch 425
2024-02-08 05:42:32.734083: Current learning rate: 0.00264
2024-02-08 05:43:16.128637: train_loss -0.6245
2024-02-08 05:43:16.130429: val_loss -0.3638
2024-02-08 05:43:16.130998: Pseudo dice [0.8373, 0.8203, 0.7475, 0.8391, 0.8114]
2024-02-08 05:43:16.131476: Epoch time: 43.49 s
2024-02-08 05:43:17.157694: 
2024-02-08 05:43:17.158891: Epoch 426
2024-02-08 05:43:17.159967: Current learning rate: 0.00262
2024-02-08 05:44:00.254303: train_loss -0.6254
2024-02-08 05:44:00.255677: val_loss -0.3489
2024-02-08 05:44:00.256159: Pseudo dice [0.8353, 0.8127, 0.743, 0.8371, 0.811]
2024-02-08 05:44:00.256601: Epoch time: 43.1 s
2024-02-08 05:44:01.524258: 
2024-02-08 05:44:01.525400: Epoch 427
2024-02-08 05:44:01.526651: Current learning rate: 0.0026
2024-02-08 05:44:44.819570: train_loss -0.6216
2024-02-08 05:44:44.821784: val_loss -0.3847
2024-02-08 05:44:44.822594: Pseudo dice [0.8425, 0.8245, 0.7483, 0.8451, 0.8167]
2024-02-08 05:44:44.823136: Epoch time: 43.3 s
2024-02-08 05:44:45.841400: 
2024-02-08 05:44:45.842518: Epoch 428
2024-02-08 05:44:45.843550: Current learning rate: 0.00258
2024-02-08 05:45:29.209525: train_loss -0.6231
2024-02-08 05:45:29.210852: val_loss -0.3486
2024-02-08 05:45:29.211341: Pseudo dice [0.8374, 0.8143, 0.7372, 0.8341, 0.8082]
2024-02-08 05:45:29.211763: Epoch time: 43.37 s
2024-02-08 05:45:30.231834: 
2024-02-08 05:45:30.233181: Epoch 429
2024-02-08 05:45:30.234477: Current learning rate: 0.00256
2024-02-08 05:46:13.549102: train_loss -0.6235
2024-02-08 05:46:13.550823: val_loss -0.3681
2024-02-08 05:46:13.551325: Pseudo dice [0.8384, 0.8173, 0.7406, 0.8411, 0.8127]
2024-02-08 05:46:13.551872: Epoch time: 43.32 s
2024-02-08 05:46:14.566045: 
2024-02-08 05:46:14.567240: Epoch 430
2024-02-08 05:46:14.568269: Current learning rate: 0.00254
2024-02-08 05:46:58.046316: train_loss -0.6189
2024-02-08 05:46:58.048683: val_loss -0.3932
2024-02-08 05:46:58.049246: Pseudo dice [0.8453, 0.8218, 0.7528, 0.8411, 0.8204]
2024-02-08 05:46:58.049669: Epoch time: 43.48 s
2024-02-08 05:46:59.080977: 
2024-02-08 05:46:59.082097: Epoch 431
2024-02-08 05:46:59.083113: Current learning rate: 0.00252
2024-02-08 05:47:42.382469: train_loss -0.6236
2024-02-08 05:47:42.384137: val_loss -0.3636
2024-02-08 05:47:42.384673: Pseudo dice [0.8374, 0.8192, 0.7448, 0.8401, 0.8059]
2024-02-08 05:47:42.385130: Epoch time: 43.3 s
2024-02-08 05:47:43.794057: 
2024-02-08 05:47:43.795268: Epoch 432
2024-02-08 05:47:43.796550: Current learning rate: 0.0025
2024-02-08 05:48:26.951689: train_loss -0.6214
2024-02-08 05:48:26.953058: val_loss -0.3686
2024-02-08 05:48:26.953518: Pseudo dice [0.8392, 0.8217, 0.7444, 0.8384, 0.8137]
2024-02-08 05:48:26.953938: Epoch time: 43.16 s
2024-02-08 05:48:28.000778: 
2024-02-08 05:48:28.039372: Epoch 433
2024-02-08 05:48:28.040281: Current learning rate: 0.00248
2024-02-08 05:49:11.116990: train_loss -0.619
2024-02-08 05:49:11.118585: val_loss -0.3791
2024-02-08 05:49:11.119059: Pseudo dice [0.8396, 0.8259, 0.7551, 0.8507, 0.8113]
2024-02-08 05:49:11.119507: Epoch time: 43.12 s
2024-02-08 05:49:12.174553: 
2024-02-08 05:49:12.175495: Epoch 434
2024-02-08 05:49:12.176528: Current learning rate: 0.00246
2024-02-08 05:49:55.252285: train_loss -0.6271
2024-02-08 05:49:55.253702: val_loss -0.3844
2024-02-08 05:49:55.254201: Pseudo dice [0.8405, 0.8213, 0.7418, 0.8448, 0.8133]
2024-02-08 05:49:55.254633: Epoch time: 43.08 s
2024-02-08 05:49:56.275320: 
2024-02-08 05:49:56.276285: Epoch 435
2024-02-08 05:49:56.277330: Current learning rate: 0.00245
2024-02-08 05:50:39.576815: train_loss -0.625
2024-02-08 05:50:39.578241: val_loss -0.354
2024-02-08 05:50:39.578753: Pseudo dice [0.8311, 0.8239, 0.7428, 0.8316, 0.818]
2024-02-08 05:50:39.579207: Epoch time: 43.3 s
2024-02-08 05:50:40.646502: 
2024-02-08 05:50:40.647925: Epoch 436
2024-02-08 05:50:40.649061: Current learning rate: 0.00243
2024-02-08 05:51:23.865710: train_loss -0.6279
2024-02-08 05:51:23.867108: val_loss -0.3824
2024-02-08 05:51:23.867575: Pseudo dice [0.8416, 0.8222, 0.7508, 0.8352, 0.8149]
2024-02-08 05:51:23.868092: Epoch time: 43.22 s
2024-02-08 05:51:24.899878: 
2024-02-08 05:51:24.900835: Epoch 437
2024-02-08 05:51:24.901816: Current learning rate: 0.00241
2024-02-08 05:52:08.244106: train_loss -0.6191
2024-02-08 05:52:08.245718: val_loss -0.3601
2024-02-08 05:52:08.246229: Pseudo dice [0.8384, 0.8233, 0.7439, 0.8404, 0.8049]
2024-02-08 05:52:08.246673: Epoch time: 43.35 s
2024-02-08 05:52:09.540083: 
2024-02-08 05:52:09.541004: Epoch 438
2024-02-08 05:52:09.542212: Current learning rate: 0.00239
2024-02-08 05:52:52.812141: train_loss -0.6219
2024-02-08 05:52:52.813632: val_loss -0.3811
2024-02-08 05:52:52.814147: Pseudo dice [0.8384, 0.8287, 0.7503, 0.8451, 0.8172]
2024-02-08 05:52:52.814584: Epoch time: 43.27 s
2024-02-08 05:52:53.831105: 
2024-02-08 05:52:53.832698: Epoch 439
2024-02-08 05:52:53.833317: Current learning rate: 0.00237
2024-02-08 05:53:37.189839: train_loss -0.6193
2024-02-08 05:53:37.191370: val_loss -0.3694
2024-02-08 05:53:37.191908: Pseudo dice [0.836, 0.8219, 0.7495, 0.851, 0.8023]
2024-02-08 05:53:37.192357: Epoch time: 43.36 s
2024-02-08 05:53:38.223164: 
2024-02-08 05:53:38.224383: Epoch 440
2024-02-08 05:53:38.225648: Current learning rate: 0.00235
2024-02-08 05:54:21.335998: train_loss -0.6218
2024-02-08 05:54:21.337826: val_loss -0.365
2024-02-08 05:54:21.338642: Pseudo dice [0.8382, 0.8133, 0.7411, 0.8453, 0.8152]
2024-02-08 05:54:21.339194: Epoch time: 43.11 s
2024-02-08 05:54:22.383935: 
2024-02-08 05:54:22.385008: Epoch 441
2024-02-08 05:54:22.386262: Current learning rate: 0.00233
2024-02-08 05:55:05.558558: train_loss -0.6178
2024-02-08 05:55:05.561292: val_loss -0.3876
2024-02-08 05:55:05.561801: Pseudo dice [0.8412, 0.8294, 0.7493, 0.8546, 0.8085]
2024-02-08 05:55:05.562246: Epoch time: 43.18 s
2024-02-08 05:55:06.577608: 
2024-02-08 05:55:06.578780: Epoch 442
2024-02-08 05:55:06.580098: Current learning rate: 0.00231
2024-02-08 05:55:49.869582: train_loss -0.6262
2024-02-08 05:55:49.871216: val_loss -0.3874
2024-02-08 05:55:49.871750: Pseudo dice [0.8405, 0.8219, 0.7516, 0.849, 0.8213]
2024-02-08 05:55:49.872226: Epoch time: 43.29 s
2024-02-08 05:55:49.872626: Yayy! New best EMA pseudo Dice: 0.8128
2024-02-08 05:55:51.509255: 
2024-02-08 05:55:51.510535: Epoch 443
2024-02-08 05:55:51.511090: Current learning rate: 0.00229
2024-02-08 05:56:34.838626: train_loss -0.6172
2024-02-08 05:56:34.840126: val_loss -0.3673
2024-02-08 05:56:34.840580: Pseudo dice [0.8371, 0.8185, 0.7432, 0.8428, 0.8125]
2024-02-08 05:56:34.841014: Epoch time: 43.33 s
2024-02-08 05:56:35.871082: 
2024-02-08 05:56:35.872644: Epoch 444
2024-02-08 05:56:35.873615: Current learning rate: 0.00227
2024-02-08 05:57:19.127073: train_loss -0.625
2024-02-08 05:57:19.128877: val_loss -0.3729
2024-02-08 05:57:19.129473: Pseudo dice [0.8359, 0.8187, 0.7464, 0.8483, 0.8127]
2024-02-08 05:57:19.129972: Epoch time: 43.26 s
2024-02-08 05:57:20.175370: 
2024-02-08 05:57:20.176516: Epoch 445
2024-02-08 05:57:20.177614: Current learning rate: 0.00225
2024-02-08 05:58:03.319906: train_loss -0.6235
2024-02-08 05:58:03.321290: val_loss -0.369
2024-02-08 05:58:03.321784: Pseudo dice [0.8388, 0.8196, 0.7471, 0.8392, 0.805]
2024-02-08 05:58:03.322225: Epoch time: 43.15 s
2024-02-08 05:58:04.367243: 
2024-02-08 05:58:04.368307: Epoch 446
2024-02-08 05:58:04.369147: Current learning rate: 0.00223
2024-02-08 05:58:47.553322: train_loss -0.622
2024-02-08 05:58:47.555535: val_loss -0.3758
2024-02-08 05:58:47.556182: Pseudo dice [0.8396, 0.8229, 0.7461, 0.8494, 0.8102]
2024-02-08 05:58:47.556778: Epoch time: 43.19 s
2024-02-08 05:58:48.677626: 
2024-02-08 05:58:48.678779: Epoch 447
2024-02-08 05:58:48.679802: Current learning rate: 0.00221
2024-02-08 05:59:32.088388: train_loss -0.627
2024-02-08 05:59:32.090150: val_loss -0.3804
2024-02-08 05:59:32.090673: Pseudo dice [0.8427, 0.8252, 0.7432, 0.8494, 0.8226]
2024-02-08 05:59:32.091132: Epoch time: 43.41 s
2024-02-08 05:59:32.091587: Yayy! New best EMA pseudo Dice: 0.8129
2024-02-08 05:59:33.769706: 
2024-02-08 05:59:33.771189: Epoch 448
2024-02-08 05:59:33.771799: Current learning rate: 0.00219
2024-02-08 06:00:16.984915: train_loss -0.6271
2024-02-08 06:00:16.986669: val_loss -0.3568
2024-02-08 06:00:16.988190: Pseudo dice [0.8344, 0.82, 0.7489, 0.8384, 0.8068]
2024-02-08 06:00:16.988713: Epoch time: 43.22 s
2024-02-08 06:00:18.016237: 
2024-02-08 06:00:18.017719: Epoch 449
2024-02-08 06:00:18.018234: Current learning rate: 0.00218
2024-02-08 06:01:01.461425: train_loss -0.6325
2024-02-08 06:01:01.462844: val_loss -0.3819
2024-02-08 06:01:01.463329: Pseudo dice [0.8393, 0.8255, 0.7491, 0.8472, 0.81]
2024-02-08 06:01:01.463781: Epoch time: 43.45 s
2024-02-08 06:01:02.838173: 
2024-02-08 06:01:02.839152: Epoch 450
2024-02-08 06:01:02.840085: Current learning rate: 0.00216
2024-02-08 06:01:45.798872: train_loss -0.6213
2024-02-08 06:01:45.800419: val_loss -0.3716
2024-02-08 06:01:45.800993: Pseudo dice [0.8408, 0.8243, 0.7491, 0.8482, 0.8013]
2024-02-08 06:01:45.801715: Epoch time: 42.96 s
2024-02-08 06:01:46.830630: 
2024-02-08 06:01:46.831827: Epoch 451
2024-02-08 06:01:46.832892: Current learning rate: 0.00214
2024-02-08 06:02:29.933888: train_loss -0.6288
2024-02-08 06:02:29.935348: val_loss -0.3565
2024-02-08 06:02:29.935871: Pseudo dice [0.8369, 0.821, 0.7416, 0.8416, 0.7994]
2024-02-08 06:02:29.936364: Epoch time: 43.11 s
2024-02-08 06:02:30.992785: 
2024-02-08 06:02:30.994098: Epoch 452
2024-02-08 06:02:30.995197: Current learning rate: 0.00212
2024-02-08 06:03:14.070124: train_loss -0.6264
2024-02-08 06:03:14.071697: val_loss -0.3607
2024-02-08 06:03:14.072400: Pseudo dice [0.8386, 0.8172, 0.7435, 0.8391, 0.8087]
2024-02-08 06:03:14.072847: Epoch time: 43.08 s
2024-02-08 06:03:15.301135: 
2024-02-08 06:03:15.302462: Epoch 453
2024-02-08 06:03:15.303737: Current learning rate: 0.0021
2024-02-08 06:03:58.544500: train_loss -0.6198
2024-02-08 06:03:58.546071: val_loss -0.3772
2024-02-08 06:03:58.546563: Pseudo dice [0.8384, 0.8193, 0.7443, 0.8429, 0.8069]
2024-02-08 06:03:58.547082: Epoch time: 43.24 s
2024-02-08 06:03:59.610693: 
2024-02-08 06:03:59.612156: Epoch 454
2024-02-08 06:03:59.613582: Current learning rate: 0.00208
2024-02-08 06:04:42.722633: train_loss -0.6224
2024-02-08 06:04:42.724390: val_loss -0.3705
2024-02-08 06:04:42.724968: Pseudo dice [0.8386, 0.8242, 0.7473, 0.8388, 0.8108]
2024-02-08 06:04:42.725430: Epoch time: 43.11 s
2024-02-08 06:04:43.769492: 
2024-02-08 06:04:43.770639: Epoch 455
2024-02-08 06:04:43.771589: Current learning rate: 0.00206
2024-02-08 06:05:27.010071: train_loss -0.6253
2024-02-08 06:05:27.011445: val_loss -0.3906
2024-02-08 06:05:27.011905: Pseudo dice [0.8399, 0.8234, 0.7519, 0.8465, 0.8113]
2024-02-08 06:05:27.012382: Epoch time: 43.24 s
2024-02-08 06:05:28.040790: 
2024-02-08 06:05:28.041953: Epoch 456
2024-02-08 06:05:28.043489: Current learning rate: 0.00204
2024-02-08 06:06:11.095775: train_loss -0.6292
2024-02-08 06:06:11.097665: val_loss -0.3491
2024-02-08 06:06:11.098359: Pseudo dice [0.8341, 0.818, 0.7397, 0.8365, 0.8092]
2024-02-08 06:06:11.098934: Epoch time: 43.06 s
2024-02-08 06:06:12.152613: 
2024-02-08 06:06:12.153655: Epoch 457
2024-02-08 06:06:12.154850: Current learning rate: 0.00202
2024-02-08 06:06:55.415362: train_loss -0.6322
2024-02-08 06:06:55.416979: val_loss -0.3785
2024-02-08 06:06:55.417495: Pseudo dice [0.8405, 0.8246, 0.7477, 0.8397, 0.8193]
2024-02-08 06:06:55.417937: Epoch time: 43.26 s
2024-02-08 06:06:56.432625: 
2024-02-08 06:06:56.433718: Epoch 458
2024-02-08 06:06:56.434919: Current learning rate: 0.002
2024-02-08 06:07:39.448469: train_loss -0.6294
2024-02-08 06:07:39.450052: val_loss -0.3557
2024-02-08 06:07:39.450602: Pseudo dice [0.8317, 0.8156, 0.7376, 0.837, 0.8001]
2024-02-08 06:07:39.451029: Epoch time: 43.02 s
2024-02-08 06:07:40.689006: 
2024-02-08 06:07:40.690470: Epoch 459
2024-02-08 06:07:40.691615: Current learning rate: 0.00198
2024-02-08 06:08:23.878159: train_loss -0.6297
2024-02-08 06:08:23.879901: val_loss -0.3739
2024-02-08 06:08:23.880461: Pseudo dice [0.8404, 0.8192, 0.7519, 0.8452, 0.8166]
2024-02-08 06:08:23.880960: Epoch time: 43.19 s
2024-02-08 06:08:24.903161: 
2024-02-08 06:08:24.905295: Epoch 460
2024-02-08 06:08:24.906314: Current learning rate: 0.00196
2024-02-08 06:09:08.011794: train_loss -0.6318
2024-02-08 06:09:08.013029: val_loss -0.3633
2024-02-08 06:09:08.013519: Pseudo dice [0.8384, 0.8231, 0.7442, 0.8408, 0.8093]
2024-02-08 06:09:08.013984: Epoch time: 43.11 s
2024-02-08 06:09:09.063365: 
2024-02-08 06:09:09.065159: Epoch 461
2024-02-08 06:09:09.065706: Current learning rate: 0.00194
2024-02-08 06:09:52.022003: train_loss -0.6295
2024-02-08 06:09:52.023946: val_loss -0.3679
2024-02-08 06:09:52.024496: Pseudo dice [0.8414, 0.8162, 0.7436, 0.8396, 0.8122]
2024-02-08 06:09:52.024989: Epoch time: 42.96 s
2024-02-08 06:09:53.047631: 
2024-02-08 06:09:53.048630: Epoch 462
2024-02-08 06:09:53.049585: Current learning rate: 0.00192
2024-02-08 06:10:36.160133: train_loss -0.6271
2024-02-08 06:10:36.161442: val_loss -0.354
2024-02-08 06:10:36.161911: Pseudo dice [0.8382, 0.8221, 0.7418, 0.8462, 0.8034]
2024-02-08 06:10:36.162356: Epoch time: 43.11 s
2024-02-08 06:10:37.196023: 
2024-02-08 06:10:37.197044: Epoch 463
2024-02-08 06:10:37.197872: Current learning rate: 0.0019
2024-02-08 06:11:20.339139: train_loss -0.6294
2024-02-08 06:11:20.340942: val_loss -0.3573
2024-02-08 06:11:20.341522: Pseudo dice [0.8341, 0.8242, 0.7436, 0.8412, 0.8026]
2024-02-08 06:11:20.342202: Epoch time: 43.14 s
2024-02-08 06:11:21.574924: 
2024-02-08 06:11:21.576227: Epoch 464
2024-02-08 06:11:21.577305: Current learning rate: 0.00188
2024-02-08 06:12:04.715900: train_loss -0.6271
2024-02-08 06:12:04.717270: val_loss -0.3719
2024-02-08 06:12:04.717763: Pseudo dice [0.8367, 0.8254, 0.7533, 0.8458, 0.8121]
2024-02-08 06:12:04.718222: Epoch time: 43.14 s
2024-02-08 06:12:05.754334: 
2024-02-08 06:12:05.755886: Epoch 465
2024-02-08 06:12:05.757563: Current learning rate: 0.00186
2024-02-08 06:12:49.029496: train_loss -0.6362
2024-02-08 06:12:49.030990: val_loss -0.3508
2024-02-08 06:12:49.031440: Pseudo dice [0.8351, 0.8186, 0.7409, 0.8426, 0.8117]
2024-02-08 06:12:49.031889: Epoch time: 43.28 s
2024-02-08 06:12:50.059304: 
2024-02-08 06:12:50.061015: Epoch 466
2024-02-08 06:12:50.062301: Current learning rate: 0.00184
2024-02-08 06:13:33.533300: train_loss -0.6258
2024-02-08 06:13:33.534644: val_loss -0.3642
2024-02-08 06:13:33.535161: Pseudo dice [0.8388, 0.8191, 0.7443, 0.8369, 0.8076]
2024-02-08 06:13:33.535635: Epoch time: 43.48 s
2024-02-08 06:13:34.551873: 
2024-02-08 06:13:34.552877: Epoch 467
2024-02-08 06:13:34.553798: Current learning rate: 0.00182
2024-02-08 06:14:17.972324: train_loss -0.6276
2024-02-08 06:14:17.973637: val_loss -0.3544
2024-02-08 06:14:17.974123: Pseudo dice [0.8347, 0.814, 0.7455, 0.8399, 0.7996]
2024-02-08 06:14:17.974575: Epoch time: 43.42 s
2024-02-08 06:14:19.034921: 
2024-02-08 06:14:19.036110: Epoch 468
2024-02-08 06:14:19.037577: Current learning rate: 0.0018
2024-02-08 06:15:02.388839: train_loss -0.6294
2024-02-08 06:15:02.390455: val_loss -0.3697
2024-02-08 06:15:02.390941: Pseudo dice [0.8357, 0.825, 0.753, 0.8444, 0.8075]
2024-02-08 06:15:02.391889: Epoch time: 43.36 s
2024-02-08 06:15:03.405565: 
2024-02-08 06:15:03.406652: Epoch 469
2024-02-08 06:15:03.407926: Current learning rate: 0.00178
2024-02-08 06:15:46.692360: train_loss -0.6307
2024-02-08 06:15:46.693652: val_loss -0.374
2024-02-08 06:15:46.694165: Pseudo dice [0.8424, 0.822, 0.7468, 0.8444, 0.8124]
2024-02-08 06:15:46.694578: Epoch time: 43.29 s
2024-02-08 06:15:47.870392: 
2024-02-08 06:15:47.871441: Epoch 470
2024-02-08 06:15:47.872869: Current learning rate: 0.00176
2024-02-08 06:16:31.050196: train_loss -0.6304
2024-02-08 06:16:31.051771: val_loss -0.3666
2024-02-08 06:16:31.052285: Pseudo dice [0.8387, 0.8232, 0.7425, 0.8445, 0.7977]
2024-02-08 06:16:31.052725: Epoch time: 43.18 s
2024-02-08 06:16:32.074836: 
2024-02-08 06:16:32.075947: Epoch 471
2024-02-08 06:16:32.077059: Current learning rate: 0.00174
2024-02-08 06:17:15.445086: train_loss -0.6333
2024-02-08 06:17:15.446584: val_loss -0.3561
2024-02-08 06:17:15.447060: Pseudo dice [0.8341, 0.8188, 0.7424, 0.8402, 0.8106]
2024-02-08 06:17:15.447496: Epoch time: 43.37 s
2024-02-08 06:17:16.468880: 
2024-02-08 06:17:16.470453: Epoch 472
2024-02-08 06:17:16.471287: Current learning rate: 0.00172
2024-02-08 06:17:59.731811: train_loss -0.6333
2024-02-08 06:17:59.733535: val_loss -0.3928
2024-02-08 06:17:59.734044: Pseudo dice [0.8458, 0.8265, 0.7565, 0.8488, 0.8155]
2024-02-08 06:17:59.734528: Epoch time: 43.27 s
2024-02-08 06:18:00.748218: 
2024-02-08 06:18:00.749270: Epoch 473
2024-02-08 06:18:00.750504: Current learning rate: 0.0017
2024-02-08 06:18:44.277311: train_loss -0.632
2024-02-08 06:18:44.278830: val_loss -0.3683
2024-02-08 06:18:44.279327: Pseudo dice [0.8413, 0.819, 0.7459, 0.8449, 0.8079]
2024-02-08 06:18:44.279776: Epoch time: 43.53 s
2024-02-08 06:18:45.306552: 
2024-02-08 06:18:45.307953: Epoch 474
2024-02-08 06:18:45.309234: Current learning rate: 0.00168
2024-02-08 06:19:28.709906: train_loss -0.6353
2024-02-08 06:19:28.711336: val_loss -0.3494
2024-02-08 06:19:28.712073: Pseudo dice [0.8363, 0.8178, 0.7427, 0.8393, 0.8094]
2024-02-08 06:19:28.712503: Epoch time: 43.4 s
2024-02-08 06:19:30.108133: 
2024-02-08 06:19:30.109281: Epoch 475
2024-02-08 06:19:30.110274: Current learning rate: 0.00166
2024-02-08 06:20:13.489781: train_loss -0.6357
2024-02-08 06:20:13.491690: val_loss -0.3594
2024-02-08 06:20:13.492268: Pseudo dice [0.8402, 0.8201, 0.7479, 0.8413, 0.8129]
2024-02-08 06:20:13.492777: Epoch time: 43.38 s
2024-02-08 06:20:14.553846: 
2024-02-08 06:20:14.554985: Epoch 476
2024-02-08 06:20:14.556076: Current learning rate: 0.00164
2024-02-08 06:20:57.844847: train_loss -0.6369
2024-02-08 06:20:57.846629: val_loss -0.3679
2024-02-08 06:20:57.847439: Pseudo dice [0.8387, 0.8133, 0.7446, 0.8416, 0.8081]
2024-02-08 06:20:57.847894: Epoch time: 43.29 s
2024-02-08 06:20:58.904212: 
2024-02-08 06:20:58.905456: Epoch 477
2024-02-08 06:20:58.906694: Current learning rate: 0.00162
2024-02-08 06:21:42.201216: train_loss -0.6338
2024-02-08 06:21:42.202800: val_loss -0.3799
2024-02-08 06:21:42.203280: Pseudo dice [0.843, 0.8274, 0.7501, 0.8468, 0.8076]
2024-02-08 06:21:42.203743: Epoch time: 43.3 s
2024-02-08 06:21:43.240991: 
2024-02-08 06:21:43.242328: Epoch 478
2024-02-08 06:21:43.242810: Current learning rate: 0.0016
2024-02-08 06:22:26.570379: train_loss -0.6323
2024-02-08 06:22:26.571778: val_loss -0.368
2024-02-08 06:22:26.572548: Pseudo dice [0.8393, 0.8158, 0.7438, 0.841, 0.8134]
2024-02-08 06:22:26.573102: Epoch time: 43.33 s
2024-02-08 06:22:27.611126: 
2024-02-08 06:22:27.612325: Epoch 479
2024-02-08 06:22:27.613328: Current learning rate: 0.00158
2024-02-08 06:23:10.672521: train_loss -0.6329
2024-02-08 06:23:10.673902: val_loss -0.3692
2024-02-08 06:23:10.674345: Pseudo dice [0.8393, 0.8245, 0.7448, 0.8445, 0.816]
2024-02-08 06:23:10.674775: Epoch time: 43.06 s
2024-02-08 06:23:11.736986: 
2024-02-08 06:23:11.738001: Epoch 480
2024-02-08 06:23:11.739030: Current learning rate: 0.00156
2024-02-08 06:23:54.803901: train_loss -0.6291
2024-02-08 06:23:54.805381: val_loss -0.3692
2024-02-08 06:23:54.805871: Pseudo dice [0.8426, 0.8208, 0.7477, 0.8453, 0.8019]
2024-02-08 06:23:54.806305: Epoch time: 43.07 s
2024-02-08 06:23:56.151536: 
2024-02-08 06:23:56.152915: Epoch 481
2024-02-08 06:23:56.153899: Current learning rate: 0.00154
2024-02-08 06:24:39.197748: train_loss -0.6358
2024-02-08 06:24:39.199120: val_loss -0.3726
2024-02-08 06:24:39.199650: Pseudo dice [0.8397, 0.8249, 0.7503, 0.8489, 0.8131]
2024-02-08 06:24:39.200060: Epoch time: 43.05 s
2024-02-08 06:24:40.238606: 
2024-02-08 06:24:40.239613: Epoch 482
2024-02-08 06:24:40.240474: Current learning rate: 0.00152
2024-02-08 06:25:23.497465: train_loss -0.6337
2024-02-08 06:25:23.499175: val_loss -0.3716
2024-02-08 06:25:23.500790: Pseudo dice [0.839, 0.8193, 0.7472, 0.845, 0.8148]
2024-02-08 06:25:23.501236: Epoch time: 43.26 s
2024-02-08 06:25:24.544541: 
2024-02-08 06:25:24.545630: Epoch 483
2024-02-08 06:25:24.546681: Current learning rate: 0.0015
2024-02-08 06:26:07.836930: train_loss -0.6302
2024-02-08 06:26:07.838231: val_loss -0.3704
2024-02-08 06:26:07.838825: Pseudo dice [0.8411, 0.8239, 0.7493, 0.8468, 0.806]
2024-02-08 06:26:07.839279: Epoch time: 43.29 s
2024-02-08 06:26:08.894453: 
2024-02-08 06:26:08.895642: Epoch 484
2024-02-08 06:26:08.896461: Current learning rate: 0.00148
2024-02-08 06:26:52.189463: train_loss -0.6301
2024-02-08 06:26:52.190853: val_loss -0.3525
2024-02-08 06:26:52.191330: Pseudo dice [0.8372, 0.819, 0.7366, 0.8365, 0.807]
2024-02-08 06:26:52.191763: Epoch time: 43.3 s
2024-02-08 06:26:53.218547: 
2024-02-08 06:26:53.219569: Epoch 485
2024-02-08 06:26:53.220793: Current learning rate: 0.00146
2024-02-08 06:27:36.148809: train_loss -0.6287
2024-02-08 06:27:36.150169: val_loss -0.3624
2024-02-08 06:27:36.150613: Pseudo dice [0.8399, 0.8171, 0.7497, 0.8455, 0.8101]
2024-02-08 06:27:36.151055: Epoch time: 42.93 s
2024-02-08 06:27:37.203709: 
2024-02-08 06:27:37.205199: Epoch 486
2024-02-08 06:27:37.206468: Current learning rate: 0.00144
2024-02-08 06:28:20.445013: train_loss -0.6345
2024-02-08 06:28:20.446893: val_loss -0.3593
2024-02-08 06:28:20.447723: Pseudo dice [0.8393, 0.8192, 0.7437, 0.8394, 0.8181]
2024-02-08 06:28:20.448216: Epoch time: 43.24 s
2024-02-08 06:28:21.700636: 
2024-02-08 06:28:21.701797: Epoch 487
2024-02-08 06:28:21.702830: Current learning rate: 0.00142
2024-02-08 06:29:04.886471: train_loss -0.637
2024-02-08 06:29:04.888437: val_loss -0.3534
2024-02-08 06:29:04.889086: Pseudo dice [0.8326, 0.824, 0.7455, 0.8395, 0.8049]
2024-02-08 06:29:04.889629: Epoch time: 43.19 s
2024-02-08 06:29:05.925253: 
2024-02-08 06:29:05.926367: Epoch 488
2024-02-08 06:29:05.927636: Current learning rate: 0.0014
2024-02-08 06:29:49.080331: train_loss -0.6346
2024-02-08 06:29:49.082342: val_loss -0.3715
2024-02-08 06:29:49.082830: Pseudo dice [0.8417, 0.8215, 0.7454, 0.8457, 0.8173]
2024-02-08 06:29:49.083278: Epoch time: 43.16 s
2024-02-08 06:29:50.130305: 
2024-02-08 06:29:50.131680: Epoch 489
2024-02-08 06:29:50.133076: Current learning rate: 0.00138
2024-02-08 06:30:33.427526: train_loss -0.6364
2024-02-08 06:30:33.429554: val_loss -0.3774
2024-02-08 06:30:33.430141: Pseudo dice [0.8399, 0.83, 0.7536, 0.8433, 0.8225]
2024-02-08 06:30:33.430665: Epoch time: 43.3 s
2024-02-08 06:30:34.451726: 
2024-02-08 06:30:34.452787: Epoch 490
2024-02-08 06:30:34.453988: Current learning rate: 0.00136
2024-02-08 06:31:17.729469: train_loss -0.6324
2024-02-08 06:31:17.730976: val_loss -0.362
2024-02-08 06:31:17.731489: Pseudo dice [0.8378, 0.8218, 0.7423, 0.8341, 0.8175]
2024-02-08 06:31:17.731951: Epoch time: 43.28 s
2024-02-08 06:31:18.809652: 
2024-02-08 06:31:18.811145: Epoch 491
2024-02-08 06:31:18.812137: Current learning rate: 0.00134
2024-02-08 06:32:01.926673: train_loss -0.6343
2024-02-08 06:32:01.928070: val_loss -0.3827
2024-02-08 06:32:01.928618: Pseudo dice [0.8416, 0.8261, 0.7551, 0.8456, 0.8176]
2024-02-08 06:32:01.929070: Epoch time: 43.12 s
2024-02-08 06:32:03.117201: 
2024-02-08 06:32:03.118424: Epoch 492
2024-02-08 06:32:03.119589: Current learning rate: 0.00132
2024-02-08 06:32:46.201065: train_loss -0.637
2024-02-08 06:32:46.202564: val_loss -0.3825
2024-02-08 06:32:46.203021: Pseudo dice [0.844, 0.824, 0.7543, 0.8488, 0.8269]
2024-02-08 06:32:46.203445: Epoch time: 43.09 s
2024-02-08 06:32:46.203863: Yayy! New best EMA pseudo Dice: 0.8135
2024-02-08 06:32:47.533406: 
2024-02-08 06:32:47.534443: Epoch 493
2024-02-08 06:32:47.535674: Current learning rate: 0.0013
2024-02-08 06:33:30.668307: train_loss -0.6364
2024-02-08 06:33:30.669779: val_loss -0.359
2024-02-08 06:33:30.670241: Pseudo dice [0.8358, 0.8221, 0.7463, 0.8472, 0.8006]
2024-02-08 06:33:30.670671: Epoch time: 43.14 s
2024-02-08 06:33:31.690263: 
2024-02-08 06:33:31.691666: Epoch 494
2024-02-08 06:33:31.693065: Current learning rate: 0.00128
2024-02-08 06:34:15.061870: train_loss -0.6376
2024-02-08 06:34:15.063322: val_loss -0.3646
2024-02-08 06:34:15.063804: Pseudo dice [0.8378, 0.8252, 0.749, 0.8466, 0.8045]
2024-02-08 06:34:15.064205: Epoch time: 43.37 s
2024-02-08 06:34:16.171638: 
2024-02-08 06:34:16.172761: Epoch 495
2024-02-08 06:34:16.174176: Current learning rate: 0.00126
2024-02-08 06:34:59.417081: train_loss -0.6357
2024-02-08 06:34:59.418547: val_loss -0.3628
2024-02-08 06:34:59.419013: Pseudo dice [0.8378, 0.8178, 0.7438, 0.8416, 0.8114]
2024-02-08 06:34:59.419487: Epoch time: 43.25 s
2024-02-08 06:35:00.439662: 
2024-02-08 06:35:00.440776: Epoch 496
2024-02-08 06:35:00.441932: Current learning rate: 0.00124
2024-02-08 06:35:43.621772: train_loss -0.6355
2024-02-08 06:35:43.623075: val_loss -0.3502
2024-02-08 06:35:43.623551: Pseudo dice [0.8367, 0.8126, 0.7412, 0.8414, 0.797]
2024-02-08 06:35:43.623985: Epoch time: 43.18 s
2024-02-08 06:35:44.883008: 
2024-02-08 06:35:44.884700: Epoch 497
2024-02-08 06:35:44.886213: Current learning rate: 0.00122
2024-02-08 06:36:28.429223: train_loss -0.6291
2024-02-08 06:36:28.430683: val_loss -0.3603
2024-02-08 06:36:28.431182: Pseudo dice [0.8399, 0.8251, 0.7483, 0.8476, 0.8096]
2024-02-08 06:36:28.431660: Epoch time: 43.55 s
2024-02-08 06:36:29.457102: 
2024-02-08 06:36:29.461923: Epoch 498
2024-02-08 06:36:29.463927: Current learning rate: 0.0012
2024-02-08 06:37:12.889799: train_loss -0.6383
2024-02-08 06:37:12.891430: val_loss -0.3682
2024-02-08 06:37:12.891927: Pseudo dice [0.838, 0.8148, 0.7466, 0.8385, 0.8205]
2024-02-08 06:37:12.892352: Epoch time: 43.43 s
2024-02-08 06:37:13.974584: 
2024-02-08 06:37:13.975648: Epoch 499
2024-02-08 06:37:13.976748: Current learning rate: 0.00118
2024-02-08 06:37:57.119643: train_loss -0.6442
2024-02-08 06:37:57.121268: val_loss -0.3738
2024-02-08 06:37:57.121758: Pseudo dice [0.8422, 0.8254, 0.7537, 0.8522, 0.8175]
2024-02-08 06:37:57.122218: Epoch time: 43.15 s
2024-02-08 06:37:58.520365: 
2024-02-08 06:37:58.521653: Epoch 500
2024-02-08 06:37:58.522811: Current learning rate: 0.00116
2024-02-08 06:38:41.729712: train_loss -0.6393
2024-02-08 06:38:41.731241: val_loss -0.3595
2024-02-08 06:38:41.731723: Pseudo dice [0.8391, 0.823, 0.7418, 0.8437, 0.8041]
2024-02-08 06:38:41.732203: Epoch time: 43.21 s
2024-02-08 06:38:42.766578: 
2024-02-08 06:38:42.767776: Epoch 501
2024-02-08 06:38:42.768874: Current learning rate: 0.00113
2024-02-08 06:39:26.037854: train_loss -0.639
2024-02-08 06:39:26.039669: val_loss -0.3509
2024-02-08 06:39:26.040224: Pseudo dice [0.84, 0.8149, 0.7453, 0.841, 0.8056]
2024-02-08 06:39:26.040743: Epoch time: 43.27 s
2024-02-08 06:39:27.324617: 
2024-02-08 06:39:27.325919: Epoch 502
2024-02-08 06:39:27.327080: Current learning rate: 0.00111
2024-02-08 06:40:10.352797: train_loss -0.6456
2024-02-08 06:40:10.354373: val_loss -0.3685
2024-02-08 06:40:10.354910: Pseudo dice [0.8373, 0.827, 0.7445, 0.8471, 0.8059]
2024-02-08 06:40:10.355365: Epoch time: 43.03 s
2024-02-08 06:40:11.413561: 
2024-02-08 06:40:11.414638: Epoch 503
2024-02-08 06:40:11.415550: Current learning rate: 0.00109
2024-02-08 06:40:54.502273: train_loss -0.6395
2024-02-08 06:40:54.503614: val_loss -0.3466
2024-02-08 06:40:54.504254: Pseudo dice [0.8335, 0.8237, 0.7442, 0.8332, 0.8089]
2024-02-08 06:40:54.504698: Epoch time: 43.09 s
2024-02-08 06:40:55.564989: 
2024-02-08 06:40:55.566060: Epoch 504
2024-02-08 06:40:55.567233: Current learning rate: 0.00107
2024-02-08 06:41:38.676289: train_loss -0.6453
2024-02-08 06:41:38.677826: val_loss -0.3764
2024-02-08 06:41:38.678381: Pseudo dice [0.8418, 0.8209, 0.7525, 0.8409, 0.8181]
2024-02-08 06:41:38.678910: Epoch time: 43.11 s
2024-02-08 06:41:39.735507: 
2024-02-08 06:41:39.736530: Epoch 505
2024-02-08 06:41:39.737351: Current learning rate: 0.00105
2024-02-08 06:42:22.935836: train_loss -0.6415
2024-02-08 06:42:22.937364: val_loss -0.3545
2024-02-08 06:42:22.937863: Pseudo dice [0.8366, 0.8229, 0.7468, 0.8447, 0.815]
2024-02-08 06:42:22.938259: Epoch time: 43.2 s
2024-02-08 06:42:23.973251: 
2024-02-08 06:42:23.974288: Epoch 506
2024-02-08 06:42:23.975534: Current learning rate: 0.00103
2024-02-08 06:43:07.033007: train_loss -0.6349
2024-02-08 06:43:07.034582: val_loss -0.3707
2024-02-08 06:43:07.035099: Pseudo dice [0.8372, 0.8237, 0.7456, 0.8417, 0.8084]
2024-02-08 06:43:07.035626: Epoch time: 43.06 s
2024-02-08 06:43:08.076601: 
2024-02-08 06:43:08.077751: Epoch 507
2024-02-08 06:43:08.078772: Current learning rate: 0.00101
2024-02-08 06:43:51.301306: train_loss -0.6407
2024-02-08 06:43:51.302807: val_loss -0.3525
2024-02-08 06:43:51.303336: Pseudo dice [0.8345, 0.8231, 0.7448, 0.8414, 0.8067]
2024-02-08 06:43:51.303970: Epoch time: 43.23 s
2024-02-08 06:43:52.564123: 
2024-02-08 06:43:52.565150: Epoch 508
2024-02-08 06:43:52.566057: Current learning rate: 0.00099
2024-02-08 06:44:35.631144: train_loss -0.6415
2024-02-08 06:44:35.632638: val_loss -0.3742
2024-02-08 06:44:35.633153: Pseudo dice [0.8412, 0.8234, 0.7514, 0.8486, 0.8145]
2024-02-08 06:44:35.633648: Epoch time: 43.07 s
2024-02-08 06:44:36.667288: 
2024-02-08 06:44:36.668394: Epoch 509
2024-02-08 06:44:36.669368: Current learning rate: 0.00097
2024-02-08 06:45:19.647639: train_loss -0.6453
2024-02-08 06:45:19.649241: val_loss -0.376
2024-02-08 06:45:19.649806: Pseudo dice [0.8434, 0.8277, 0.7525, 0.8485, 0.8063]
2024-02-08 06:45:19.650279: Epoch time: 42.98 s
2024-02-08 06:45:20.694515: 
2024-02-08 06:45:20.695657: Epoch 510
2024-02-08 06:45:20.697099: Current learning rate: 0.00095
2024-02-08 06:46:03.798824: train_loss -0.6401
2024-02-08 06:46:03.800307: val_loss -0.3637
2024-02-08 06:46:03.800937: Pseudo dice [0.8377, 0.8255, 0.746, 0.8449, 0.8102]
2024-02-08 06:46:03.801374: Epoch time: 43.11 s
2024-02-08 06:46:04.835630: 
2024-02-08 06:46:04.836734: Epoch 511
2024-02-08 06:46:04.837907: Current learning rate: 0.00092
2024-02-08 06:46:48.003083: train_loss -0.64
2024-02-08 06:46:48.004427: val_loss -0.3714
2024-02-08 06:46:48.004881: Pseudo dice [0.8435, 0.824, 0.7473, 0.8496, 0.8223]
2024-02-08 06:46:48.005296: Epoch time: 43.17 s
2024-02-08 06:46:49.040497: 
2024-02-08 06:46:49.041617: Epoch 512
2024-02-08 06:46:49.043297: Current learning rate: 0.0009
2024-02-08 06:47:32.230812: train_loss -0.6385
2024-02-08 06:47:32.232564: val_loss -0.363
2024-02-08 06:47:32.233207: Pseudo dice [0.8381, 0.8262, 0.7492, 0.8421, 0.8111]
2024-02-08 06:47:32.233685: Epoch time: 43.19 s
2024-02-08 06:47:33.547647: 
2024-02-08 06:47:33.550173: Epoch 513
2024-02-08 06:47:33.551585: Current learning rate: 0.00088
2024-02-08 06:48:16.531610: train_loss -0.6397
2024-02-08 06:48:16.533286: val_loss -0.3592
2024-02-08 06:48:16.533824: Pseudo dice [0.8358, 0.8142, 0.744, 0.8397, 0.8029]
2024-02-08 06:48:16.534282: Epoch time: 42.99 s
2024-02-08 06:48:17.623192: 
2024-02-08 06:48:17.624497: Epoch 514
2024-02-08 06:48:17.625751: Current learning rate: 0.00086
2024-02-08 06:49:00.861333: train_loss -0.6457
2024-02-08 06:49:00.864002: val_loss -0.3643
2024-02-08 06:49:00.864496: Pseudo dice [0.8417, 0.8188, 0.7463, 0.8407, 0.804]
2024-02-08 06:49:00.864943: Epoch time: 43.24 s
2024-02-08 06:49:01.886625: 
2024-02-08 06:49:01.887670: Epoch 515
2024-02-08 06:49:01.888898: Current learning rate: 0.00084
2024-02-08 06:49:44.893564: train_loss -0.6461
2024-02-08 06:49:44.894973: val_loss -0.3578
2024-02-08 06:49:44.895477: Pseudo dice [0.8339, 0.8199, 0.744, 0.8312, 0.826]
2024-02-08 06:49:44.895935: Epoch time: 43.01 s
2024-02-08 06:49:45.927068: 
2024-02-08 06:49:45.928632: Epoch 516
2024-02-08 06:49:45.930238: Current learning rate: 0.00082
2024-02-08 06:50:29.041388: train_loss -0.6419
2024-02-08 06:50:29.043206: val_loss -0.3721
2024-02-08 06:50:29.043775: Pseudo dice [0.8408, 0.8278, 0.7493, 0.8465, 0.8093]
2024-02-08 06:50:29.044235: Epoch time: 43.12 s
2024-02-08 06:50:30.071366: 
2024-02-08 06:50:30.072386: Epoch 517
2024-02-08 06:50:30.073491: Current learning rate: 0.00079
2024-02-08 06:51:13.292264: train_loss -0.6437
2024-02-08 06:51:13.293674: val_loss -0.3774
2024-02-08 06:51:13.294164: Pseudo dice [0.8428, 0.8284, 0.7468, 0.8498, 0.8172]
2024-02-08 06:51:13.294616: Epoch time: 43.22 s
2024-02-08 06:51:14.329386: 
2024-02-08 06:51:14.330523: Epoch 518
2024-02-08 06:51:14.331503: Current learning rate: 0.00077
2024-02-08 06:51:57.430362: train_loss -0.6431
2024-02-08 06:51:57.432350: val_loss -0.3809
2024-02-08 06:51:57.433062: Pseudo dice [0.8429, 0.8252, 0.7531, 0.8504, 0.807]
2024-02-08 06:51:57.433561: Epoch time: 43.1 s
2024-02-08 06:51:58.649369: 
2024-02-08 06:51:58.650778: Epoch 519
2024-02-08 06:51:58.652033: Current learning rate: 0.00075
2024-02-08 06:52:41.936837: train_loss -0.6461
2024-02-08 06:52:41.938943: val_loss -0.3676
2024-02-08 06:52:41.939490: Pseudo dice [0.838, 0.8185, 0.747, 0.8392, 0.8093]
2024-02-08 06:52:41.939914: Epoch time: 43.29 s
2024-02-08 06:52:42.997148: 
2024-02-08 06:52:42.998675: Epoch 520
2024-02-08 06:52:42.999981: Current learning rate: 0.00073
2024-02-08 06:53:26.264045: train_loss -0.6428
2024-02-08 06:53:26.265586: val_loss -0.3812
2024-02-08 06:53:26.266086: Pseudo dice [0.842, 0.8219, 0.7541, 0.8555, 0.817]
2024-02-08 06:53:26.266535: Epoch time: 43.27 s
2024-02-08 06:53:27.295948: 
2024-02-08 06:53:27.297086: Epoch 521
2024-02-08 06:53:27.298346: Current learning rate: 0.00071
2024-02-08 06:54:10.393614: train_loss -0.6423
2024-02-08 06:54:10.394976: val_loss -0.3716
2024-02-08 06:54:10.395434: Pseudo dice [0.8366, 0.8259, 0.7528, 0.8496, 0.8049]
2024-02-08 06:54:10.396151: Epoch time: 43.1 s
2024-02-08 06:54:10.396586: Yayy! New best EMA pseudo Dice: 0.8135
2024-02-08 06:54:11.768878: 
2024-02-08 06:54:11.769838: Epoch 522
2024-02-08 06:54:11.770686: Current learning rate: 0.00069
2024-02-08 06:54:54.998628: train_loss -0.6407
2024-02-08 06:54:55.000417: val_loss -0.3616
2024-02-08 06:54:55.001027: Pseudo dice [0.8385, 0.8233, 0.7444, 0.8404, 0.8099]
2024-02-08 06:54:55.001517: Epoch time: 43.23 s
2024-02-08 06:54:56.041793: 
2024-02-08 06:54:56.043508: Epoch 523
2024-02-08 06:54:56.045303: Current learning rate: 0.00066
2024-02-08 06:55:39.160526: train_loss -0.64
2024-02-08 06:55:39.161824: val_loss -0.361
2024-02-08 06:55:39.162255: Pseudo dice [0.8413, 0.8188, 0.7478, 0.8442, 0.8173]
2024-02-08 06:55:39.162665: Epoch time: 43.12 s
2024-02-08 06:55:40.408413: 
2024-02-08 06:55:40.409602: Epoch 524
2024-02-08 06:55:40.410493: Current learning rate: 0.00064
2024-02-08 06:56:23.616550: train_loss -0.6458
2024-02-08 06:56:23.618081: val_loss -0.3589
2024-02-08 06:56:23.618578: Pseudo dice [0.8327, 0.8194, 0.74, 0.8349, 0.8161]
2024-02-08 06:56:23.619044: Epoch time: 43.21 s
2024-02-08 06:56:24.665881: 
2024-02-08 06:56:24.666918: Epoch 525
2024-02-08 06:56:24.668173: Current learning rate: 0.00062
2024-02-08 06:57:07.865955: train_loss -0.6405
2024-02-08 06:57:07.867561: val_loss -0.368
2024-02-08 06:57:07.868037: Pseudo dice [0.8355, 0.8293, 0.744, 0.839, 0.8112]
2024-02-08 06:57:07.868487: Epoch time: 43.2 s
2024-02-08 06:57:08.891773: 
2024-02-08 06:57:08.892911: Epoch 526
2024-02-08 06:57:08.894302: Current learning rate: 0.0006
2024-02-08 06:57:51.949227: train_loss -0.6477
2024-02-08 06:57:51.950868: val_loss -0.3896
2024-02-08 06:57:51.951342: Pseudo dice [0.8458, 0.8306, 0.7566, 0.853, 0.8192]
2024-02-08 06:57:51.951751: Epoch time: 43.06 s
2024-02-08 06:57:51.952187: Yayy! New best EMA pseudo Dice: 0.8136
2024-02-08 06:57:53.343860: 
2024-02-08 06:57:53.345347: Epoch 527
2024-02-08 06:57:53.346517: Current learning rate: 0.00057
2024-02-08 06:58:36.539679: train_loss -0.6426
2024-02-08 06:58:36.541513: val_loss -0.3457
2024-02-08 06:58:36.542028: Pseudo dice [0.8351, 0.8168, 0.7413, 0.8417, 0.8045]
2024-02-08 06:58:36.542529: Epoch time: 43.2 s
2024-02-08 06:58:37.576984: 
2024-02-08 06:58:37.578254: Epoch 528
2024-02-08 06:58:37.579566: Current learning rate: 0.00055
2024-02-08 06:59:20.767365: train_loss -0.6503
2024-02-08 06:59:20.769772: val_loss -0.3467
2024-02-08 06:59:20.770597: Pseudo dice [0.8351, 0.8185, 0.7436, 0.8404, 0.8033]
2024-02-08 06:59:20.771935: Epoch time: 43.19 s
2024-02-08 06:59:21.965000: 
2024-02-08 06:59:21.966547: Epoch 529
2024-02-08 06:59:21.967498: Current learning rate: 0.00053
2024-02-08 07:00:04.963003: train_loss -0.6445
2024-02-08 07:00:04.964415: val_loss -0.3818
2024-02-08 07:00:04.964896: Pseudo dice [0.8453, 0.8258, 0.7532, 0.8482, 0.8207]
2024-02-08 07:00:04.965336: Epoch time: 43.0 s
2024-02-08 07:00:06.001150: 
2024-02-08 07:00:06.002436: Epoch 530
2024-02-08 07:00:06.004128: Current learning rate: 0.00051
2024-02-08 07:00:49.166670: train_loss -0.6453
2024-02-08 07:00:49.167958: val_loss -0.3719
2024-02-08 07:00:49.168423: Pseudo dice [0.8413, 0.8215, 0.7484, 0.8465, 0.8043]
2024-02-08 07:00:49.168845: Epoch time: 43.17 s
2024-02-08 07:00:50.240725: 
2024-02-08 07:00:50.242990: Epoch 531
2024-02-08 07:00:50.243974: Current learning rate: 0.00048
2024-02-08 07:01:33.385835: train_loss -0.6428
2024-02-08 07:01:33.387520: val_loss -0.3612
2024-02-08 07:01:33.388027: Pseudo dice [0.8419, 0.8243, 0.7469, 0.8495, 0.8091]
2024-02-08 07:01:33.388493: Epoch time: 43.15 s
2024-02-08 07:01:34.462923: 
2024-02-08 07:01:34.464128: Epoch 532
2024-02-08 07:01:34.465558: Current learning rate: 0.00046
2024-02-08 07:02:17.465433: train_loss -0.6455
2024-02-08 07:02:17.466858: val_loss -0.345
2024-02-08 07:02:17.467354: Pseudo dice [0.8342, 0.817, 0.7425, 0.8404, 0.8094]
2024-02-08 07:02:17.467803: Epoch time: 43.0 s
2024-02-08 07:02:18.520213: 
2024-02-08 07:02:18.521278: Epoch 533
2024-02-08 07:02:18.522412: Current learning rate: 0.00044
2024-02-08 07:03:01.648317: train_loss -0.649
2024-02-08 07:03:01.650711: val_loss -0.3851
2024-02-08 07:03:01.651259: Pseudo dice [0.8463, 0.8235, 0.7552, 0.8461, 0.8183]
2024-02-08 07:03:01.651930: Epoch time: 43.13 s
2024-02-08 07:03:02.679804: 
2024-02-08 07:03:02.680990: Epoch 534
2024-02-08 07:03:02.682202: Current learning rate: 0.00041
2024-02-08 07:03:45.640431: train_loss -0.6462
2024-02-08 07:03:45.642668: val_loss -0.3759
2024-02-08 07:03:45.643477: Pseudo dice [0.8413, 0.8238, 0.7503, 0.8481, 0.8153]
2024-02-08 07:03:45.644008: Epoch time: 42.96 s
2024-02-08 07:03:46.825880: 
2024-02-08 07:03:46.827981: Epoch 535
2024-02-08 07:03:46.829496: Current learning rate: 0.00039
2024-02-08 07:04:30.008353: train_loss -0.6497
2024-02-08 07:04:30.010082: val_loss -0.3646
2024-02-08 07:04:30.010606: Pseudo dice [0.8411, 0.8206, 0.7475, 0.8468, 0.8096]
2024-02-08 07:04:30.011087: Epoch time: 43.18 s
2024-02-08 07:04:31.075068: 
2024-02-08 07:04:31.076659: Epoch 536
2024-02-08 07:04:31.077388: Current learning rate: 0.00037
2024-02-08 07:05:14.338434: train_loss -0.6475
2024-02-08 07:05:14.340004: val_loss -0.3642
2024-02-08 07:05:14.340518: Pseudo dice [0.8395, 0.8228, 0.7449, 0.8436, 0.8082]
2024-02-08 07:05:14.341009: Epoch time: 43.26 s
2024-02-08 07:05:15.416881: 
2024-02-08 07:05:15.417952: Epoch 537
2024-02-08 07:05:15.419063: Current learning rate: 0.00034
2024-02-08 07:05:58.600180: train_loss -0.6451
2024-02-08 07:05:58.601517: val_loss -0.3516
2024-02-08 07:05:58.601979: Pseudo dice [0.838, 0.8232, 0.7465, 0.8449, 0.8145]
2024-02-08 07:05:58.602400: Epoch time: 43.18 s
2024-02-08 07:05:59.675145: 
2024-02-08 07:05:59.676252: Epoch 538
2024-02-08 07:05:59.677125: Current learning rate: 0.00032
2024-02-08 07:06:43.023411: train_loss -0.6437
2024-02-08 07:06:43.024873: val_loss -0.3741
2024-02-08 07:06:43.025355: Pseudo dice [0.8421, 0.8293, 0.7478, 0.8448, 0.808]
2024-02-08 07:06:43.025823: Epoch time: 43.35 s
2024-02-08 07:06:44.083084: 
2024-02-08 07:06:44.084317: Epoch 539
2024-02-08 07:06:44.085464: Current learning rate: 0.0003
2024-02-08 07:07:27.212596: train_loss -0.6414
2024-02-08 07:07:27.214531: val_loss -0.3762
2024-02-08 07:07:27.215036: Pseudo dice [0.837, 0.8247, 0.7453, 0.8423, 0.8139]
2024-02-08 07:07:27.215506: Epoch time: 43.13 s
2024-02-08 07:07:28.439935: 
2024-02-08 07:07:28.441156: Epoch 540
2024-02-08 07:07:28.442258: Current learning rate: 0.00027
2024-02-08 07:08:11.817868: train_loss -0.6426
2024-02-08 07:08:11.822104: val_loss -0.3772
2024-02-08 07:08:11.822586: Pseudo dice [0.8407, 0.8284, 0.751, 0.8429, 0.8131]
2024-02-08 07:08:11.823056: Epoch time: 43.38 s
2024-02-08 07:08:12.858334: 
2024-02-08 07:08:12.859510: Epoch 541
2024-02-08 07:08:12.860749: Current learning rate: 0.00025
2024-02-08 07:08:56.127993: train_loss -0.6506
2024-02-08 07:08:56.129586: val_loss -0.3655
2024-02-08 07:08:56.130092: Pseudo dice [0.8407, 0.8251, 0.7468, 0.8429, 0.8142]
2024-02-08 07:08:56.130556: Epoch time: 43.27 s
2024-02-08 07:08:57.181284: 
2024-02-08 07:08:57.182452: Epoch 542
2024-02-08 07:08:57.183684: Current learning rate: 0.00022
2024-02-08 07:09:40.355370: train_loss -0.6463
2024-02-08 07:09:40.356930: val_loss -0.3914
2024-02-08 07:09:40.357450: Pseudo dice [0.8461, 0.8302, 0.7542, 0.8565, 0.8121]
2024-02-08 07:09:40.357907: Epoch time: 43.18 s
2024-02-08 07:09:40.358316: Yayy! New best EMA pseudo Dice: 0.8142
2024-02-08 07:09:41.716955: 
2024-02-08 07:09:41.718486: Epoch 543
2024-02-08 07:09:41.719623: Current learning rate: 0.0002
2024-02-08 07:10:24.964187: train_loss -0.6446
2024-02-08 07:10:24.965843: val_loss -0.3525
2024-02-08 07:10:24.966366: Pseudo dice [0.8374, 0.8149, 0.7398, 0.8431, 0.8108]
2024-02-08 07:10:24.966866: Epoch time: 43.25 s
2024-02-08 07:10:26.007114: 
2024-02-08 07:10:26.008341: Epoch 544
2024-02-08 07:10:26.009407: Current learning rate: 0.00017
2024-02-08 07:11:09.136744: train_loss -0.6435
2024-02-08 07:11:09.138480: val_loss -0.3728
2024-02-08 07:11:09.139009: Pseudo dice [0.8411, 0.822, 0.7451, 0.8486, 0.8283]
2024-02-08 07:11:09.139551: Epoch time: 43.13 s
2024-02-08 07:11:10.337127: 
2024-02-08 07:11:10.338583: Epoch 545
2024-02-08 07:11:10.339687: Current learning rate: 0.00015
2024-02-08 07:11:53.808088: train_loss -0.6497
2024-02-08 07:11:53.809671: val_loss -0.3564
2024-02-08 07:11:53.810167: Pseudo dice [0.8393, 0.8218, 0.7463, 0.8465, 0.8113]
2024-02-08 07:11:53.810614: Epoch time: 43.47 s
2024-02-08 07:11:54.841688: 
2024-02-08 07:11:54.842739: Epoch 546
2024-02-08 07:11:54.843947: Current learning rate: 0.00012
2024-02-08 07:12:38.186624: train_loss -0.6493
2024-02-08 07:12:38.191075: val_loss -0.3692
2024-02-08 07:12:38.191648: Pseudo dice [0.8416, 0.8246, 0.751, 0.8496, 0.8117]
2024-02-08 07:12:38.192165: Epoch time: 43.35 s
2024-02-08 07:12:39.233964: 
2024-02-08 07:12:39.235020: Epoch 547
2024-02-08 07:12:39.236249: Current learning rate: 9e-05
2024-02-08 07:13:22.655912: train_loss -0.6463
2024-02-08 07:13:22.657495: val_loss -0.3608
2024-02-08 07:13:22.657986: Pseudo dice [0.8388, 0.8214, 0.7447, 0.8448, 0.8154]
2024-02-08 07:13:22.658440: Epoch time: 43.42 s
2024-02-08 07:13:23.729454: 
2024-02-08 07:13:23.730982: Epoch 548
2024-02-08 07:13:23.732536: Current learning rate: 6e-05
2024-02-08 07:14:06.965995: train_loss -0.6431
2024-02-08 07:14:06.968029: val_loss -0.3643
2024-02-08 07:14:06.968687: Pseudo dice [0.8392, 0.8216, 0.7452, 0.8424, 0.8134]
2024-02-08 07:14:06.969095: Epoch time: 43.24 s
2024-02-08 07:14:08.023700: 
2024-02-08 07:14:08.024706: Epoch 549
2024-02-08 07:14:08.025772: Current learning rate: 3e-05
2024-02-08 07:14:51.278027: train_loss -0.6485
2024-02-08 07:14:51.280621: val_loss -0.3676
2024-02-08 07:14:51.281134: Pseudo dice [0.8418, 0.8237, 0.7494, 0.84, 0.8152]
2024-02-08 07:14:51.281601: Epoch time: 43.26 s
2024-02-08 07:14:53.051228: Training done.
2024-02-08 07:14:53.467344: Using splits from existing split file: /scratch/gilbreth/li2068/nnUNet_v2/nnUNet_preprocessed/Dataset301_HMstroke/splits_final.json
2024-02-08 07:14:53.468548: The split file contains 5 splits.
2024-02-08 07:14:53.468863: Desired fold for training: 5
2024-02-08 07:14:53.469162: INFO: You requested fold 5 for training but splits contain only 5 folds. I am now creating a random (but seeded) 80:20 split!
2024-02-08 07:14:53.470279: This random 80:20 split has 64 training and 16 validation cases.
2024-02-08 07:14:53.470749: predicting HM_003
2024-02-08 07:14:56.459637: predicting HM_007
2024-02-08 07:15:00.682749: predicting HM_016
2024-02-08 07:15:02.566988: predicting HM_017
2024-02-08 07:15:04.465249: predicting HM_026
2024-02-08 07:15:07.287408: predicting HM_037
2024-02-08 07:15:08.253341: predicting HM_044
2024-02-08 07:15:11.085322: predicting HM_045
2024-02-08 07:15:12.988074: predicting HM_048
2024-02-08 07:15:15.817136: predicting HM_058
2024-02-08 07:15:18.639626: predicting HM_059
2024-02-08 07:15:21.474273: predicting HM_061
2024-02-08 07:15:25.680771: predicting HM_069
2024-02-08 07:15:28.524566: predicting HM_072
2024-02-08 07:15:31.357189: predicting HM_074
2024-02-08 07:15:33.253316: predicting HM_076
2024-02-08 07:15:41.337476: Validation complete
2024-02-08 07:15:41.339228: Mean Validation Dice:  0.8131755119036596
